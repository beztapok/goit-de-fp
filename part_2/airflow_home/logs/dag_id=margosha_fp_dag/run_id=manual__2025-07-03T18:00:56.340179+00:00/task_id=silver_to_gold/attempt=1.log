[2025-07-03T18:01:53.230+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-07-03T18:01:53.234+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: margosha_fp_dag.silver_to_gold manual__2025-07-03T18:00:56.340179+00:00 [queued]>
[2025-07-03T18:01:53.237+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: margosha_fp_dag.silver_to_gold manual__2025-07-03T18:00:56.340179+00:00 [queued]>
[2025-07-03T18:01:53.237+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-07-03T18:01:53.242+0000] {taskinstance.py:2889} INFO - Executing <Task(SparkSubmitOperator): silver_to_gold> on 2025-07-03 18:00:56.340179+00:00
[2025-07-03T18:01:53.244+0000] {standard_task_runner.py:72} INFO - Started process 3176 to run task
[2025-07-03T18:01:53.246+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'margosha_fp_dag', 'silver_to_gold', 'manual__2025-07-03T18:00:56.340179+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/margosha/project_solution.py', '--cfg-path', '/tmp/tmp1m88brmd']
[2025-07-03T18:01:53.248+0000] {standard_task_runner.py:105} INFO - Job 6: Subtask silver_to_gold
[2025-07-03T18:01:53.272+0000] {task_command.py:467} INFO - Running <TaskInstance: margosha_fp_dag.silver_to_gold manual__2025-07-03T18:00:56.340179+00:00 [running]> on host 39b5ac792cf9
[2025-07-03T18:01:53.295+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='margosha' AIRFLOW_CTX_DAG_ID='margosha_fp_dag' AIRFLOW_CTX_TASK_ID='silver_to_gold' AIRFLOW_CTX_EXECUTION_DATE='2025-07-03T18:00:56.340179+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-03T18:00:56.340179+00:00'
[2025-07-03T18:01:53.295+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-07-03T18:01:53.307+0000] {base.py:84} INFO - Retrieving connection 'spark-default'
[2025-07-03T18:01:53.308+0000] {spark_submit.py:403} INFO - Spark-Submit cmd: spark-submit --master local --conf spark.master=local[*] --conf spark.executor.memory=1g --conf spark.driver.memory=1g --conf spark.sql.adaptive.enabled=false --name arrow-spark --verbose --deploy-mode client /opt/airflow/dags/margosha/silver_to_gold.py /opt/shared
[2025-07-03T18:01:54.160+0000] {spark_submit.py:579} INFO - Using properties file: null
[2025-07-03T18:01:54.208+0000] {spark_submit.py:579} INFO - Parsed arguments:
[2025-07-03T18:01:54.209+0000] {spark_submit.py:579} INFO - master                  local
[2025-07-03T18:01:54.209+0000] {spark_submit.py:579} INFO - remote                  null
[2025-07-03T18:01:54.209+0000] {spark_submit.py:579} INFO - deployMode              client
[2025-07-03T18:01:54.209+0000] {spark_submit.py:579} INFO - executorMemory          1g
[2025-07-03T18:01:54.209+0000] {spark_submit.py:579} INFO - executorCores           null
[2025-07-03T18:01:54.209+0000] {spark_submit.py:579} INFO - totalExecutorCores      null
[2025-07-03T18:01:54.209+0000] {spark_submit.py:579} INFO - propertiesFile          null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - driverMemory            1g
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - driverCores             null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - driverExtraClassPath    null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - driverExtraLibraryPath  null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - driverExtraJavaOptions  null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - supervise               false
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - queue                   null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - numExecutors            null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - files                   null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - pyFiles                 null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - archives                null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - mainClass               null
[2025-07-03T18:01:54.210+0000] {spark_submit.py:579} INFO - primaryResource         file:/opt/airflow/dags/margosha/silver_to_gold.py
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - name                    arrow-spark
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - childArgs               [/opt/shared]
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - jars                    null
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - packages                null
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - packagesExclusions      null
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - repositories            null
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - verbose                 true
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - Spark properties used, including those specified through
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - --conf and those from the properties file null:
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - (spark.driver.memory,1g)
[2025-07-03T18:01:54.211+0000] {spark_submit.py:579} INFO - (spark.executor.memory,1g)
[2025-07-03T18:01:54.212+0000] {spark_submit.py:579} INFO - (spark.master,local[*])
[2025-07-03T18:01:54.212+0000] {spark_submit.py:579} INFO - (spark.sql.adaptive.enabled,false)
[2025-07-03T18:01:54.212+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:54.212+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:54.336+0000] {spark_submit.py:579} INFO - Main class:
[2025-07-03T18:01:54.336+0000] {spark_submit.py:579} INFO - org.apache.spark.deploy.PythonRunner
[2025-07-03T18:01:54.336+0000] {spark_submit.py:579} INFO - Arguments:
[2025-07-03T18:01:54.337+0000] {spark_submit.py:579} INFO - file:/opt/airflow/dags/margosha/silver_to_gold.py
[2025-07-03T18:01:54.337+0000] {spark_submit.py:579} INFO - null
[2025-07-03T18:01:54.337+0000] {spark_submit.py:579} INFO - /opt/shared
[2025-07-03T18:01:54.338+0000] {spark_submit.py:579} INFO - Spark config:
[2025-07-03T18:01:54.338+0000] {spark_submit.py:579} INFO - (spark.app.name,arrow-spark)
[2025-07-03T18:01:54.338+0000] {spark_submit.py:579} INFO - (spark.app.submitTime,1751565714328)
[2025-07-03T18:01:54.338+0000] {spark_submit.py:579} INFO - (spark.driver.memory,1g)
[2025-07-03T18:01:54.338+0000] {spark_submit.py:579} INFO - (spark.executor.memory,1g)
[2025-07-03T18:01:54.338+0000] {spark_submit.py:579} INFO - (spark.master,local)
[2025-07-03T18:01:54.339+0000] {spark_submit.py:579} INFO - (spark.sql.adaptive.enabled,false)
[2025-07-03T18:01:54.339+0000] {spark_submit.py:579} INFO - (spark.submit.deployMode,client)
[2025-07-03T18:01:54.339+0000] {spark_submit.py:579} INFO - (spark.submit.pyFiles,)
[2025-07-03T18:01:54.339+0000] {spark_submit.py:579} INFO - Classpath elements:
[2025-07-03T18:01:54.339+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:54.339+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:54.339+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:54.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SparkContext: Running Spark version 3.5.2
[2025-07-03T18:01:54.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-03T18:01:54.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SparkContext: Java version 17.0.15
[2025-07-03T18:01:54.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-03T18:01:54.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO ResourceUtils: ==============================================================
[2025-07-03T18:01:54.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-03T18:01:54.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO ResourceUtils: ==============================================================
[2025-07-03T18:01:54.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SparkContext: Submitted application: Calculate Average Stats
[2025-07-03T18:01:54.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-03T18:01:54.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO ResourceProfile: Limiting resource is cpu
[2025-07-03T18:01:54.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-03T18:01:54.994+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SecurityManager: Changing view acls to: airflow
[2025-07-03T18:01:54.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SecurityManager: Changing modify acls to: airflow
[2025-07-03T18:01:54.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SecurityManager: Changing view acls groups to:
[2025-07-03T18:01:54.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SecurityManager: Changing modify acls groups to:
[2025-07-03T18:01:54.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY
[2025-07-03T18:01:55.095+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Utils: Successfully started service 'sparkDriver' on port 45739.
[2025-07-03T18:01:55.113+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO SparkEnv: Registering MapOutputTracker
[2025-07-03T18:01:55.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-03T18:01:55.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-03T18:01:55.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-03T18:01:55.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-03T18:01:55.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8cbec90f-6360-4ece-a493-c3ef72e6e696
[2025-07-03T18:01:55.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-03T18:01:55.172+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-03T18:01:55.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-03T18:01:55.258+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-07-03T18:01:55.301+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Executor: Starting executor ID driver on host 39b5ac792cf9
[2025-07-03T18:01:55.302+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-03T18:01:55.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Executor: Java version 17.0.15
[2025-07-03T18:01:55.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-03T18:01:55.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4ea8cbd5 for default.
[2025-07-03T18:01:55.311+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37901.
[2025-07-03T18:01:55.311+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO NettyBlockTransferService: Server created on 39b5ac792cf9:37901
[2025-07-03T18:01:55.311+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-03T18:01:55.314+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 39b5ac792cf9, 37901, None)
[2025-07-03T18:01:55.315+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO BlockManagerMasterEndpoint: Registering block manager 39b5ac792cf9:37901 with 434.4 MiB RAM, BlockManagerId(driver, 39b5ac792cf9, 37901, None)
[2025-07-03T18:01:55.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 39b5ac792cf9, 37901, None)
[2025-07-03T18:01:55.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 39b5ac792cf9, 37901, None)
[2025-07-03T18:01:55.501+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-03T18:01:55.504+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-07-03T18:01:55.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:55 INFO InMemoryFileIndex: It took 90 ms to list leaf files for 1 paths.
[2025-07-03T18:01:56.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-07-03T18:01:56.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-03T18:01:56.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
[2025-07-03T18:01:56.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Parents of final stage: List()
[2025-07-03T18:01:56.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Missing parents: List()
[2025-07-03T18:01:56.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:01:56.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.4 KiB, free 434.3 MiB)
[2025-07-03T18:01:56.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 434.3 MiB)
[2025-07-03T18:01:56.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 39b5ac792cf9:37901 (size: 37.1 KiB, free: 434.4 MiB)
[2025-07-03T18:01:56.279+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:01:56.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-03T18:01:56.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-03T18:01:56.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 9197 bytes)
[2025-07-03T18:01:56.343+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-03T18:01:56.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2065 bytes result sent to driver
[2025-07-03T18:01:56.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 230 ms on 39b5ac792cf9 (executor driver) (1/1)
[2025-07-03T18:01:56.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-03T18:01:56.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.371 s
[2025-07-03T18:01:56.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:01:56.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-07-03T18:01:56.559+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.387925 s
[2025-07-03T18:01:56.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 39b5ac792cf9:37901 in memory (size: 37.1 KiB, free: 434.4 MiB)
[2025-07-03T18:01:56.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO InMemoryFileIndex: It took 54 ms to list leaf files for 1 paths.
[2025-07-03T18:01:56.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-07-03T18:01:56.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Got job 1 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-03T18:01:56.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0)
[2025-07-03T18:01:56.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Parents of final stage: List()
[2025-07-03T18:01:56.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Missing parents: List()
[2025-07-03T18:01:56.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:01:56.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 103.4 KiB, free 434.3 MiB)
[2025-07-03T18:01:56.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 434.3 MiB)
[2025-07-03T18:01:56.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 39b5ac792cf9:37901 (size: 37.1 KiB, free: 434.4 MiB)
[2025-07-03T18:01:56.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:01:56.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-03T18:01:56.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-07-03T18:01:56.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 9207 bytes)
[2025-07-03T18:01:56.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-07-03T18:01:56.961+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2115 bytes result sent to driver
[2025-07-03T18:01:56.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 17 ms on 39b5ac792cf9 (executor driver) (1/1)
[2025-07-03T18:01:56.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-03T18:01:56.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.025 s
[2025-07-03T18:01:56.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:01:56.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-03T18:01:56.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO DAGScheduler: Job 1 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.026711 s
[2025-07-03T18:01:56.975+0000] {spark_submit.py:579} INFO - Athlete bio schema:
[2025-07-03T18:01:56.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:56 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 39b5ac792cf9:37901 in memory (size: 37.1 KiB, free: 434.4 MiB)
[2025-07-03T18:01:56.994+0000] {spark_submit.py:579} INFO - root
[2025-07-03T18:01:56.994+0000] {spark_submit.py:579} INFO - |-- athlete_id: integer (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- name: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- sex: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- born: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- height: integer (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- weight: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- country: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- country_noc: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- description: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - |-- special_notes: string (nullable = true)
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - Athlete event schema:
[2025-07-03T18:01:56.995+0000] {spark_submit.py:579} INFO - root
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- edition: string (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- edition_id: integer (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- country_noc: string (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- sport: string (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- event: string (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- result_id: integer (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- athlete: string (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- athlete_id: integer (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- pos: string (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- medal: string (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - |-- isTeamSport: boolean (nullable = true)
[2025-07-03T18:01:56.996+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:01:57.286+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:01:57.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#0)
[2025-07-03T18:01:57.292+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:01:57.292+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#27)
[2025-07-03T18:01:57.433+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO CodeGenerator: Code generated in 87.272416 ms
[2025-07-03T18:01:57.434+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO CodeGenerator: Code generated in 79.258708 ms
[2025-07-03T18:01:57.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 201.3 KiB, free 434.2 MiB)
[2025-07-03T18:01:57.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 434.2 MiB)
[2025-07-03T18:01:57.446+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 39b5ac792cf9:37901 (size: 35.0 KiB, free: 434.4 MiB)
[2025-07-03T18:01:57.446+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO SparkContext: Created broadcast 2 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:01:57.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:01:57.488+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:01:57.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 7 output partitions
[2025-07-03T18:01:57.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-03T18:01:57.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO DAGScheduler: Parents of final stage: List()
[2025-07-03T18:01:57.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO DAGScheduler: Missing parents: List()
[2025-07-03T18:01:57.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-03T18:01:57.492+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.3 KiB, free 434.2 MiB)
[2025-07-03T18:01:57.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.1 MiB)
[2025-07-03T18:01:57.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 39b5ac792cf9:37901 (size: 6.3 KiB, free: 434.4 MiB)
[2025-07-03T18:01:57.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:01:57.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:01:57.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 7 tasks resource profile 0
[2025-07-03T18:01:57.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:57.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2025-07-03T18:01:57.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO CodeGenerator: Code generated in 8.506667 ms
[2025-07-03T18:01:57.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00130-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57587, partition values: [empty row]
[2025-07-03T18:01:57.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO CodecPool: Got brand-new decompressor [.snappy]
[2025-07-03T18:01:57.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00029-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57404, partition values: [empty row]
[2025-07-03T18:01:57.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.670+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00025-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56716, partition values: [empty row]
[2025-07-03T18:01:57.673+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00094-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56382, partition values: [empty row]
[2025-07-03T18:01:57.679+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.681+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00051-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56298, partition values: [empty row]
[2025-07-03T18:01:57.685+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.687+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00076-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56236, partition values: [empty row]
[2025-07-03T18:01:57.691+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.692+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00193-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56152, partition values: [empty row]
[2025-07-03T18:01:57.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.697+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00159-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56131, partition values: [empty row]
[2025-07-03T18:01:57.699+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00040-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56041, partition values: [empty row]
[2025-07-03T18:01:57.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.705+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00172-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55935, partition values: [empty row]
[2025-07-03T18:01:57.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.710+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00101-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55751, partition values: [empty row]
[2025-07-03T18:01:57.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.713+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00103-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55611, partition values: [empty row]
[2025-07-03T18:01:57.715+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.717+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00189-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55606, partition values: [empty row]
[2025-07-03T18:01:57.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.720+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00127-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55599, partition values: [empty row]
[2025-07-03T18:01:57.723+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00063-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55563, partition values: [empty row]
[2025-07-03T18:01:57.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.728+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00095-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55516, partition values: [empty row]
[2025-07-03T18:01:57.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00173-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55432, partition values: [empty row]
[2025-07-03T18:01:57.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00188-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55276, partition values: [empty row]
[2025-07-03T18:01:57.738+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.739+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00125-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55207, partition values: [empty row]
[2025-07-03T18:01:57.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00154-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55088, partition values: [empty row]
[2025-07-03T18:01:57.744+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00010-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55072, partition values: [empty row]
[2025-07-03T18:01:57.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.749+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00005-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55055, partition values: [empty row]
[2025-07-03T18:01:57.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00000-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55054, partition values: [empty row]
[2025-07-03T18:01:57.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00098-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55020, partition values: [empty row]
[2025-07-03T18:01:57.759+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.760+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00168-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54965, partition values: [empty row]
[2025-07-03T18:01:57.762+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00074-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54962, partition values: [empty row]
[2025-07-03T18:01:57.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.767+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00108-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54960, partition values: [empty row]
[2025-07-03T18:01:57.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00004-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54956, partition values: [empty row]
[2025-07-03T18:01:57.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.774+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00139-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54954, partition values: [empty row]
[2025-07-03T18:01:57.776+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00182-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54952, partition values: [empty row]
[2025-07-03T18:01:57.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00122-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54947, partition values: [empty row]
[2025-07-03T18:01:57.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00018-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54918, partition values: [empty row]
[2025-07-03T18:01:57.787+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 299564 bytes result sent to driver
[2025-07-03T18:01:57.792+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:57.792+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 297 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:01:57.792+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
[2025-07-03T18:01:57.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00057-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54867, partition values: [empty row]
[2025-07-03T18:01:57.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00023-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54835, partition values: [empty row]
[2025-07-03T18:01:57.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00143-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54795, partition values: [empty row]
[2025-07-03T18:01:57.808+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.809+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00158-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54737, partition values: [empty row]
[2025-07-03T18:01:57.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.813+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00116-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54723, partition values: [empty row]
[2025-07-03T18:01:57.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00042-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54716, partition values: [empty row]
[2025-07-03T18:01:57.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00083-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:01:57.825+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.826+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00119-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:01:57.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00141-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54669, partition values: [empty row]
[2025-07-03T18:01:57.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00186-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54659, partition values: [empty row]
[2025-07-03T18:01:57.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00045-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54586, partition values: [empty row]
[2025-07-03T18:01:57.836+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00155-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54571, partition values: [empty row]
[2025-07-03T18:01:57.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.840+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00162-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54563, partition values: [empty row]
[2025-07-03T18:01:57.842+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.843+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00144-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54516, partition values: [empty row]
[2025-07-03T18:01:57.845+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00087-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54501, partition values: [empty row]
[2025-07-03T18:01:57.848+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00009-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54492, partition values: [empty row]
[2025-07-03T18:01:57.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00100-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54461, partition values: [empty row]
[2025-07-03T18:01:57.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00032-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54441, partition values: [empty row]
[2025-07-03T18:01:57.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00176-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54386, partition values: [empty row]
[2025-07-03T18:01:57.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00003-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54385, partition values: [empty row]
[2025-07-03T18:01:57.864+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00058-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54354, partition values: [empty row]
[2025-07-03T18:01:57.867+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00111-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54349, partition values: [empty row]
[2025-07-03T18:01:57.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00147-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54288, partition values: [empty row]
[2025-07-03T18:01:57.874+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.875+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00091-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54283, partition values: [empty row]
[2025-07-03T18:01:57.877+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.878+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00107-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54279, partition values: [empty row]
[2025-07-03T18:01:57.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00024-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54230, partition values: [empty row]
[2025-07-03T18:01:57.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00038-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54190, partition values: [empty row]
[2025-07-03T18:01:57.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00191-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54144, partition values: [empty row]
[2025-07-03T18:01:57.889+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.891+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00120-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54132, partition values: [empty row]
[2025-07-03T18:01:57.893+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00194-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54131, partition values: [empty row]
[2025-07-03T18:01:57.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00035-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54124, partition values: [empty row]
[2025-07-03T18:01:57.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00110-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54080, partition values: [empty row]
[2025-07-03T18:01:57.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 296236 bytes result sent to driver
[2025-07-03T18:01:57.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:57.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO Executor: Running task 2.0 in stage 2.0 (TID 4)
[2025-07-03T18:01:57.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 112 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:01:57.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00021-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54070, partition values: [empty row]
[2025-07-03T18:01:57.908+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.909+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00114-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54048, partition values: [empty row]
[2025-07-03T18:01:57.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00150-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54032, partition values: [empty row]
[2025-07-03T18:01:57.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00169-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54022, partition values: [empty row]
[2025-07-03T18:01:57.917+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00082-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54019, partition values: [empty row]
[2025-07-03T18:01:57.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00043-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53970, partition values: [empty row]
[2025-07-03T18:01:57.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.924+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00015-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53950, partition values: [empty row]
[2025-07-03T18:01:57.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00164-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53947, partition values: [empty row]
[2025-07-03T18:01:57.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00152-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53936, partition values: [empty row]
[2025-07-03T18:01:57.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00197-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53935, partition values: [empty row]
[2025-07-03T18:01:57.934+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00160-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53924, partition values: [empty row]
[2025-07-03T18:01:57.936+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00002-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53904, partition values: [empty row]
[2025-07-03T18:01:57.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00165-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53870, partition values: [empty row]
[2025-07-03T18:01:57.940+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00078-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53867, partition values: [empty row]
[2025-07-03T18:01:57.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00145-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53865, partition values: [empty row]
[2025-07-03T18:01:57.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00153-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53863, partition values: [empty row]
[2025-07-03T18:01:57.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.948+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00047-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53839, partition values: [empty row]
[2025-07-03T18:01:57.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00077-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53831, partition values: [empty row]
[2025-07-03T18:01:57.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00131-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53770, partition values: [empty row]
[2025-07-03T18:01:57.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00028-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:01:57.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00022-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:01:57.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.961+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00126-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53726, partition values: [empty row]
[2025-07-03T18:01:57.962+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00148-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53681, partition values: [empty row]
[2025-07-03T18:01:57.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00179-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53662, partition values: [empty row]
[2025-07-03T18:01:57.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00034-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53650, partition values: [empty row]
[2025-07-03T18:01:57.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00171-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53632, partition values: [empty row]
[2025-07-03T18:01:57.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00137-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53624, partition values: [empty row]
[2025-07-03T18:01:57.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00086-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53620, partition values: [empty row]
[2025-07-03T18:01:57.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00014-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53616, partition values: [empty row]
[2025-07-03T18:01:57.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.984+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00073-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53614, partition values: [empty row]
[2025-07-03T18:01:57.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00105-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53604, partition values: [empty row]
[2025-07-03T18:01:57.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00199-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53602, partition values: [empty row]
[2025-07-03T18:01:57.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:57.994+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 287674 bytes result sent to driver
[2025-07-03T18:01:57.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:57.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO Executor: Running task 3.0 in stage 2.0 (TID 5)
[2025-07-03T18:01:57.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 93 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:01:57.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00044-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53598, partition values: [empty row]
[2025-07-03T18:01:57.999+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:57 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00146-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53596, partition values: [empty row]
[2025-07-03T18:01:58.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00016-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53586, partition values: [empty row]
[2025-07-03T18:01:58.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00070-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53575, partition values: [empty row]
[2025-07-03T18:01:58.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00037-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53559, partition values: [empty row]
[2025-07-03T18:01:58.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00001-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53526, partition values: [empty row]
[2025-07-03T18:01:58.012+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.013+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00080-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53515, partition values: [empty row]
[2025-07-03T18:01:58.014+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00056-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53508, partition values: [empty row]
[2025-07-03T18:01:58.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00117-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53501, partition values: [empty row]
[2025-07-03T18:01:58.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00187-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53499, partition values: [empty row]
[2025-07-03T18:01:58.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00007-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53477, partition values: [empty row]
[2025-07-03T18:01:58.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00006-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53475, partition values: [empty row]
[2025-07-03T18:01:58.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00039-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53453, partition values: [empty row]
[2025-07-03T18:01:58.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.029+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00174-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53442, partition values: [empty row]
[2025-07-03T18:01:58.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00113-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53440, partition values: [empty row]
[2025-07-03T18:01:58.033+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00106-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53430, partition values: [empty row]
[2025-07-03T18:01:58.036+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00163-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53416, partition values: [empty row]
[2025-07-03T18:01:58.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00121-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53400, partition values: [empty row]
[2025-07-03T18:01:58.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00177-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53349, partition values: [empty row]
[2025-07-03T18:01:58.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00128-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53335, partition values: [empty row]
[2025-07-03T18:01:58.046+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00118-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53325, partition values: [empty row]
[2025-07-03T18:01:58.048+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.049+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00132-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53320, partition values: [empty row]
[2025-07-03T18:01:58.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00140-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53318, partition values: [empty row]
[2025-07-03T18:01:58.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00135-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53317, partition values: [empty row]
[2025-07-03T18:01:58.057+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00124-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53308, partition values: [empty row]
[2025-07-03T18:01:58.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.061+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00096-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53302, partition values: [empty row]
[2025-07-03T18:01:58.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00183-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53295, partition values: [empty row]
[2025-07-03T18:01:58.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00134-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53289, partition values: [empty row]
[2025-07-03T18:01:58.068+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.068+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00151-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53288, partition values: [empty row]
[2025-07-03T18:01:58.072+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.072+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00067-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53279, partition values: [empty row]
[2025-07-03T18:01:58.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.076+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00053-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53278, partition values: [empty row]
[2025-07-03T18:01:58.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00129-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:01:58.081+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.084+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 3.0 in stage 2.0 (TID 5). 285285 bytes result sent to driver
[2025-07-03T18:01:58.084+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:58.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 4.0 in stage 2.0 (TID 6)
[2025-07-03T18:01:58.086+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 90 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:01:58.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00019-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:01:58.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.091+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00198-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53274, partition values: [empty row]
[2025-07-03T18:01:58.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00046-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53272, partition values: [empty row]
[2025-07-03T18:01:58.098+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.099+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00065-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53261, partition values: [empty row]
[2025-07-03T18:01:58.102+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.104+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00052-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53240, partition values: [empty row]
[2025-07-03T18:01:58.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00190-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:01:58.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00196-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:01:58.110+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.110+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00157-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53211, partition values: [empty row]
[2025-07-03T18:01:58.111+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.112+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00048-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:01:58.113+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.113+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00185-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:01:58.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00020-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53155, partition values: [empty row]
[2025-07-03T18:01:58.116+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.117+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00180-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53145, partition values: [empty row]
[2025-07-03T18:01:58.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00178-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53134, partition values: [empty row]
[2025-07-03T18:01:58.121+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.122+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00104-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53119, partition values: [empty row]
[2025-07-03T18:01:58.124+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.125+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00138-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53103, partition values: [empty row]
[2025-07-03T18:01:58.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.127+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00085-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53097, partition values: [empty row]
[2025-07-03T18:01:58.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00112-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53073, partition values: [empty row]
[2025-07-03T18:01:58.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00181-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53071, partition values: [empty row]
[2025-07-03T18:01:58.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00075-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53065, partition values: [empty row]
[2025-07-03T18:01:58.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.137+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00149-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53062, partition values: [empty row]
[2025-07-03T18:01:58.138+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.139+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00012-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53049, partition values: [empty row]
[2025-07-03T18:01:58.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.141+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00090-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53047, partition values: [empty row]
[2025-07-03T18:01:58.142+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.143+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00068-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52969, partition values: [empty row]
[2025-07-03T18:01:58.146+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.146+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00054-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52925, partition values: [empty row]
[2025-07-03T18:01:58.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00195-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52882, partition values: [empty row]
[2025-07-03T18:01:58.149+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00049-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52845, partition values: [empty row]
[2025-07-03T18:01:58.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00092-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52842, partition values: [empty row]
[2025-07-03T18:01:58.153+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.153+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00102-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52835, partition values: [empty row]
[2025-07-03T18:01:58.155+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.155+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00081-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52833, partition values: [empty row]
[2025-07-03T18:01:58.157+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.157+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00072-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:01:58.160+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.161+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00142-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:01:58.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00036-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52790, partition values: [empty row]
[2025-07-03T18:01:58.164+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 4.0 in stage 2.0 (TID 6). 284641 bytes result sent to driver
[2025-07-03T18:01:58.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:58.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 5.0 in stage 2.0 (TID 7)
[2025-07-03T18:01:58.168+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 83 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:01:58.169+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00109-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52784, partition values: [empty row]
[2025-07-03T18:01:58.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.172+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00084-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52779, partition values: [empty row]
[2025-07-03T18:01:58.173+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.174+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00030-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52777, partition values: [empty row]
[2025-07-03T18:01:58.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00156-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52761, partition values: [empty row]
[2025-07-03T18:01:58.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00133-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52743, partition values: [empty row]
[2025-07-03T18:01:58.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00123-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52718, partition values: [empty row]
[2025-07-03T18:01:58.182+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.183+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00184-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52713, partition values: [empty row]
[2025-07-03T18:01:58.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00088-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52688, partition values: [empty row]
[2025-07-03T18:01:58.187+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.187+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00136-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52677, partition values: [empty row]
[2025-07-03T18:01:58.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00033-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52557, partition values: [empty row]
[2025-07-03T18:01:58.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.191+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00167-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52551, partition values: [empty row]
[2025-07-03T18:01:58.192+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00060-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52533, partition values: [empty row]
[2025-07-03T18:01:58.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00192-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52518, partition values: [empty row]
[2025-07-03T18:01:58.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00055-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52503, partition values: [empty row]
[2025-07-03T18:01:58.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00027-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52497, partition values: [empty row]
[2025-07-03T18:01:58.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00066-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52492, partition values: [empty row]
[2025-07-03T18:01:58.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00097-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52439, partition values: [empty row]
[2025-07-03T18:01:58.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00166-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52417, partition values: [empty row]
[2025-07-03T18:01:58.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00050-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52366, partition values: [empty row]
[2025-07-03T18:01:58.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00071-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52346, partition values: [empty row]
[2025-07-03T18:01:58.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00008-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52121, partition values: [empty row]
[2025-07-03T18:01:58.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00061-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52118, partition values: [empty row]
[2025-07-03T18:01:58.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00115-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52045, partition values: [empty row]
[2025-07-03T18:01:58.218+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.219+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00041-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51912, partition values: [empty row]
[2025-07-03T18:01:58.220+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.220+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00089-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51902, partition values: [empty row]
[2025-07-03T18:01:58.223+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.223+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00026-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51833, partition values: [empty row]
[2025-07-03T18:01:58.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00062-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51819, partition values: [empty row]
[2025-07-03T18:01:58.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.228+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00031-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51818, partition values: [empty row]
[2025-07-03T18:01:58.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.231+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00017-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51773, partition values: [empty row]
[2025-07-03T18:01:58.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00175-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51738, partition values: [empty row]
[2025-07-03T18:01:58.235+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.236+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00093-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51630, partition values: [empty row]
[2025-07-03T18:01:58.237+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00099-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51626, partition values: [empty row]
[2025-07-03T18:01:58.239+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.243+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 5.0 in stage 2.0 (TID 7). 277160 bytes result sent to driver
[2025-07-03T18:01:58.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 10881 bytes)
[2025-07-03T18:01:58.246+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 78 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:01:58.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 6.0 in stage 2.0 (TID 8)
[2025-07-03T18:01:58.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00011-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51506, partition values: [empty row]
[2025-07-03T18:01:58.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00170-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51479, partition values: [empty row]
[2025-07-03T18:01:58.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00013-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51405, partition values: [empty row]
[2025-07-03T18:01:58.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00059-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51381, partition values: [empty row]
[2025-07-03T18:01:58.254+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00064-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51360, partition values: [empty row]
[2025-07-03T18:01:58.257+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.257+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00161-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51349, partition values: [empty row]
[2025-07-03T18:01:58.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.260+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00069-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51017, partition values: [empty row]
[2025-07-03T18:01:58.261+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00079-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-50801, partition values: [empty row]
[2025-07-03T18:01:58.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.265+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 6.0 in stage 2.0 (TID 8). 68589 bytes result sent to driver
[2025-07-03T18:01:58.265+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 22 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:01:58.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-03T18:01:58.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.775 s
[2025-07-03T18:01:58.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:01:58.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-07-03T18:01:58.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.778278 s
[2025-07-03T18:01:58.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO CodeGenerator: Code generated in 16.102583 ms
[2025-07-03T18:01:58.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 39b5ac792cf9:37901 in memory (size: 6.3 KiB, free: 434.4 MiB)
[2025-07-03T18:01:58.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.0 MiB, free 418.2 MiB)
[2025-07-03T18:01:58.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 414.2 MiB)
[2025-07-03T18:01:58.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 39b5ac792cf9:37901 (size: 4.0 MiB, free: 430.4 MiB)
[2025-07-03T18:01:58.398+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO MemoryStore: Block broadcast_4_piece1 stored as bytes in memory (estimated size 543.4 KiB, free 413.6 MiB)
[2025-07-03T18:01:58.398+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO BlockManagerInfo: Added broadcast_4_piece1 in memory on 39b5ac792cf9:37901 (size: 543.4 KiB, free: 429.8 MiB)
[2025-07-03T18:01:58.399+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:01:58.427+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO CodeGenerator: Code generated in 21.339875 ms
[2025-07-03T18:01:58.430+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 201.3 KiB, free 413.4 MiB)
[2025-07-03T18:01:58.431+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 413.4 MiB)
[2025-07-03T18:01:58.431+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 39b5ac792cf9:37901 (size: 35.0 KiB, free: 429.8 MiB)
[2025-07-03T18:01:58.433+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
[2025-07-03T18:01:58.433+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:01:58.458+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-07-03T18:01:58.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Registering RDD 11 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-07-03T18:01:58.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-03T18:01:58.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Final stage: ResultStage 4 (count at NativeMethodAccessorImpl.java:0)
[2025-07-03T18:01:58.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
[2025-07-03T18:01:58.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
[2025-07-03T18:01:58.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:01:58.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.8 KiB, free 413.4 MiB)
[2025-07-03T18:01:58.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 413.4 MiB)
[2025-07-03T18:01:58.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 39b5ac792cf9:37901 (size: 8.8 KiB, free: 429.8 MiB)
[2025-07-03T18:01:58.468+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:01:58.468+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:01:58.468+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSchedulerImpl: Adding task set 3.0 with 7 tasks resource profile 0
[2025-07-03T18:01:58.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 9) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:01:58.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 0.0 in stage 3.0 (TID 9)
[2025-07-03T18:01:58.488+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO CodeGenerator: Code generated in 10.583 ms
[2025-07-03T18:01:58.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00068-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-168362, partition values: [empty row]
[2025-07-03T18:01:58.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.501+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00196-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-163710, partition values: [empty row]
[2025-07-03T18:01:58.504+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.505+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00029-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157967, partition values: [empty row]
[2025-07-03T18:01:58.509+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.511+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00198-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157920, partition values: [empty row]
[2025-07-03T18:01:58.512+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00128-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157850, partition values: [empty row]
[2025-07-03T18:01:58.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.517+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00120-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157700, partition values: [empty row]
[2025-07-03T18:01:58.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00102-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157204, partition values: [empty row]
[2025-07-03T18:01:58.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.525+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00053-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156699, partition values: [empty row]
[2025-07-03T18:01:58.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.530+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00147-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156146, partition values: [empty row]
[2025-07-03T18:01:58.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00087-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-155444, partition values: [empty row]
[2025-07-03T18:01:58.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.538+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00140-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-154024, partition values: [empty row]
[2025-07-03T18:01:58.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00095-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153497, partition values: [empty row]
[2025-07-03T18:01:58.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00079-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153486, partition values: [empty row]
[2025-07-03T18:01:58.547+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.549+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00130-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153363, partition values: [empty row]
[2025-07-03T18:01:58.551+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.552+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00172-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153223, partition values: [empty row]
[2025-07-03T18:01:58.553+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00049-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152868, partition values: [empty row]
[2025-07-03T18:01:58.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00031-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152746, partition values: [empty row]
[2025-07-03T18:01:58.560+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00133-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152572, partition values: [empty row]
[2025-07-03T18:01:58.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00038-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152480, partition values: [empty row]
[2025-07-03T18:01:58.568+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00097-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152347, partition values: [empty row]
[2025-07-03T18:01:58.575+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00178-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152161, partition values: [empty row]
[2025-07-03T18:01:58.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00027-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152149, partition values: [empty row]
[2025-07-03T18:01:58.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00045-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151971, partition values: [empty row]
[2025-07-03T18:01:58.589+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00135-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151699, partition values: [empty row]
[2025-07-03T18:01:58.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.595+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00187-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151670, partition values: [empty row]
[2025-07-03T18:01:58.597+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.599+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00083-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151205, partition values: [empty row]
[2025-07-03T18:01:58.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.604+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00034-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150976, partition values: [empty row]
[2025-07-03T18:01:58.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00111-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150838, partition values: [empty row]
[2025-07-03T18:01:58.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00142-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150787, partition values: [empty row]
[2025-07-03T18:01:58.613+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00011-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150662, partition values: [empty row]
[2025-07-03T18:01:58.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00030-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150182, partition values: [empty row]
[2025-07-03T18:01:58.621+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 0.0 in stage 3.0 (TID 9). 2291 bytes result sent to driver
[2025-07-03T18:01:58.634+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 10) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:01:58.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 1.0 in stage 3.0 (TID 10)
[2025-07-03T18:01:58.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 165 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:01:58.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00108-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150170, partition values: [empty row]
[2025-07-03T18:01:58.639+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.641+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00188-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150141, partition values: [empty row]
[2025-07-03T18:01:58.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.644+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00092-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150033, partition values: [empty row]
[2025-07-03T18:01:58.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00132-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149955, partition values: [empty row]
[2025-07-03T18:01:58.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00162-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149789, partition values: [empty row]
[2025-07-03T18:01:58.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.654+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00112-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149402, partition values: [empty row]
[2025-07-03T18:01:58.657+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.658+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00146-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149158, partition values: [empty row]
[2025-07-03T18:01:58.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00039-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149155, partition values: [empty row]
[2025-07-03T18:01:58.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00164-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149052, partition values: [empty row]
[2025-07-03T18:01:58.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00123-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148925, partition values: [empty row]
[2025-07-03T18:01:58.670+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.672+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00041-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148678, partition values: [empty row]
[2025-07-03T18:01:58.674+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00105-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148248, partition values: [empty row]
[2025-07-03T18:01:58.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.679+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00020-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147953, partition values: [empty row]
[2025-07-03T18:01:58.681+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00072-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147680, partition values: [empty row]
[2025-07-03T18:01:58.685+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.688+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00184-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147353, partition values: [empty row]
[2025-07-03T18:01:58.690+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.691+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00119-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147307, partition values: [empty row]
[2025-07-03T18:01:58.693+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.694+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00160-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147088, partition values: [empty row]
[2025-07-03T18:01:58.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.697+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00089-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146834, partition values: [empty row]
[2025-07-03T18:01:58.699+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00055-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146628, partition values: [empty row]
[2025-07-03T18:01:58.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.705+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00107-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146573, partition values: [empty row]
[2025-07-03T18:01:58.707+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00050-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146529, partition values: [empty row]
[2025-07-03T18:01:58.710+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.711+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00073-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146322, partition values: [empty row]
[2025-07-03T18:01:58.713+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00182-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146085, partition values: [empty row]
[2025-07-03T18:01:58.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00124-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145923, partition values: [empty row]
[2025-07-03T18:01:58.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00037-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145736, partition values: [empty row]
[2025-07-03T18:01:58.725+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.728+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00032-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145483, partition values: [empty row]
[2025-07-03T18:01:58.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.731+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00044-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145472, partition values: [empty row]
[2025-07-03T18:01:58.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00137-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145459, partition values: [empty row]
[2025-07-03T18:01:58.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.738+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00009-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145443, partition values: [empty row]
[2025-07-03T18:01:58.740+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00067-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145348, partition values: [empty row]
[2025-07-03T18:01:58.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00139-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145180, partition values: [empty row]
[2025-07-03T18:01:58.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.758+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 1.0 in stage 3.0 (TID 10). 2291 bytes result sent to driver
[2025-07-03T18:01:58.759+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 11) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:01:58.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 10) in 126 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:01:58.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 2.0 in stage 3.0 (TID 11)
[2025-07-03T18:01:58.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00114-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145175, partition values: [empty row]
[2025-07-03T18:01:58.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.765+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00154-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144764, partition values: [empty row]
[2025-07-03T18:01:58.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00115-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144653, partition values: [empty row]
[2025-07-03T18:01:58.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00062-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144636, partition values: [empty row]
[2025-07-03T18:01:58.774+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.776+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00177-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144534, partition values: [empty row]
[2025-07-03T18:01:58.778+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00131-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144411, partition values: [empty row]
[2025-07-03T18:01:58.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00003-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144247, partition values: [empty row]
[2025-07-03T18:01:58.785+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.787+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00159-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144214, partition values: [empty row]
[2025-07-03T18:01:58.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.791+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00081-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144124, partition values: [empty row]
[2025-07-03T18:01:58.793+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.797+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00173-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143839, partition values: [empty row]
[2025-07-03T18:01:58.798+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00145-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143692, partition values: [empty row]
[2025-07-03T18:01:58.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00100-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143512, partition values: [empty row]
[2025-07-03T18:01:58.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00110-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143491, partition values: [empty row]
[2025-07-03T18:01:58.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.808+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00167-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143463, partition values: [empty row]
[2025-07-03T18:01:58.809+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.810+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00082-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143421, partition values: [empty row]
[2025-07-03T18:01:58.812+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.814+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00103-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143305, partition values: [empty row]
[2025-07-03T18:01:58.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.817+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00094-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143260, partition values: [empty row]
[2025-07-03T18:01:58.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.819+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00192-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143248, partition values: [empty row]
[2025-07-03T18:01:58.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00153-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142738, partition values: [empty row]
[2025-07-03T18:01:58.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.825+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00028-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142579, partition values: [empty row]
[2025-07-03T18:01:58.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00109-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142500, partition values: [empty row]
[2025-07-03T18:01:58.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.833+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00007-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142453, partition values: [empty row]
[2025-07-03T18:01:58.836+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00197-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142400, partition values: [empty row]
[2025-07-03T18:01:58.840+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.842+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00048-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142344, partition values: [empty row]
[2025-07-03T18:01:58.845+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00024-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142324, partition values: [empty row]
[2025-07-03T18:01:58.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00113-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142107, partition values: [empty row]
[2025-07-03T18:01:58.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00179-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141811, partition values: [empty row]
[2025-07-03T18:01:58.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00194-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141737, partition values: [empty row]
[2025-07-03T18:01:58.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.863+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00022-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141733, partition values: [empty row]
[2025-07-03T18:01:58.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00006-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141716, partition values: [empty row]
[2025-07-03T18:01:58.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00057-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141276, partition values: [empty row]
[2025-07-03T18:01:58.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.877+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 2.0 in stage 3.0 (TID 11). 2291 bytes result sent to driver
[2025-07-03T18:01:58.878+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 12) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:01:58.878+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 11) in 119 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:01:58.879+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 3.0 in stage 3.0 (TID 12)
[2025-07-03T18:01:58.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00180-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141220, partition values: [empty row]
[2025-07-03T18:01:58.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00181-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141147, partition values: [empty row]
[2025-07-03T18:01:58.884+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00134-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141133, partition values: [empty row]
[2025-07-03T18:01:58.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00174-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141104, partition values: [empty row]
[2025-07-03T18:01:58.889+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.890+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00054-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141050, partition values: [empty row]
[2025-07-03T18:01:58.892+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00085-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140960, partition values: [empty row]
[2025-07-03T18:01:58.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00122-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140951, partition values: [empty row]
[2025-07-03T18:01:58.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00064-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140895, partition values: [empty row]
[2025-07-03T18:01:58.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00080-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140405, partition values: [empty row]
[2025-07-03T18:01:58.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.910+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00071-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140133, partition values: [empty row]
[2025-07-03T18:01:58.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00118-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140113, partition values: [empty row]
[2025-07-03T18:01:58.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00136-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140097, partition values: [empty row]
[2025-07-03T18:01:58.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00056-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140011, partition values: [empty row]
[2025-07-03T18:01:58.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.925+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00016-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139898, partition values: [empty row]
[2025-07-03T18:01:58.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00121-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139858, partition values: [empty row]
[2025-07-03T18:01:58.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00018-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139827, partition values: [empty row]
[2025-07-03T18:01:58.933+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00002-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139804, partition values: [empty row]
[2025-07-03T18:01:58.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00052-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139763, partition values: [empty row]
[2025-07-03T18:01:58.940+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00152-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139683, partition values: [empty row]
[2025-07-03T18:01:58.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00170-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139630, partition values: [empty row]
[2025-07-03T18:01:58.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00183-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139299, partition values: [empty row]
[2025-07-03T18:01:58.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.948+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00025-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139114, partition values: [empty row]
[2025-07-03T18:01:58.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00026-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138875, partition values: [empty row]
[2025-07-03T18:01:58.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00070-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138619, partition values: [empty row]
[2025-07-03T18:01:58.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00117-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138472, partition values: [empty row]
[2025-07-03T18:01:58.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00148-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138343, partition values: [empty row]
[2025-07-03T18:01:58.962+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00151-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138303, partition values: [empty row]
[2025-07-03T18:01:58.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00190-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137980, partition values: [empty row]
[2025-07-03T18:01:58.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00116-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137825, partition values: [empty row]
[2025-07-03T18:01:58.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00046-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137502, partition values: [empty row]
[2025-07-03T18:01:58.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00063-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137399, partition values: [empty row]
[2025-07-03T18:01:58.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Finished task 3.0 in stage 3.0 (TID 12). 2291 bytes result sent to driver
[2025-07-03T18:01:58.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 13) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:01:58.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 12) in 103 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:01:58.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO Executor: Running task 4.0 in stage 3.0 (TID 13)
[2025-07-03T18:01:58.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00143-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137169, partition values: [empty row]
[2025-07-03T18:01:58.984+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00047-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137073, partition values: [empty row]
[2025-07-03T18:01:58.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00084-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136997, partition values: [empty row]
[2025-07-03T18:01:58.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00156-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136937, partition values: [empty row]
[2025-07-03T18:01:58.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.994+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00193-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136790, partition values: [empty row]
[2025-07-03T18:01:58.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:58.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:58 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00042-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136602, partition values: [empty row]
[2025-07-03T18:01:59.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00088-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136524, partition values: [empty row]
[2025-07-03T18:01:59.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00191-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136091, partition values: [empty row]
[2025-07-03T18:01:59.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00019-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136064, partition values: [empty row]
[2025-07-03T18:01:59.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.012+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00127-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135998, partition values: [empty row]
[2025-07-03T18:01:59.014+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00199-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135968, partition values: [empty row]
[2025-07-03T18:01:59.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00013-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135936, partition values: [empty row]
[2025-07-03T18:01:59.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00144-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135783, partition values: [empty row]
[2025-07-03T18:01:59.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00101-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135779, partition values: [empty row]
[2025-07-03T18:01:59.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00171-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135629, partition values: [empty row]
[2025-07-03T18:01:59.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00166-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135568, partition values: [empty row]
[2025-07-03T18:01:59.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00165-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135539, partition values: [empty row]
[2025-07-03T18:01:59.032+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.033+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00060-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135477, partition values: [empty row]
[2025-07-03T18:01:59.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00004-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135462, partition values: [empty row]
[2025-07-03T18:01:59.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00010-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135408, partition values: [empty row]
[2025-07-03T18:01:59.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.045+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00040-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135398, partition values: [empty row]
[2025-07-03T18:01:59.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.049+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00033-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135395, partition values: [empty row]
[2025-07-03T18:01:59.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00021-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135250, partition values: [empty row]
[2025-07-03T18:01:59.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.057+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00023-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135210, partition values: [empty row]
[2025-07-03T18:01:59.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.061+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00185-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135190, partition values: [empty row]
[2025-07-03T18:01:59.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00061-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134981, partition values: [empty row]
[2025-07-03T18:01:59.067+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.068+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00001-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134944, partition values: [empty row]
[2025-07-03T18:01:59.070+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.072+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00189-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134929, partition values: [empty row]
[2025-07-03T18:01:59.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00091-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134926, partition values: [empty row]
[2025-07-03T18:01:59.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00161-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134806, partition values: [empty row]
[2025-07-03T18:01:59.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00012-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134703, partition values: [empty row]
[2025-07-03T18:01:59.082+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 4.0 in stage 3.0 (TID 13). 2291 bytes result sent to driver
[2025-07-03T18:01:59.086+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 14) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:01:59.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 5.0 in stage 3.0 (TID 14)
[2025-07-03T18:01:59.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 13) in 106 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:01:59.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00014-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134651, partition values: [empty row]
[2025-07-03T18:01:59.091+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.092+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00075-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134649, partition values: [empty row]
[2025-07-03T18:01:59.094+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.097+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00168-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134557, partition values: [empty row]
[2025-07-03T18:01:59.099+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.099+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00176-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134495, partition values: [empty row]
[2025-07-03T18:01:59.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00157-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134432, partition values: [empty row]
[2025-07-03T18:01:59.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00069-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134344, partition values: [empty row]
[2025-07-03T18:01:59.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00051-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134093, partition values: [empty row]
[2025-07-03T18:01:59.110+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.111+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00035-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133957, partition values: [empty row]
[2025-07-03T18:01:59.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00175-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133736, partition values: [empty row]
[2025-07-03T18:01:59.117+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00058-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133517, partition values: [empty row]
[2025-07-03T18:01:59.120+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.122+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00008-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133312, partition values: [empty row]
[2025-07-03T18:01:59.124+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.125+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00036-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133250, partition values: [empty row]
[2025-07-03T18:01:59.127+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00017-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133244, partition values: [empty row]
[2025-07-03T18:01:59.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00195-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133115, partition values: [empty row]
[2025-07-03T18:01:59.134+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00086-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132787, partition values: [empty row]
[2025-07-03T18:01:59.137+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.139+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00106-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132496, partition values: [empty row]
[2025-07-03T18:01:59.141+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.143+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00149-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132477, partition values: [empty row]
[2025-07-03T18:01:59.146+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00126-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132427, partition values: [empty row]
[2025-07-03T18:01:59.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00099-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132405, partition values: [empty row]
[2025-07-03T18:01:59.155+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00186-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132164, partition values: [empty row]
[2025-07-03T18:01:59.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.160+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00093-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131331, partition values: [empty row]
[2025-07-03T18:01:59.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.164+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00074-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131260, partition values: [empty row]
[2025-07-03T18:01:59.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.168+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00078-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130578, partition values: [empty row]
[2025-07-03T18:01:59.169+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00141-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130266, partition values: [empty row]
[2025-07-03T18:01:59.173+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.174+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00005-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130222, partition values: [empty row]
[2025-07-03T18:01:59.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00065-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130083, partition values: [empty row]
[2025-07-03T18:01:59.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00125-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130011, partition values: [empty row]
[2025-07-03T18:01:59.183+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00077-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129832, partition values: [empty row]
[2025-07-03T18:01:59.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.187+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00169-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129566, partition values: [empty row]
[2025-07-03T18:01:59.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00150-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129448, partition values: [empty row]
[2025-07-03T18:01:59.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00163-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129300, partition values: [empty row]
[2025-07-03T18:01:59.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 5.0 in stage 3.0 (TID 14). 2291 bytes result sent to driver
[2025-07-03T18:01:59.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 15) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 11762 bytes)
[2025-07-03T18:01:59.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 6.0 in stage 3.0 (TID 15)
[2025-07-03T18:01:59.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 14) in 111 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:01:59.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00129-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129243, partition values: [empty row]
[2025-07-03T18:01:59.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00155-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128963, partition values: [empty row]
[2025-07-03T18:01:59.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00076-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128747, partition values: [empty row]
[2025-07-03T18:01:59.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00098-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128595, partition values: [empty row]
[2025-07-03T18:01:59.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00066-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128097, partition values: [empty row]
[2025-07-03T18:01:59.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00090-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-127202, partition values: [empty row]
[2025-07-03T18:01:59.219+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.219+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00138-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-126507, partition values: [empty row]
[2025-07-03T18:01:59.221+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.222+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00043-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125123, partition values: [empty row]
[2025-07-03T18:01:59.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00158-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125003, partition values: [empty row]
[2025-07-03T18:01:59.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00059-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123983, partition values: [empty row]
[2025-07-03T18:01:59.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.231+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00104-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123468, partition values: [empty row]
[2025-07-03T18:01:59.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00000-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123063, partition values: [empty row]
[2025-07-03T18:01:59.234+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.235+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00015-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-122798, partition values: [empty row]
[2025-07-03T18:01:59.237+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.239+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00096-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-118888, partition values: [empty row]
[2025-07-03T18:01:59.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.243+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 6.0 in stage 3.0 (TID 15). 2291 bytes result sent to driver
[2025-07-03T18:01:59.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 15) in 47 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:01:59.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-03T18:01:59.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.781 s
[2025-07-03T18:01:59.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: looking for newly runnable stages
[2025-07-03T18:01:59.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: running: Set()
[2025-07-03T18:01:59.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: waiting: Set(ResultStage 4)
[2025-07-03T18:01:59.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: failed: Set()
[2025-07-03T18:01:59.246+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:01:59.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.5 KiB, free 413.4 MiB)
[2025-07-03T18:01:59.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 413.4 MiB)
[2025-07-03T18:01:59.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 39b5ac792cf9:37901 (size: 5.9 KiB, free: 429.8 MiB)
[2025-07-03T18:01:59.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:01:59.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-03T18:01:59.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-03T18:01:59.253+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 16) (39b5ac792cf9, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:01:59.253+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 0.0 in stage 4.0 (TID 16)
[2025-07-03T18:01:59.265+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO ShuffleBlockFetcherIterator: Getting 7 (420.0 B) non-empty blocks including 7 (420.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:01:59.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-03T18:01:59.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO CodeGenerator: Code generated in 7.455875 ms
[2025-07-03T18:01:59.279+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 0.0 in stage 4.0 (TID 16). 3995 bytes result sent to driver
[2025-07-03T18:01:59.280+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 16) in 28 ms on 39b5ac792cf9 (executor driver) (1/1)
[2025-07-03T18:01:59.280+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-03T18:01:59.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: ResultStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.032 s
[2025-07-03T18:01:59.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:01:59.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-07-03T18:01:59.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.823041 s
[2025-07-03T18:01:59.282+0000] {spark_submit.py:579} INFO - Joined records: 315619
[2025-07-03T18:01:59.389+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:01:59.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#0)
[2025-07-03T18:01:59.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:01:59.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#27)
[2025-07-03T18:01:59.444+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:01:59.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:01:59.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:01:59.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:01:59.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:01:59.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:01:59.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:01:59.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-07-03T18:01:59.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 39b5ac792cf9:37901 in memory (size: 8.8 KiB, free: 429.8 MiB)
[2025-07-03T18:01:59.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 39b5ac792cf9:37901 in memory (size: 5.9 KiB, free: 429.8 MiB)
[2025-07-03T18:01:59.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO CodeGenerator: Code generated in 30.975708 ms
[2025-07-03T18:01:59.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 201.5 KiB, free 413.2 MiB)
[2025-07-03T18:01:59.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 413.2 MiB)
[2025-07-03T18:01:59.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 39b5ac792cf9:37901 (size: 35.1 KiB, free: 429.8 MiB)
[2025-07-03T18:01:59.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO SparkContext: Created broadcast 8 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:01:59.524+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:01:59.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO CodeGenerator: Code generated in 24.372458 ms
[2025-07-03T18:01:59.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:01:59.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 7 output partitions
[2025-07-03T18:01:59.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-03T18:01:59.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Parents of final stage: List()
[2025-07-03T18:01:59.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Missing parents: List()
[2025-07-03T18:01:59.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-03T18:01:59.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.6 KiB, free 413.2 MiB)
[2025-07-03T18:01:59.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 413.2 MiB)
[2025-07-03T18:01:59.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 39b5ac792cf9:37901 (size: 6.6 KiB, free: 429.8 MiB)
[2025-07-03T18:01:59.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:01:59.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:01:59.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSchedulerImpl: Adding task set 5.0 with 7 tasks resource profile 0
[2025-07-03T18:01:59.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 17) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:59.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 0.0 in stage 5.0 (TID 17)
[2025-07-03T18:01:59.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO CodeGenerator: Code generated in 6.174125 ms
[2025-07-03T18:01:59.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00130-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57587, partition values: [empty row]
[2025-07-03T18:01:59.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00029-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57404, partition values: [empty row]
[2025-07-03T18:01:59.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.566+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00025-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56716, partition values: [empty row]
[2025-07-03T18:01:59.568+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00094-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56382, partition values: [empty row]
[2025-07-03T18:01:59.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00051-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56298, partition values: [empty row]
[2025-07-03T18:01:59.576+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00076-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56236, partition values: [empty row]
[2025-07-03T18:01:59.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.592+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00193-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56152, partition values: [empty row]
[2025-07-03T18:01:59.595+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00159-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56131, partition values: [empty row]
[2025-07-03T18:01:59.600+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00040-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56041, partition values: [empty row]
[2025-07-03T18:01:59.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.605+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00172-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55935, partition values: [empty row]
[2025-07-03T18:01:59.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00101-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55751, partition values: [empty row]
[2025-07-03T18:01:59.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00103-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55611, partition values: [empty row]
[2025-07-03T18:01:59.613+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00189-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55606, partition values: [empty row]
[2025-07-03T18:01:59.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00127-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55599, partition values: [empty row]
[2025-07-03T18:01:59.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.621+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00063-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55563, partition values: [empty row]
[2025-07-03T18:01:59.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00095-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55516, partition values: [empty row]
[2025-07-03T18:01:59.625+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.627+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00173-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55432, partition values: [empty row]
[2025-07-03T18:01:59.629+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.630+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00188-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55276, partition values: [empty row]
[2025-07-03T18:01:59.631+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00125-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55207, partition values: [empty row]
[2025-07-03T18:01:59.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00154-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55088, partition values: [empty row]
[2025-07-03T18:01:59.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00010-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55072, partition values: [empty row]
[2025-07-03T18:01:59.638+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.638+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00005-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55055, partition values: [empty row]
[2025-07-03T18:01:59.639+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.640+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00000-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55054, partition values: [empty row]
[2025-07-03T18:01:59.641+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.642+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00098-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55020, partition values: [empty row]
[2025-07-03T18:01:59.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.644+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00168-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54965, partition values: [empty row]
[2025-07-03T18:01:59.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00074-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54962, partition values: [empty row]
[2025-07-03T18:01:59.647+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00108-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54960, partition values: [empty row]
[2025-07-03T18:01:59.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00004-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54956, partition values: [empty row]
[2025-07-03T18:01:59.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.652+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00139-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54954, partition values: [empty row]
[2025-07-03T18:01:59.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.654+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00182-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54952, partition values: [empty row]
[2025-07-03T18:01:59.655+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.656+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00122-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54947, partition values: [empty row]
[2025-07-03T18:01:59.658+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00018-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54918, partition values: [empty row]
[2025-07-03T18:01:59.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 0.0 in stage 5.0 (TID 17). 742770 bytes result sent to driver
[2025-07-03T18:01:59.665+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 18) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:59.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 17) in 124 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:01:59.668+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 1.0 in stage 5.0 (TID 18)
[2025-07-03T18:01:59.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00057-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54867, partition values: [empty row]
[2025-07-03T18:01:59.670+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.672+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00023-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54835, partition values: [empty row]
[2025-07-03T18:01:59.674+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00143-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54795, partition values: [empty row]
[2025-07-03T18:01:59.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00158-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54737, partition values: [empty row]
[2025-07-03T18:01:59.679+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.680+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00116-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54723, partition values: [empty row]
[2025-07-03T18:01:59.681+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00042-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54716, partition values: [empty row]
[2025-07-03T18:01:59.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.686+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00083-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:01:59.688+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.689+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00119-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:01:59.690+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.691+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00141-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54669, partition values: [empty row]
[2025-07-03T18:01:59.693+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.694+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00186-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54659, partition values: [empty row]
[2025-07-03T18:01:59.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00045-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54586, partition values: [empty row]
[2025-07-03T18:01:59.698+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.699+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00155-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54571, partition values: [empty row]
[2025-07-03T18:01:59.700+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00162-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54563, partition values: [empty row]
[2025-07-03T18:01:59.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.704+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00144-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54516, partition values: [empty row]
[2025-07-03T18:01:59.706+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.707+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00087-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54501, partition values: [empty row]
[2025-07-03T18:01:59.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.709+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00009-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54492, partition values: [empty row]
[2025-07-03T18:01:59.711+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00100-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54461, partition values: [empty row]
[2025-07-03T18:01:59.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.715+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00032-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54441, partition values: [empty row]
[2025-07-03T18:01:59.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.717+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00176-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54386, partition values: [empty row]
[2025-07-03T18:01:59.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00003-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54385, partition values: [empty row]
[2025-07-03T18:01:59.720+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00058-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54354, partition values: [empty row]
[2025-07-03T18:01:59.723+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00111-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54349, partition values: [empty row]
[2025-07-03T18:01:59.725+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.726+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00147-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54288, partition values: [empty row]
[2025-07-03T18:01:59.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.728+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00091-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54283, partition values: [empty row]
[2025-07-03T18:01:59.729+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00107-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54279, partition values: [empty row]
[2025-07-03T18:01:59.731+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00024-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54230, partition values: [empty row]
[2025-07-03T18:01:59.733+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00038-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54190, partition values: [empty row]
[2025-07-03T18:01:59.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00191-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54144, partition values: [empty row]
[2025-07-03T18:01:59.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00120-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54132, partition values: [empty row]
[2025-07-03T18:01:59.738+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.739+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00194-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54131, partition values: [empty row]
[2025-07-03T18:01:59.740+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.740+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00035-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54124, partition values: [empty row]
[2025-07-03T18:01:59.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00110-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54080, partition values: [empty row]
[2025-07-03T18:01:59.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.745+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 1.0 in stage 5.0 (TID 18). 722316 bytes result sent to driver
[2025-07-03T18:01:59.745+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 19) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:59.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 2.0 in stage 5.0 (TID 19)
[2025-07-03T18:01:59.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 18) in 81 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:01:59.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00021-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54070, partition values: [empty row]
[2025-07-03T18:01:59.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.749+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00114-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54048, partition values: [empty row]
[2025-07-03T18:01:59.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00150-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54032, partition values: [empty row]
[2025-07-03T18:01:59.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00169-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54022, partition values: [empty row]
[2025-07-03T18:01:59.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00082-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54019, partition values: [empty row]
[2025-07-03T18:01:59.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.757+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00043-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53970, partition values: [empty row]
[2025-07-03T18:01:59.758+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.759+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00015-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53950, partition values: [empty row]
[2025-07-03T18:01:59.760+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00164-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53947, partition values: [empty row]
[2025-07-03T18:01:59.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00152-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53936, partition values: [empty row]
[2025-07-03T18:01:59.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00197-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53935, partition values: [empty row]
[2025-07-03T18:01:59.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00160-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53924, partition values: [empty row]
[2025-07-03T18:01:59.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00002-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53904, partition values: [empty row]
[2025-07-03T18:01:59.774+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.775+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00165-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53870, partition values: [empty row]
[2025-07-03T18:01:59.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.778+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00078-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53867, partition values: [empty row]
[2025-07-03T18:01:59.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.780+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00145-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53865, partition values: [empty row]
[2025-07-03T18:01:59.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00153-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53863, partition values: [empty row]
[2025-07-03T18:01:59.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.785+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00047-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53839, partition values: [empty row]
[2025-07-03T18:01:59.788+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00077-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53831, partition values: [empty row]
[2025-07-03T18:01:59.791+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.792+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00131-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53770, partition values: [empty row]
[2025-07-03T18:01:59.793+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.794+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00028-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:01:59.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00022-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:01:59.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.797+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00126-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53726, partition values: [empty row]
[2025-07-03T18:01:59.798+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00148-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53681, partition values: [empty row]
[2025-07-03T18:01:59.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00179-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53662, partition values: [empty row]
[2025-07-03T18:01:59.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00034-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53650, partition values: [empty row]
[2025-07-03T18:01:59.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00171-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53632, partition values: [empty row]
[2025-07-03T18:01:59.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00137-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53624, partition values: [empty row]
[2025-07-03T18:01:59.808+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.809+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00086-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53620, partition values: [empty row]
[2025-07-03T18:01:59.809+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.810+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00014-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53616, partition values: [empty row]
[2025-07-03T18:01:59.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00073-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53614, partition values: [empty row]
[2025-07-03T18:01:59.812+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.813+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00105-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53604, partition values: [empty row]
[2025-07-03T18:01:59.814+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.814+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00199-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53602, partition values: [empty row]
[2025-07-03T18:01:59.815+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.817+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 2.0 in stage 5.0 (TID 19). 713806 bytes result sent to driver
[2025-07-03T18:01:59.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 20) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:59.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 3.0 in stage 5.0 (TID 20)
[2025-07-03T18:01:59.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 19) in 73 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:01:59.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00044-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53598, partition values: [empty row]
[2025-07-03T18:01:59.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00146-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53596, partition values: [empty row]
[2025-07-03T18:01:59.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00016-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53586, partition values: [empty row]
[2025-07-03T18:01:59.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.825+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00070-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53575, partition values: [empty row]
[2025-07-03T18:01:59.826+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.826+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00037-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53559, partition values: [empty row]
[2025-07-03T18:01:59.827+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00001-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53526, partition values: [empty row]
[2025-07-03T18:01:59.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00080-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53515, partition values: [empty row]
[2025-07-03T18:01:59.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00056-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53508, partition values: [empty row]
[2025-07-03T18:01:59.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.833+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00117-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53501, partition values: [empty row]
[2025-07-03T18:01:59.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00187-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53499, partition values: [empty row]
[2025-07-03T18:01:59.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.836+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00007-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53477, partition values: [empty row]
[2025-07-03T18:01:59.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00006-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53475, partition values: [empty row]
[2025-07-03T18:01:59.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.840+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00039-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53453, partition values: [empty row]
[2025-07-03T18:01:59.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00174-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53442, partition values: [empty row]
[2025-07-03T18:01:59.847+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.848+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00113-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53440, partition values: [empty row]
[2025-07-03T18:01:59.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00106-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53430, partition values: [empty row]
[2025-07-03T18:01:59.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.853+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00163-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53416, partition values: [empty row]
[2025-07-03T18:01:59.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00121-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53400, partition values: [empty row]
[2025-07-03T18:01:59.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00177-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53349, partition values: [empty row]
[2025-07-03T18:01:59.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00128-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53335, partition values: [empty row]
[2025-07-03T18:01:59.860+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.860+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00118-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53325, partition values: [empty row]
[2025-07-03T18:01:59.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.863+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00132-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53320, partition values: [empty row]
[2025-07-03T18:01:59.864+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00140-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53318, partition values: [empty row]
[2025-07-03T18:01:59.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.867+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00135-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53317, partition values: [empty row]
[2025-07-03T18:01:59.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00124-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53308, partition values: [empty row]
[2025-07-03T18:01:59.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00096-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53302, partition values: [empty row]
[2025-07-03T18:01:59.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00183-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53295, partition values: [empty row]
[2025-07-03T18:01:59.874+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.876+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00134-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53289, partition values: [empty row]
[2025-07-03T18:01:59.877+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.878+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00151-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53288, partition values: [empty row]
[2025-07-03T18:01:59.878+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.879+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00067-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53279, partition values: [empty row]
[2025-07-03T18:01:59.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00053-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53278, partition values: [empty row]
[2025-07-03T18:01:59.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00129-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:01:59.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 3.0 in stage 5.0 (TID 20). 709160 bytes result sent to driver
[2025-07-03T18:01:59.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 21) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:59.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 20) in 69 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:01:59.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 4.0 in stage 5.0 (TID 21)
[2025-07-03T18:01:59.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00019-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:01:59.889+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.890+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00198-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53274, partition values: [empty row]
[2025-07-03T18:01:59.891+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.892+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00046-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53272, partition values: [empty row]
[2025-07-03T18:01:59.893+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00065-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53261, partition values: [empty row]
[2025-07-03T18:01:59.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00052-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53240, partition values: [empty row]
[2025-07-03T18:01:59.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00190-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:01:59.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.899+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00196-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:01:59.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00157-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53211, partition values: [empty row]
[2025-07-03T18:01:59.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00048-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:01:59.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00185-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:01:59.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00020-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53155, partition values: [empty row]
[2025-07-03T18:01:59.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.906+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00180-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53145, partition values: [empty row]
[2025-07-03T18:01:59.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00178-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53134, partition values: [empty row]
[2025-07-03T18:01:59.908+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.909+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00104-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53119, partition values: [empty row]
[2025-07-03T18:01:59.909+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.910+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00138-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53103, partition values: [empty row]
[2025-07-03T18:01:59.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00085-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53097, partition values: [empty row]
[2025-07-03T18:01:59.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00112-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53073, partition values: [empty row]
[2025-07-03T18:01:59.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00181-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53071, partition values: [empty row]
[2025-07-03T18:01:59.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00075-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53065, partition values: [empty row]
[2025-07-03T18:01:59.917+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00149-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53062, partition values: [empty row]
[2025-07-03T18:01:59.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00012-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53049, partition values: [empty row]
[2025-07-03T18:01:59.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00090-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53047, partition values: [empty row]
[2025-07-03T18:01:59.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00068-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52969, partition values: [empty row]
[2025-07-03T18:01:59.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.924+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00054-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52925, partition values: [empty row]
[2025-07-03T18:01:59.925+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00195-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52882, partition values: [empty row]
[2025-07-03T18:01:59.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00049-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52845, partition values: [empty row]
[2025-07-03T18:01:59.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00092-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52842, partition values: [empty row]
[2025-07-03T18:01:59.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00102-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52835, partition values: [empty row]
[2025-07-03T18:01:59.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.933+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00081-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52833, partition values: [empty row]
[2025-07-03T18:01:59.934+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.934+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00072-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:01:59.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.936+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00142-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:01:59.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00036-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52790, partition values: [empty row]
[2025-07-03T18:01:59.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.940+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Finished task 4.0 in stage 5.0 (TID 21). 702781 bytes result sent to driver
[2025-07-03T18:01:59.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 22) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:01:59.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO Executor: Running task 5.0 in stage 5.0 (TID 22)
[2025-07-03T18:01:59.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 21) in 56 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:01:59.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00109-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52784, partition values: [empty row]
[2025-07-03T18:01:59.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00084-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52779, partition values: [empty row]
[2025-07-03T18:01:59.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00030-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52777, partition values: [empty row]
[2025-07-03T18:01:59.948+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.949+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00156-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52761, partition values: [empty row]
[2025-07-03T18:01:59.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00133-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52743, partition values: [empty row]
[2025-07-03T18:01:59.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00123-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52718, partition values: [empty row]
[2025-07-03T18:01:59.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00184-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52713, partition values: [empty row]
[2025-07-03T18:01:59.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00088-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52688, partition values: [empty row]
[2025-07-03T18:01:59.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00136-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52677, partition values: [empty row]
[2025-07-03T18:01:59.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00033-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52557, partition values: [empty row]
[2025-07-03T18:01:59.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.961+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00167-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52551, partition values: [empty row]
[2025-07-03T18:01:59.962+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00060-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52533, partition values: [empty row]
[2025-07-03T18:01:59.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00192-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52518, partition values: [empty row]
[2025-07-03T18:01:59.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00055-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52503, partition values: [empty row]
[2025-07-03T18:01:59.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00027-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52497, partition values: [empty row]
[2025-07-03T18:01:59.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00066-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52492, partition values: [empty row]
[2025-07-03T18:01:59.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00097-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52439, partition values: [empty row]
[2025-07-03T18:01:59.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.977+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00166-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52417, partition values: [empty row]
[2025-07-03T18:01:59.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00050-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52366, partition values: [empty row]
[2025-07-03T18:01:59.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00071-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52346, partition values: [empty row]
[2025-07-03T18:01:59.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.984+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00008-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52121, partition values: [empty row]
[2025-07-03T18:01:59.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00061-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52118, partition values: [empty row]
[2025-07-03T18:01:59.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00115-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52045, partition values: [empty row]
[2025-07-03T18:01:59.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00041-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51912, partition values: [empty row]
[2025-07-03T18:01:59.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00089-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51902, partition values: [empty row]
[2025-07-03T18:01:59.992+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00026-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51833, partition values: [empty row]
[2025-07-03T18:01:59.994+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00062-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51819, partition values: [empty row]
[2025-07-03T18:01:59.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00031-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51818, partition values: [empty row]
[2025-07-03T18:01:59.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:01:59.998+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00017-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51773, partition values: [empty row]
[2025-07-03T18:01:59.999+0000] {spark_submit.py:579} INFO - 25/07/03 18:01:59 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00175-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51738, partition values: [empty row]
[2025-07-03T18:02:00.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00093-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51630, partition values: [empty row]
[2025-07-03T18:02:00.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00099-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51626, partition values: [empty row]
[2025-07-03T18:02:00.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Finished task 5.0 in stage 5.0 (TID 22). 693371 bytes result sent to driver
[2025-07-03T18:02:00.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 23) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 10881 bytes)
[2025-07-03T18:02:00.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Running task 6.0 in stage 5.0 (TID 23)
[2025-07-03T18:02:00.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 22) in 67 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:02:00.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00011-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51506, partition values: [empty row]
[2025-07-03T18:02:00.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00170-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51479, partition values: [empty row]
[2025-07-03T18:02:00.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.012+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00013-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51405, partition values: [empty row]
[2025-07-03T18:02:00.014+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00059-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51381, partition values: [empty row]
[2025-07-03T18:02:00.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00064-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51360, partition values: [empty row]
[2025-07-03T18:02:00.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00161-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51349, partition values: [empty row]
[2025-07-03T18:02:00.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00069-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51017, partition values: [empty row]
[2025-07-03T18:02:00.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00079-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-50801, partition values: [empty row]
[2025-07-03T18:02:00.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Finished task 6.0 in stage 5.0 (TID 23). 171090 bytes result sent to driver
[2025-07-03T18:02:00.029+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 23) in 21 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:02:00.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-03T18:02:00.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.495 s
[2025-07-03T18:02:00.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:02:00.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-03T18:02:00.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.496738 s
[2025-07-03T18:02:00.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO CodeGenerator: Code generated in 4.724666 ms
[2025-07-03T18:02:00.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 39b5ac792cf9:37901 in memory (size: 6.6 KiB, free: 429.8 MiB)
[2025-07-03T18:02:00.155+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 40.0 MiB, free 373.2 MiB)
[2025-07-03T18:02:00.207+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 39b5ac792cf9:37901 in memory (size: 35.0 KiB, free: 429.8 MiB)
[2025-07-03T18:02:00.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 369.4 MiB)
[2025-07-03T18:02:00.209+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 39b5ac792cf9:37901 (size: 4.0 MiB, free: 425.8 MiB)
[2025-07-03T18:02:00.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO MemoryStore: Block broadcast_10_piece1 stored as bytes in memory (estimated size 3.3 MiB, free 366.1 MiB)
[2025-07-03T18:02:00.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Added broadcast_10_piece1 in memory on 39b5ac792cf9:37901 (size: 3.3 MiB, free: 422.5 MiB)
[2025-07-03T18:02:00.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:02:00.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO CodeGenerator: Code generated in 54.719417 ms
[2025-07-03T18:02:00.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 201.8 KiB, free 365.9 MiB)
[2025-07-03T18:02:00.292+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 39b5ac792cf9:37901 in memory (size: 35.0 KiB, free: 422.5 MiB)
[2025-07-03T18:02:00.293+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 366.1 MiB)
[2025-07-03T18:02:00.293+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 39b5ac792cf9:37901 (size: 35.2 KiB, free: 422.5 MiB)
[2025-07-03T18:02:00.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO SparkContext: Created broadcast 11 from parquet at NativeMethodAccessorImpl.java:0
[2025-07-03T18:02:00.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:02:00.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 39b5ac792cf9:37901 in memory (size: 4.0 MiB, free: 426.5 MiB)
[2025-07-03T18:02:00.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Removed broadcast_4_piece1 on 39b5ac792cf9:37901 in memory (size: 543.4 KiB, free: 427.0 MiB)
[2025-07-03T18:02:00.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-07-03T18:02:00.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Registering RDD 22 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-07-03T18:02:00.335+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 200 output partitions
[2025-07-03T18:02:00.335+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Final stage: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0)
[2025-07-03T18:02:00.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-07-03T18:02:00.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
[2025-07-03T18:02:00.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[22] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:02:00.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 63.4 KiB, free 386.6 MiB)
[2025-07-03T18:02:00.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.9 KiB, free 386.6 MiB)
[2025-07-03T18:02:00.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 39b5ac792cf9:37901 (size: 25.9 KiB, free: 427.0 MiB)
[2025-07-03T18:02:00.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:00.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[22] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:02:00.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSchedulerImpl: Adding task set 6.0 with 7 tasks resource profile 0
[2025-07-03T18:02:00.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 24) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:00.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Running task 0.0 in stage 6.0 (TID 24)
[2025-07-03T18:02:00.377+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO CodeGenerator: Code generated in 24.174166 ms
[2025-07-03T18:02:00.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO CodeGenerator: Code generated in 4.15175 ms
[2025-07-03T18:02:00.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO CodeGenerator: Code generated in 2.247958 ms
[2025-07-03T18:02:00.407+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO CodeGenerator: Code generated in 2.783625 ms
[2025-07-03T18:02:00.417+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO CodeGenerator: Code generated in 2.742416 ms
[2025-07-03T18:02:00.420+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00068-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-168362, partition values: [empty row]
[2025-07-03T18:02:00.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.437+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00196-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-163710, partition values: [empty row]
[2025-07-03T18:02:00.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.443+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00029-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157967, partition values: [empty row]
[2025-07-03T18:02:00.444+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.447+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00198-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157920, partition values: [empty row]
[2025-07-03T18:02:00.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.451+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00128-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157850, partition values: [empty row]
[2025-07-03T18:02:00.452+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00120-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157700, partition values: [empty row]
[2025-07-03T18:02:00.457+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00102-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157204, partition values: [empty row]
[2025-07-03T18:02:00.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.463+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00053-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156699, partition values: [empty row]
[2025-07-03T18:02:00.465+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00147-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156146, partition values: [empty row]
[2025-07-03T18:02:00.468+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00087-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-155444, partition values: [empty row]
[2025-07-03T18:02:00.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.475+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00140-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-154024, partition values: [empty row]
[2025-07-03T18:02:00.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00095-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153497, partition values: [empty row]
[2025-07-03T18:02:00.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00079-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153486, partition values: [empty row]
[2025-07-03T18:02:00.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.488+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00130-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153363, partition values: [empty row]
[2025-07-03T18:02:00.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.491+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00172-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153223, partition values: [empty row]
[2025-07-03T18:02:00.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00049-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152868, partition values: [empty row]
[2025-07-03T18:02:00.496+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00031-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152746, partition values: [empty row]
[2025-07-03T18:02:00.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00133-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152572, partition values: [empty row]
[2025-07-03T18:02:00.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.511+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00038-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152480, partition values: [empty row]
[2025-07-03T18:02:00.512+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00097-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152347, partition values: [empty row]
[2025-07-03T18:02:00.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.518+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00178-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152161, partition values: [empty row]
[2025-07-03T18:02:00.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00027-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152149, partition values: [empty row]
[2025-07-03T18:02:00.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.526+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00045-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151971, partition values: [empty row]
[2025-07-03T18:02:00.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.531+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00135-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151699, partition values: [empty row]
[2025-07-03T18:02:00.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00187-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151670, partition values: [empty row]
[2025-07-03T18:02:00.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00083-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151205, partition values: [empty row]
[2025-07-03T18:02:00.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.546+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00034-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150976, partition values: [empty row]
[2025-07-03T18:02:00.547+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00111-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150838, partition values: [empty row]
[2025-07-03T18:02:00.551+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.553+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00142-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150787, partition values: [empty row]
[2025-07-03T18:02:00.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00011-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150662, partition values: [empty row]
[2025-07-03T18:02:00.559+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.561+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00030-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150182, partition values: [empty row]
[2025-07-03T18:02:00.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.625+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Finished task 0.0 in stage 6.0 (TID 24). 3926 bytes result sent to driver
[2025-07-03T18:02:00.630+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 25) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:00.630+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 24) in 281 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:02:00.631+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Running task 1.0 in stage 6.0 (TID 25)
[2025-07-03T18:02:00.640+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00108-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150170, partition values: [empty row]
[2025-07-03T18:02:00.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.655+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00188-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150141, partition values: [empty row]
[2025-07-03T18:02:00.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00092-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150033, partition values: [empty row]
[2025-07-03T18:02:00.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.672+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00132-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149955, partition values: [empty row]
[2025-07-03T18:02:00.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.681+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00162-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149789, partition values: [empty row]
[2025-07-03T18:02:00.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.693+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00112-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149402, partition values: [empty row]
[2025-07-03T18:02:00.697+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.705+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00146-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149158, partition values: [empty row]
[2025-07-03T18:02:00.709+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.713+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00039-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149155, partition values: [empty row]
[2025-07-03T18:02:00.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00164-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149052, partition values: [empty row]
[2025-07-03T18:02:00.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.733+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00123-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148925, partition values: [empty row]
[2025-07-03T18:02:00.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.739+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00041-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148678, partition values: [empty row]
[2025-07-03T18:02:00.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.744+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00105-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148248, partition values: [empty row]
[2025-07-03T18:02:00.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00020-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147953, partition values: [empty row]
[2025-07-03T18:02:00.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00072-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147680, partition values: [empty row]
[2025-07-03T18:02:00.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00184-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147353, partition values: [empty row]
[2025-07-03T18:02:00.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00119-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147307, partition values: [empty row]
[2025-07-03T18:02:00.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00160-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147088, partition values: [empty row]
[2025-07-03T18:02:00.780+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00089-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146834, partition values: [empty row]
[2025-07-03T18:02:00.786+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00055-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146628, partition values: [empty row]
[2025-07-03T18:02:00.794+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00107-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146573, partition values: [empty row]
[2025-07-03T18:02:00.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00050-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146529, partition values: [empty row]
[2025-07-03T18:02:00.813+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.817+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00073-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146322, partition values: [empty row]
[2025-07-03T18:02:00.819+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00182-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146085, partition values: [empty row]
[2025-07-03T18:02:00.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.827+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00124-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145923, partition values: [empty row]
[2025-07-03T18:02:00.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00037-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145736, partition values: [empty row]
[2025-07-03T18:02:00.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.844+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00032-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145483, partition values: [empty row]
[2025-07-03T18:02:00.847+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00044-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145472, partition values: [empty row]
[2025-07-03T18:02:00.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00137-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145459, partition values: [empty row]
[2025-07-03T18:02:00.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.864+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00009-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145443, partition values: [empty row]
[2025-07-03T18:02:00.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00067-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145348, partition values: [empty row]
[2025-07-03T18:02:00.874+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.878+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00139-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145180, partition values: [empty row]
[2025-07-03T18:02:00.879+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Finished task 1.0 in stage 6.0 (TID 25). 3883 bytes result sent to driver
[2025-07-03T18:02:00.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 26) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:00.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 25) in 320 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:02:00.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO Executor: Running task 2.0 in stage 6.0 (TID 26)
[2025-07-03T18:02:00.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00114-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145175, partition values: [empty row]
[2025-07-03T18:02:00.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00154-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144764, partition values: [empty row]
[2025-07-03T18:02:00.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00115-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144653, partition values: [empty row]
[2025-07-03T18:02:00.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00062-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144636, partition values: [empty row]
[2025-07-03T18:02:00.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00177-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144534, partition values: [empty row]
[2025-07-03T18:02:00.984+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00131-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144411, partition values: [empty row]
[2025-07-03T18:02:00.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:00.998+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:00 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00003-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144247, partition values: [empty row]
[2025-07-03T18:02:01.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00159-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144214, partition values: [empty row]
[2025-07-03T18:02:01.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00081-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144124, partition values: [empty row]
[2025-07-03T18:02:01.012+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.014+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00173-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143839, partition values: [empty row]
[2025-07-03T18:02:01.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00145-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143692, partition values: [empty row]
[2025-07-03T18:02:01.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00100-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143512, partition values: [empty row]
[2025-07-03T18:02:01.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00110-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143491, partition values: [empty row]
[2025-07-03T18:02:01.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00167-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143463, partition values: [empty row]
[2025-07-03T18:02:01.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00082-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143421, partition values: [empty row]
[2025-07-03T18:02:01.054+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00103-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143305, partition values: [empty row]
[2025-07-03T18:02:01.061+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00094-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143260, partition values: [empty row]
[2025-07-03T18:02:01.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.067+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00192-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143248, partition values: [empty row]
[2025-07-03T18:02:01.068+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.071+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00153-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142738, partition values: [empty row]
[2025-07-03T18:02:01.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.081+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00028-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142579, partition values: [empty row]
[2025-07-03T18:02:01.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.091+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00109-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142500, partition values: [empty row]
[2025-07-03T18:02:01.097+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00007-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142453, partition values: [empty row]
[2025-07-03T18:02:01.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.110+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00197-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142400, partition values: [empty row]
[2025-07-03T18:02:01.112+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00048-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142344, partition values: [empty row]
[2025-07-03T18:02:01.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.120+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00024-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142324, partition values: [empty row]
[2025-07-03T18:02:01.123+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00113-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142107, partition values: [empty row]
[2025-07-03T18:02:01.127+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00179-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141811, partition values: [empty row]
[2025-07-03T18:02:01.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00194-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141737, partition values: [empty row]
[2025-07-03T18:02:01.134+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00022-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141733, partition values: [empty row]
[2025-07-03T18:02:01.138+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00006-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141716, partition values: [empty row]
[2025-07-03T18:02:01.143+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00057-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141276, partition values: [empty row]
[2025-07-03T18:02:01.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.207+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO Executor: Finished task 2.0 in stage 6.0 (TID 26). 3926 bytes result sent to driver
[2025-07-03T18:02:01.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 27) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:01.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 26) in 264 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:02:01.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO Executor: Running task 3.0 in stage 6.0 (TID 27)
[2025-07-03T18:02:01.219+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00180-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141220, partition values: [empty row]
[2025-07-03T18:02:01.221+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.239+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00181-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141147, partition values: [empty row]
[2025-07-03T18:02:01.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00134-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141133, partition values: [empty row]
[2025-07-03T18:02:01.246+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00174-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141104, partition values: [empty row]
[2025-07-03T18:02:01.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.253+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00054-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141050, partition values: [empty row]
[2025-07-03T18:02:01.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00085-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140960, partition values: [empty row]
[2025-07-03T18:02:01.261+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00122-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140951, partition values: [empty row]
[2025-07-03T18:02:01.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00064-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140895, partition values: [empty row]
[2025-07-03T18:02:01.270+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00080-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140405, partition values: [empty row]
[2025-07-03T18:02:01.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.282+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00071-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140133, partition values: [empty row]
[2025-07-03T18:02:01.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00118-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140113, partition values: [empty row]
[2025-07-03T18:02:01.293+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.297+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00136-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140097, partition values: [empty row]
[2025-07-03T18:02:01.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00056-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140011, partition values: [empty row]
[2025-07-03T18:02:01.308+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.313+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00016-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139898, partition values: [empty row]
[2025-07-03T18:02:01.321+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.324+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00121-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139858, partition values: [empty row]
[2025-07-03T18:02:01.327+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.331+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00018-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139827, partition values: [empty row]
[2025-07-03T18:02:01.335+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.340+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00002-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139804, partition values: [empty row]
[2025-07-03T18:02:01.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00052-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139763, partition values: [empty row]
[2025-07-03T18:02:01.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00152-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139683, partition values: [empty row]
[2025-07-03T18:02:01.351+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.355+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00170-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139630, partition values: [empty row]
[2025-07-03T18:02:01.357+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00183-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139299, partition values: [empty row]
[2025-07-03T18:02:01.840+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00025-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139114, partition values: [empty row]
[2025-07-03T18:02:01.847+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00026-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138875, partition values: [empty row]
[2025-07-03T18:02:01.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00070-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138619, partition values: [empty row]
[2025-07-03T18:02:01.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00117-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138472, partition values: [empty row]
[2025-07-03T18:02:01.860+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00148-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138343, partition values: [empty row]
[2025-07-03T18:02:01.864+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.867+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00151-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138303, partition values: [empty row]
[2025-07-03T18:02:01.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00190-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137980, partition values: [empty row]
[2025-07-03T18:02:01.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.877+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00116-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137825, partition values: [empty row]
[2025-07-03T18:02:01.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00046-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137502, partition values: [empty row]
[2025-07-03T18:02:01.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.892+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00063-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137399, partition values: [empty row]
[2025-07-03T18:02:01.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO Executor: Finished task 3.0 in stage 6.0 (TID 27). 3926 bytes result sent to driver
[2025-07-03T18:02:01.940+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 28) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:01.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO Executor: Running task 4.0 in stage 6.0 (TID 28)
[2025-07-03T18:02:01.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 27) in 734 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:02:01.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00143-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137169, partition values: [empty row]
[2025-07-03T18:02:01.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00047-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137073, partition values: [empty row]
[2025-07-03T18:02:01.962+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00084-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136997, partition values: [empty row]
[2025-07-03T18:02:01.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00156-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136937, partition values: [empty row]
[2025-07-03T18:02:01.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00193-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136790, partition values: [empty row]
[2025-07-03T18:02:01.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00042-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136602, partition values: [empty row]
[2025-07-03T18:02:01.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00088-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136524, partition values: [empty row]
[2025-07-03T18:02:01.984+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.992+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00191-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136091, partition values: [empty row]
[2025-07-03T18:02:01.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:01.999+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:01 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00019-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136064, partition values: [empty row]
[2025-07-03T18:02:02.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00127-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135998, partition values: [empty row]
[2025-07-03T18:02:02.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00199-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135968, partition values: [empty row]
[2025-07-03T18:02:02.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00013-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135936, partition values: [empty row]
[2025-07-03T18:02:02.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.014+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00144-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135783, partition values: [empty row]
[2025-07-03T18:02:02.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00101-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135779, partition values: [empty row]
[2025-07-03T18:02:02.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00171-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135629, partition values: [empty row]
[2025-07-03T18:02:02.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00166-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135568, partition values: [empty row]
[2025-07-03T18:02:02.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00165-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135539, partition values: [empty row]
[2025-07-03T18:02:02.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.029+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00060-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135477, partition values: [empty row]
[2025-07-03T18:02:02.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00004-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135462, partition values: [empty row]
[2025-07-03T18:02:02.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00010-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135408, partition values: [empty row]
[2025-07-03T18:02:02.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00040-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135398, partition values: [empty row]
[2025-07-03T18:02:02.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00033-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135395, partition values: [empty row]
[2025-07-03T18:02:02.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.057+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00021-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135250, partition values: [empty row]
[2025-07-03T18:02:02.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.062+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00023-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135210, partition values: [empty row]
[2025-07-03T18:02:02.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00185-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135190, partition values: [empty row]
[2025-07-03T18:02:02.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.069+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00061-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134981, partition values: [empty row]
[2025-07-03T18:02:02.070+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00001-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134944, partition values: [empty row]
[2025-07-03T18:02:02.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00189-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134929, partition values: [empty row]
[2025-07-03T18:02:02.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.081+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00091-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134926, partition values: [empty row]
[2025-07-03T18:02:02.082+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00161-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134806, partition values: [empty row]
[2025-07-03T18:02:02.086+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:02.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00012-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134703, partition values: [empty row]
[2025-07-03T18:02:02.088+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:02 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.561+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO Executor: Finished task 4.0 in stage 6.0 (TID 28). 3883 bytes result sent to driver
[2025-07-03T18:02:03.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSetManager: Starting task 5.0 in stage 6.0 (TID 29) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:03.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO Executor: Running task 5.0 in stage 6.0 (TID 29)
[2025-07-03T18:02:03.566+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 28) in 1624 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:02:03.575+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00014-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134651, partition values: [empty row]
[2025-07-03T18:02:03.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00075-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134649, partition values: [empty row]
[2025-07-03T18:02:03.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00168-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134557, partition values: [empty row]
[2025-07-03T18:02:03.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00176-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134495, partition values: [empty row]
[2025-07-03T18:02:03.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00157-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134432, partition values: [empty row]
[2025-07-03T18:02:03.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00069-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134344, partition values: [empty row]
[2025-07-03T18:02:03.621+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.626+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00051-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134093, partition values: [empty row]
[2025-07-03T18:02:03.628+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00035-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133957, partition values: [empty row]
[2025-07-03T18:02:03.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.641+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00175-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133736, partition values: [empty row]
[2025-07-03T18:02:03.642+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.644+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00058-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133517, partition values: [empty row]
[2025-07-03T18:02:03.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00008-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133312, partition values: [empty row]
[2025-07-03T18:02:03.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.658+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00036-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133250, partition values: [empty row]
[2025-07-03T18:02:03.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00017-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133244, partition values: [empty row]
[2025-07-03T18:02:03.665+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00195-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133115, partition values: [empty row]
[2025-07-03T18:02:03.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.682+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00086-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132787, partition values: [empty row]
[2025-07-03T18:02:03.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.692+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00106-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132496, partition values: [empty row]
[2025-07-03T18:02:03.693+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00149-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132477, partition values: [empty row]
[2025-07-03T18:02:03.697+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00126-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132427, partition values: [empty row]
[2025-07-03T18:02:03.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.707+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00099-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132405, partition values: [empty row]
[2025-07-03T18:02:03.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.711+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00186-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132164, partition values: [empty row]
[2025-07-03T18:02:03.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00093-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131331, partition values: [empty row]
[2025-07-03T18:02:03.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00074-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131260, partition values: [empty row]
[2025-07-03T18:02:03.725+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00078-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130578, partition values: [empty row]
[2025-07-03T18:02:03.733+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.740+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00141-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130266, partition values: [empty row]
[2025-07-03T18:02:03.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00005-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130222, partition values: [empty row]
[2025-07-03T18:02:03.744+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00065-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130083, partition values: [empty row]
[2025-07-03T18:02:03.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00125-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130011, partition values: [empty row]
[2025-07-03T18:02:03.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00077-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129832, partition values: [empty row]
[2025-07-03T18:02:03.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.760+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00169-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129566, partition values: [empty row]
[2025-07-03T18:02:03.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00150-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129448, partition values: [empty row]
[2025-07-03T18:02:03.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00163-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129300, partition values: [empty row]
[2025-07-03T18:02:03.767+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO Executor: Finished task 5.0 in stage 6.0 (TID 29). 3883 bytes result sent to driver
[2025-07-03T18:02:03.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSetManager: Starting task 6.0 in stage 6.0 (TID 30) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 11762 bytes)
[2025-07-03T18:02:03.797+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO Executor: Running task 6.0 in stage 6.0 (TID 30)
[2025-07-03T18:02:03.797+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSetManager: Finished task 5.0 in stage 6.0 (TID 29) in 234 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:02:03.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00129-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129243, partition values: [empty row]
[2025-07-03T18:02:03.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.808+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00155-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128963, partition values: [empty row]
[2025-07-03T18:02:03.810+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.812+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00076-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128747, partition values: [empty row]
[2025-07-03T18:02:03.813+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.817+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00098-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128595, partition values: [empty row]
[2025-07-03T18:02:03.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00066-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128097, partition values: [empty row]
[2025-07-03T18:02:03.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.827+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00090-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-127202, partition values: [empty row]
[2025-07-03T18:02:03.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00138-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-126507, partition values: [empty row]
[2025-07-03T18:02:03.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.833+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00043-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125123, partition values: [empty row]
[2025-07-03T18:02:03.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.836+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00158-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125003, partition values: [empty row]
[2025-07-03T18:02:03.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00059-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123983, partition values: [empty row]
[2025-07-03T18:02:03.840+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.844+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00104-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123468, partition values: [empty row]
[2025-07-03T18:02:03.845+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00000-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123063, partition values: [empty row]
[2025-07-03T18:02:03.847+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00015-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-122798, partition values: [empty row]
[2025-07-03T18:02:03.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.863+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00096-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-118888, partition values: [empty row]
[2025-07-03T18:02:03.863+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:03.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO Executor: Finished task 6.0 in stage 6.0 (TID 30). 3926 bytes result sent to driver
[2025-07-03T18:02:03.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSetManager: Finished task 6.0 in stage 6.0 (TID 30) in 106 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:02:03.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-07-03T18:02:03.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO DAGScheduler: ShuffleMapStage 6 (parquet at NativeMethodAccessorImpl.java:0) finished in 3.567 s
[2025-07-03T18:02:03.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO DAGScheduler: looking for newly runnable stages
[2025-07-03T18:02:03.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO DAGScheduler: running: Set()
[2025-07-03T18:02:03.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO DAGScheduler: waiting: Set(ResultStage 7)
[2025-07-03T18:02:03.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO DAGScheduler: failed: Set()
[2025-07-03T18:02:03.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[25] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:02:03.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 260.1 KiB, free 386.3 MiB)
[2025-07-03T18:02:03.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 96.8 KiB, free 386.2 MiB)
[2025-07-03T18:02:03.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 39b5ac792cf9:37901 (size: 96.8 KiB, free: 426.9 MiB)
[2025-07-03T18:02:03.933+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:03.933+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-03T18:02:03.934+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2025-07-03T18:02:03.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 31) (39b5ac792cf9, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:03.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 31)
[2025-07-03T18:02:03.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:03.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:03.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO CodeGenerator: Code generated in 11.813792 ms
[2025-07-03T18:02:03.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:03.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:03.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:03.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:03.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:03.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:03.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:03.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:03.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:03.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:03.986+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:03.986+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:03.986+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:03.986+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:03.986+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:03.987+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:03.987+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:03.987+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:03.988+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:03.989+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:03.989+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:03.990+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:03.991+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:03.991+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:03.991+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:03.991+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:03.991+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:03.991+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:03.992+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:03.993+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecPool: Got brand-new compressor [.snappy]
[2025-07-03T18:02:04.112+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000000_31' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000000
[2025-07-03T18:02:04.112+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000000_31: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 0.0 in stage 7.0 (TID 31). 7298 bytes result sent to driver
[2025-07-03T18:02:04.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 32) (39b5ac792cf9, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 31) in 182 ms on 39b5ac792cf9 (executor driver) (1/200)
[2025-07-03T18:02:04.120+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 1.0 in stage 7.0 (TID 32)
[2025-07-03T18:02:04.123+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.8 KiB) non-empty blocks including 7 (10.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.124+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.125+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.129+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.129+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.129+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.129+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.129+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.130+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.130+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.130+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.130+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.130+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.130+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.130+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.131+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.132+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.132+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.132+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.132+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.132+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.132+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.132+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.133+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.134+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.143+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000001_32' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000001
[2025-07-03T18:02:04.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000001_32: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 1.0 in stage 7.0 (TID 32). 7255 bytes result sent to driver
[2025-07-03T18:02:04.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 33) (39b5ac792cf9, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 2.0 in stage 7.0 (TID 33)
[2025-07-03T18:02:04.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 32) in 29 ms on 39b5ac792cf9 (executor driver) (2/200)
[2025-07-03T18:02:04.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.154+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.155+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.156+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.156+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.156+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.156+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.156+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.157+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.158+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.159+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.160+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000002_33' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000002
[2025-07-03T18:02:04.168+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000002_33: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.168+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 2.0 in stage 7.0 (TID 33). 7255 bytes result sent to driver
[2025-07-03T18:02:04.168+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 34) (39b5ac792cf9, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 3.0 in stage 7.0 (TID 34)
[2025-07-03T18:02:04.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 33) in 24 ms on 39b5ac792cf9 (executor driver) (3/200)
[2025-07-03T18:02:04.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.2 KiB) non-empty blocks including 7 (9.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.180+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.181+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.182+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.183+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.184+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.185+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.185+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.185+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.185+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.185+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.191+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000003_34' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000003
[2025-07-03T18:02:04.192+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000003_34: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.192+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 3.0 in stage 7.0 (TID 34). 7255 bytes result sent to driver
[2025-07-03T18:02:04.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 35) (39b5ac792cf9, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 34) in 25 ms on 39b5ac792cf9 (executor driver) (4/200)
[2025-07-03T18:02:04.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 4.0 in stage 7.0 (TID 35)
[2025-07-03T18:02:04.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.201+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.201+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.205+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.206+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.207+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.208+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.209+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.210+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.210+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.210+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.210+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000004_35' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000004
[2025-07-03T18:02:04.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000004_35: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 4.0 in stage 7.0 (TID 35). 7255 bytes result sent to driver
[2025-07-03T18:02:04.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 36) (39b5ac792cf9, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.221+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 35) in 24 ms on 39b5ac792cf9 (executor driver) (5/200)
[2025-07-03T18:02:04.221+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 5.0 in stage 7.0 (TID 36)
[2025-07-03T18:02:04.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.8 KiB) non-empty blocks including 7 (9.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.228+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.229+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.230+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.231+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.232+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.233+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.233+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.233+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.233+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.239+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000005_36' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000005
[2025-07-03T18:02:04.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000005_36: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 5.0 in stage 7.0 (TID 36). 7255 bytes result sent to driver
[2025-07-03T18:02:04.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 37) (39b5ac792cf9, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 36) in 24 ms on 39b5ac792cf9 (executor driver) (6/200)
[2025-07-03T18:02:04.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 6.0 in stage 7.0 (TID 37)
[2025-07-03T18:02:04.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.253+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.254+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.255+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.256+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.257+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.263+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000006_37' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000006
[2025-07-03T18:02:04.263+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000006_37: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 6.0 in stage 7.0 (TID 37). 7255 bytes result sent to driver
[2025-07-03T18:02:04.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 38) (39b5ac792cf9, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 7.0 in stage 7.0 (TID 38)
[2025-07-03T18:02:04.265+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 37) in 24 ms on 39b5ac792cf9 (executor driver) (7/200)
[2025-07-03T18:02:04.270+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.2 KiB) non-empty blocks including 7 (9.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.271+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.275+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.276+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.277+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.278+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.279+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.280+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.280+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000007_38' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000007
[2025-07-03T18:02:04.286+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000007_38: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.286+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 7.0 in stage 7.0 (TID 38). 7255 bytes result sent to driver
[2025-07-03T18:02:04.286+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 39) (39b5ac792cf9, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 8.0 in stage 7.0 (TID 39)
[2025-07-03T18:02:04.288+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 38) in 24 ms on 39b5ac792cf9 (executor driver) (8/200)
[2025-07-03T18:02:04.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.297+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.299+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.300+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.301+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.302+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.303+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.303+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.303+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.308+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000008_39' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000008
[2025-07-03T18:02:04.309+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000008_39: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.309+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 8.0 in stage 7.0 (TID 39). 7255 bytes result sent to driver
[2025-07-03T18:02:04.309+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 40) (39b5ac792cf9, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.313+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 9.0 in stage 7.0 (TID 40)
[2025-07-03T18:02:04.313+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 39) in 24 ms on 39b5ac792cf9 (executor driver) (9/200)
[2025-07-03T18:02:04.315+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.315+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.319+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.320+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.321+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.322+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.323+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.323+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.323+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.323+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.323+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.323+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000009_40' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000009
[2025-07-03T18:02:04.331+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000009_40: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 9.0 in stage 7.0 (TID 40). 7298 bytes result sent to driver
[2025-07-03T18:02:04.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 41) (39b5ac792cf9, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 10.0 in stage 7.0 (TID 41)
[2025-07-03T18:02:04.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 40) in 24 ms on 39b5ac792cf9 (executor driver) (10/200)
[2025-07-03T18:02:04.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.2 KiB) non-empty blocks including 7 (9.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.343+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.343+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.346+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.347+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.348+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.349+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.350+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000010_41' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000010
[2025-07-03T18:02:04.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000010_41: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 10.0 in stage 7.0 (TID 41). 7255 bytes result sent to driver
[2025-07-03T18:02:04.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 42) (39b5ac792cf9, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 11.0 in stage 7.0 (TID 42)
[2025-07-03T18:02:04.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 41) in 27 ms on 39b5ac792cf9 (executor driver) (11/200)
[2025-07-03T18:02:04.367+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.372+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.373+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.374+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.375+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.376+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000011_42' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000011
[2025-07-03T18:02:04.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000011_42: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 11.0 in stage 7.0 (TID 42). 7255 bytes result sent to driver
[2025-07-03T18:02:04.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 43) (39b5ac792cf9, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 12.0 in stage 7.0 (TID 43)
[2025-07-03T18:02:04.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 42) in 24 ms on 39b5ac792cf9 (executor driver) (12/200)
[2025-07-03T18:02:04.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.387+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.387+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.388+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.388+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.389+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.391+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.392+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.393+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.394+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.395+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000012_43' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000012
[2025-07-03T18:02:04.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000012_43: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 12.0 in stage 7.0 (TID 43). 7255 bytes result sent to driver
[2025-07-03T18:02:04.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 44) (39b5ac792cf9, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.404+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 13.0 in stage 7.0 (TID 44)
[2025-07-03T18:02:04.405+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 43) in 20 ms on 39b5ac792cf9 (executor driver) (13/200)
[2025-07-03T18:02:04.405+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.405+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.406+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.406+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.406+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.407+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.407+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.410+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.411+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.412+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.413+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.414+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.414+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.419+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000013_44' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000013
[2025-07-03T18:02:04.420+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000013_44: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.420+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 13.0 in stage 7.0 (TID 44). 7255 bytes result sent to driver
[2025-07-03T18:02:04.420+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 45) (39b5ac792cf9, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.421+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 44) in 19 ms on 39b5ac792cf9 (executor driver) (14/200)
[2025-07-03T18:02:04.421+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 14.0 in stage 7.0 (TID 45)
[2025-07-03T18:02:04.425+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (7.3 KiB) non-empty blocks including 7 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.425+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.427+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.427+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.427+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.427+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.429+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.430+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.431+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.432+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.433+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.434+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.434+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.434+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.434+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.434+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.434+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.434+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.439+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000014_45' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000014
[2025-07-03T18:02:04.439+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000014_45: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.439+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 14.0 in stage 7.0 (TID 45). 7255 bytes result sent to driver
[2025-07-03T18:02:04.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 46) (39b5ac792cf9, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 15.0 in stage 7.0 (TID 46)
[2025-07-03T18:02:04.442+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 45) in 20 ms on 39b5ac792cf9 (executor driver) (15/200)
[2025-07-03T18:02:04.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.4 KiB) non-empty blocks including 7 (10.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.446+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.446+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.447+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.447+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.449+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.450+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.451+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.451+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.451+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.451+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.451+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.451+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.451+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.452+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.453+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.454+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.454+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.454+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.454+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.458+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000015_46' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000015
[2025-07-03T18:02:04.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000015_46: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 15.0 in stage 7.0 (TID 46). 7255 bytes result sent to driver
[2025-07-03T18:02:04.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 47) (39b5ac792cf9, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.460+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 16.0 in stage 7.0 (TID 47)
[2025-07-03T18:02:04.462+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 46) in 19 ms on 39b5ac792cf9 (executor driver) (16/200)
[2025-07-03T18:02:04.463+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.5 KiB) non-empty blocks including 7 (10.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.463+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.464+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.465+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.466+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.467+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.468+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.469+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.470+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.471+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.471+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.471+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.471+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.471+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.471+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.475+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000016_47' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000016
[2025-07-03T18:02:04.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000016_47: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 16.0 in stage 7.0 (TID 47). 7255 bytes result sent to driver
[2025-07-03T18:02:04.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 48) (39b5ac792cf9, executor driver, partition 17, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 17.0 in stage 7.0 (TID 48)
[2025-07-03T18:02:04.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 47) in 17 ms on 39b5ac792cf9 (executor driver) (17/200)
[2025-07-03T18:02:04.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (13.3 KiB) non-empty blocks including 7 (13.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.482+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.482+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.482+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.484+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.484+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.484+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.484+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.485+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.486+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.487+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.488+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.489+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000017_48' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000017
[2025-07-03T18:02:04.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000017_48: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 17.0 in stage 7.0 (TID 48). 7255 bytes result sent to driver
[2025-07-03T18:02:04.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 49) (39b5ac792cf9, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 18.0 in stage 7.0 (TID 49)
[2025-07-03T18:02:04.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 48) in 18 ms on 39b5ac792cf9 (executor driver) (18/200)
[2025-07-03T18:02:04.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.501+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.502+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.502+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.502+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.502+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.503+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.504+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.505+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.506+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.507+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.507+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.507+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.507+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.507+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.511+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000018_49' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000018
[2025-07-03T18:02:04.512+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000018_49: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.512+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 18.0 in stage 7.0 (TID 49). 7255 bytes result sent to driver
[2025-07-03T18:02:04.512+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 50) (39b5ac792cf9, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 19.0 in stage 7.0 (TID 50)
[2025-07-03T18:02:04.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 49) in 18 ms on 39b5ac792cf9 (executor driver) (19/200)
[2025-07-03T18:02:04.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.517+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.517+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.517+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.518+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.518+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.521+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.522+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.523+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.524+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.525+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.525+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.525+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.525+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.534+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 39b5ac792cf9:37901 in memory (size: 25.9 KiB, free: 426.9 MiB)
[2025-07-03T18:02:04.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000019_50' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000019
[2025-07-03T18:02:04.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000019_50: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 19.0 in stage 7.0 (TID 50). 7298 bytes result sent to driver
[2025-07-03T18:02:04.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 51) (39b5ac792cf9, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 20.0 in stage 7.0 (TID 51)
[2025-07-03T18:02:04.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 50) in 24 ms on 39b5ac792cf9 (executor driver) (20/200)
[2025-07-03T18:02:04.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.7 KiB) non-empty blocks including 7 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.542+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.544+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.545+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.545+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.545+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.545+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.545+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.545+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.545+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.546+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.546+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.546+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.546+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.546+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.546+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.546+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.547+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.548+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.549+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.549+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.549+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.549+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.549+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.553+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000020_51' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000020
[2025-07-03T18:02:04.553+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000020_51: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.553+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 20.0 in stage 7.0 (TID 51). 7255 bytes result sent to driver
[2025-07-03T18:02:04.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 52) (39b5ac792cf9, executor driver, partition 21, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 21.0 in stage 7.0 (TID 52)
[2025-07-03T18:02:04.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 51) in 17 ms on 39b5ac792cf9 (executor driver) (21/200)
[2025-07-03T18:02:04.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.559+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.559+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.563+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.564+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.565+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.565+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.565+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.565+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.565+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.565+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.565+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.566+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.567+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.568+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000021_52' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000021
[2025-07-03T18:02:04.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000021_52: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.575+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 21.0 in stage 7.0 (TID 52). 7255 bytes result sent to driver
[2025-07-03T18:02:04.575+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 53) (39b5ac792cf9, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.575+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 22.0 in stage 7.0 (TID 53)
[2025-07-03T18:02:04.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 52) in 22 ms on 39b5ac792cf9 (executor driver) (22/200)
[2025-07-03T18:02:04.579+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.9 KiB) non-empty blocks including 7 (11.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.582+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.583+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.584+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.584+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.584+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.584+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.584+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.584+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.585+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.586+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.587+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.587+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.587+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.587+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.587+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.587+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000022_53' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000022
[2025-07-03T18:02:04.592+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000022_53: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 22.0 in stage 7.0 (TID 53). 7255 bytes result sent to driver
[2025-07-03T18:02:04.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 54) (39b5ac792cf9, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.597+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 53) in 19 ms on 39b5ac792cf9 (executor driver) (23/200)
[2025-07-03T18:02:04.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 23.0 in stage 7.0 (TID 54)
[2025-07-03T18:02:04.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.4 KiB) non-empty blocks including 7 (9.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.599+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.600+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.600+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.601+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.601+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.601+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.601+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.601+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.601+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.602+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.603+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.604+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.605+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000023_54' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000023
[2025-07-03T18:02:04.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000023_54: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 23.0 in stage 7.0 (TID 54). 7255 bytes result sent to driver
[2025-07-03T18:02:04.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 55) (39b5ac792cf9, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 24.0 in stage 7.0 (TID 55)
[2025-07-03T18:02:04.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 54) in 17 ms on 39b5ac792cf9 (executor driver) (24/200)
[2025-07-03T18:02:04.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.8 KiB) non-empty blocks including 7 (11.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.619+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.620+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.621+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.622+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.626+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000024_55' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000024
[2025-07-03T18:02:04.627+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000024_55: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.627+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 24.0 in stage 7.0 (TID 55). 7255 bytes result sent to driver
[2025-07-03T18:02:04.627+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 56) (39b5ac792cf9, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.631+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 25.0 in stage 7.0 (TID 56)
[2025-07-03T18:02:04.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 55) in 16 ms on 39b5ac792cf9 (executor driver) (25/200)
[2025-07-03T18:02:04.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (12.1 KiB) non-empty blocks including 7 (12.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.636+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.637+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.638+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.639+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.644+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000025_56' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000025
[2025-07-03T18:02:04.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000025_56: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 25.0 in stage 7.0 (TID 56). 7255 bytes result sent to driver
[2025-07-03T18:02:04.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 57) (39b5ac792cf9, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 26.0 in stage 7.0 (TID 57)
[2025-07-03T18:02:04.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 56) in 18 ms on 39b5ac792cf9 (executor driver) (26/200)
[2025-07-03T18:02:04.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.8 KiB) non-empty blocks including 7 (11.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.652+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.652+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.653+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.654+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.655+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.656+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.657+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.657+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000026_57' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000026
[2025-07-03T18:02:04.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000026_57: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 26.0 in stage 7.0 (TID 57). 7255 bytes result sent to driver
[2025-07-03T18:02:04.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 58) (39b5ac792cf9, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.662+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 27.0 in stage 7.0 (TID 58)
[2025-07-03T18:02:04.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 57) in 16 ms on 39b5ac792cf9 (executor driver) (27/200)
[2025-07-03T18:02:04.665+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.665+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.668+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.668+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.669+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.669+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.670+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.671+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.672+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.673+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.677+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000027_58' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000027
[2025-07-03T18:02:04.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000027_58: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 27.0 in stage 7.0 (TID 58). 7255 bytes result sent to driver
[2025-07-03T18:02:04.682+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 59) (39b5ac792cf9, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 28.0 in stage 7.0 (TID 59)
[2025-07-03T18:02:04.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 58) in 18 ms on 39b5ac792cf9 (executor driver) (28/200)
[2025-07-03T18:02:04.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.685+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.685+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.685+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.686+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.687+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.688+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.689+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.690+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.691+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.692+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.692+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000028_59' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000028
[2025-07-03T18:02:04.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000028_59: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.697+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 28.0 in stage 7.0 (TID 59). 7255 bytes result sent to driver
[2025-07-03T18:02:04.697+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 60) (39b5ac792cf9, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.697+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 29.0 in stage 7.0 (TID 60)
[2025-07-03T18:02:04.698+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 59) in 19 ms on 39b5ac792cf9 (executor driver) (29/200)
[2025-07-03T18:02:04.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.704+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.705+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.705+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.705+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.705+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.705+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.706+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.707+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.708+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.709+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.709+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.709+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.709+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.709+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.709+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.709+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.713+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000029_60' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000029
[2025-07-03T18:02:04.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000029_60: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 29.0 in stage 7.0 (TID 60). 7255 bytes result sent to driver
[2025-07-03T18:02:04.717+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 61) (39b5ac792cf9, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 30.0 in stage 7.0 (TID 61)
[2025-07-03T18:02:04.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 60) in 17 ms on 39b5ac792cf9 (executor driver) (30/200)
[2025-07-03T18:02:04.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.4 KiB) non-empty blocks including 7 (9.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.720+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.720+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.722+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.723+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.724+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.725+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.726+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.726+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.726+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.726+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.726+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000030_61' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000030
[2025-07-03T18:02:04.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000030_61: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 30.0 in stage 7.0 (TID 61). 7255 bytes result sent to driver
[2025-07-03T18:02:04.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 62) (39b5ac792cf9, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.733+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 61) in 16 ms on 39b5ac792cf9 (executor driver) (31/200)
[2025-07-03T18:02:04.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 31.0 in stage 7.0 (TID 62)
[2025-07-03T18:02:04.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.737+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.738+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.739+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.740+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.741+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000031_62' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000031
[2025-07-03T18:02:04.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000031_62: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 31.0 in stage 7.0 (TID 62). 7255 bytes result sent to driver
[2025-07-03T18:02:04.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 63) (39b5ac792cf9, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 32.0 in stage 7.0 (TID 63)
[2025-07-03T18:02:04.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 62) in 17 ms on 39b5ac792cf9 (executor driver) (32/200)
[2025-07-03T18:02:04.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.754+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.755+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.756+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.757+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.758+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.758+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.758+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.758+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.762+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000032_63' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000032
[2025-07-03T18:02:04.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000032_63: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 32.0 in stage 7.0 (TID 63). 7255 bytes result sent to driver
[2025-07-03T18:02:04.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 64) (39b5ac792cf9, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 33.0 in stage 7.0 (TID 64)
[2025-07-03T18:02:04.767+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 63) in 17 ms on 39b5ac792cf9 (executor driver) (33/200)
[2025-07-03T18:02:04.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.771+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.772+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.773+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.774+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.775+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000033_64' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000033
[2025-07-03T18:02:04.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000033_64: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 33.0 in stage 7.0 (TID 64). 7255 bytes result sent to driver
[2025-07-03T18:02:04.780+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 65) (39b5ac792cf9, executor driver, partition 34, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 34.0 in stage 7.0 (TID 65)
[2025-07-03T18:02:04.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 64) in 17 ms on 39b5ac792cf9 (executor driver) (34/200)
[2025-07-03T18:02:04.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (8.8 KiB) non-empty blocks including 7 (8.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.785+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.785+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.786+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.786+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.786+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.787+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.788+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.789+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.790+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.791+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.791+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.791+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000034_65' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000034
[2025-07-03T18:02:04.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000034_65: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 34.0 in stage 7.0 (TID 65). 7255 bytes result sent to driver
[2025-07-03T18:02:04.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 66) (39b5ac792cf9, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 65) in 16 ms on 39b5ac792cf9 (executor driver) (35/200)
[2025-07-03T18:02:04.800+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 35.0 in stage 7.0 (TID 66)
[2025-07-03T18:02:04.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.805+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.806+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.807+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.808+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.809+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000035_66' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000035
[2025-07-03T18:02:04.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000035_66: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 35.0 in stage 7.0 (TID 66). 7255 bytes result sent to driver
[2025-07-03T18:02:04.817+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 67) (39b5ac792cf9, executor driver, partition 36, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.817+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 66) in 22 ms on 39b5ac792cf9 (executor driver) (36/200)
[2025-07-03T18:02:04.817+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 36.0 in stage 7.0 (TID 67)
[2025-07-03T18:02:04.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.4 KiB) non-empty blocks including 7 (9.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.825+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.826+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.827+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.828+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.829+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.829+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.829+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.829+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.829+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.829+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000036_67' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000036
[2025-07-03T18:02:04.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000036_67: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.833+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 36.0 in stage 7.0 (TID 67). 7255 bytes result sent to driver
[2025-07-03T18:02:04.833+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 68) (39b5ac792cf9, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 37.0 in stage 7.0 (TID 68)
[2025-07-03T18:02:04.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 67) in 18 ms on 39b5ac792cf9 (executor driver) (37/200)
[2025-07-03T18:02:04.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.840+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.841+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.842+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.843+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.844+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.845+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.846+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.846+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.846+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.846+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000037_68' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000037
[2025-07-03T18:02:04.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000037_68: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 37.0 in stage 7.0 (TID 68). 7255 bytes result sent to driver
[2025-07-03T18:02:04.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 69) (39b5ac792cf9, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.853+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 38.0 in stage 7.0 (TID 69)
[2025-07-03T18:02:04.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 68) in 17 ms on 39b5ac792cf9 (executor driver) (38/200)
[2025-07-03T18:02:04.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.858+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.859+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.860+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.861+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.862+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.862+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000038_69' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000038
[2025-07-03T18:02:04.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000038_69: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 38.0 in stage 7.0 (TID 69). 7255 bytes result sent to driver
[2025-07-03T18:02:04.867+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 70) (39b5ac792cf9, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 39.0 in stage 7.0 (TID 70)
[2025-07-03T18:02:04.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 69) in 16 ms on 39b5ac792cf9 (executor driver) (39/200)
[2025-07-03T18:02:04.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.873+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.874+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.875+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.876+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.877+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.877+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.877+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.877+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.877+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.877+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.877+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000039_70' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000039
[2025-07-03T18:02:04.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000039_70: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 39.0 in stage 7.0 (TID 70). 7255 bytes result sent to driver
[2025-07-03T18:02:04.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 71) (39b5ac792cf9, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 40.0 in stage 7.0 (TID 71)
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 70) in 16 ms on 39b5ac792cf9 (executor driver) (40/200)
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.6 KiB) non-empty blocks including 7 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.888+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.889+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.890+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.891+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.892+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.893+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.893+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.893+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000040_71' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000040
[2025-07-03T18:02:04.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000040_71: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 40.0 in stage 7.0 (TID 71). 7341 bytes result sent to driver
[2025-07-03T18:02:04.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 72) (39b5ac792cf9, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 71) in 19 ms on 39b5ac792cf9 (executor driver) (41/200)
[2025-07-03T18:02:04.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 41.0 in stage 7.0 (TID 72)
[2025-07-03T18:02:04.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.906+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.907+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.908+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.909+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.910+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.911+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.912+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000041_72' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000041
[2025-07-03T18:02:04.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000041_72: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 41.0 in stage 7.0 (TID 72). 7255 bytes result sent to driver
[2025-07-03T18:02:04.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 73) (39b5ac792cf9, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 42.0 in stage 7.0 (TID 73)
[2025-07-03T18:02:04.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 72) in 16 ms on 39b5ac792cf9 (executor driver) (42/200)
[2025-07-03T18:02:04.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.2 KiB) non-empty blocks including 7 (11.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.923+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.923+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.924+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.925+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.926+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.927+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.927+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.927+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.927+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.927+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.927+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000042_73' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000042
[2025-07-03T18:02:04.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000042_73: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 42.0 in stage 7.0 (TID 73). 7255 bytes result sent to driver
[2025-07-03T18:02:04.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 74) (39b5ac792cf9, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 73) in 16 ms on 39b5ac792cf9 (executor driver) (43/200)
[2025-07-03T18:02:04.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 43.0 in stage 7.0 (TID 74)
[2025-07-03T18:02:04.936+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.936+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.939+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.939+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.939+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.939+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.939+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.940+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.941+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.942+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.943+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.943+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.943+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.943+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.943+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.943+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.943+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000043_74' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000043
[2025-07-03T18:02:04.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000043_74: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 43.0 in stage 7.0 (TID 74). 7255 bytes result sent to driver
[2025-07-03T18:02:04.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 75) (39b5ac792cf9, executor driver, partition 44, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 74) in 17 ms on 39b5ac792cf9 (executor driver) (44/200)
[2025-07-03T18:02:04.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 44.0 in stage 7.0 (TID 75)
[2025-07-03T18:02:04.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (11.2 KiB) non-empty blocks including 7 (11.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.955+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.956+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.957+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.958+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000044_75' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000044
[2025-07-03T18:02:04.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000044_75: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 44.0 in stage 7.0 (TID 75). 7255 bytes result sent to driver
[2025-07-03T18:02:04.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 76) (39b5ac792cf9, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 45.0 in stage 7.0 (TID 76)
[2025-07-03T18:02:04.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 75) in 16 ms on 39b5ac792cf9 (executor driver) (45/200)
[2025-07-03T18:02:04.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (10.2 KiB) non-empty blocks including 7 (10.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.973+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.973+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.974+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.976+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.976+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.976+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.976+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.976+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.977+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.977+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.977+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.977+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.977+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.977+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.978+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.979+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000045_76' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000045
[2025-07-03T18:02:04.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000045_76: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:04.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Finished task 45.0 in stage 7.0 (TID 76). 7255 bytes result sent to driver
[2025-07-03T18:02:04.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 77) (39b5ac792cf9, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:04.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO Executor: Running task 46.0 in stage 7.0 (TID 77)
[2025-07-03T18:02:04.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 76) in 23 ms on 39b5ac792cf9 (executor driver) (46/200)
[2025-07-03T18:02:04.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:04.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:04.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.992+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:04.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:04.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:04.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:04.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.994+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.995+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:04.996+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:04.997+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:04.998+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:04.998+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:04.998+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000046_77' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000046
[2025-07-03T18:02:05.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000046_77: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 46.0 in stage 7.0 (TID 77). 7255 bytes result sent to driver
[2025-07-03T18:02:05.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 78) (39b5ac792cf9, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 47.0 in stage 7.0 (TID 78)
[2025-07-03T18:02:05.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 77) in 17 ms on 39b5ac792cf9 (executor driver) (47/200)
[2025-07-03T18:02:05.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.010+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.011+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.012+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.013+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.014+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.014+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000047_78' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000047
[2025-07-03T18:02:05.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000047_78: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 47.0 in stage 7.0 (TID 78). 7255 bytes result sent to driver
[2025-07-03T18:02:05.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 79) (39b5ac792cf9, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 48.0 in stage 7.0 (TID 79)
[2025-07-03T18:02:05.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 78) in 17 ms on 39b5ac792cf9 (executor driver) (48/200)
[2025-07-03T18:02:05.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.026+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.027+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.028+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.029+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000048_79' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000048
[2025-07-03T18:02:05.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000048_79: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 48.0 in stage 7.0 (TID 79). 7255 bytes result sent to driver
[2025-07-03T18:02:05.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 80) (39b5ac792cf9, executor driver, partition 49, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 79) in 17 ms on 39b5ac792cf9 (executor driver) (49/200)
[2025-07-03T18:02:05.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 49.0 in stage 7.0 (TID 80)
[2025-07-03T18:02:05.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.043+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.044+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.045+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.046+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.050+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000049_80' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000049
[2025-07-03T18:02:05.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000049_80: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 49.0 in stage 7.0 (TID 80). 7255 bytes result sent to driver
[2025-07-03T18:02:05.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 81) (39b5ac792cf9, executor driver, partition 50, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.054+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 50.0 in stage 7.0 (TID 81)
[2025-07-03T18:02:05.054+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 80) in 16 ms on 39b5ac792cf9 (executor driver) (50/200)
[2025-07-03T18:02:05.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.2 KiB) non-empty blocks including 7 (11.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.057+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.058+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.059+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.060+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.061+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.062+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.062+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.062+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.062+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.062+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.062+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000050_81' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000050
[2025-07-03T18:02:05.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000050_81: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 50.0 in stage 7.0 (TID 81). 7255 bytes result sent to driver
[2025-07-03T18:02:05.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 82) (39b5ac792cf9, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.070+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 51.0 in stage 7.0 (TID 82)
[2025-07-03T18:02:05.070+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 81) in 17 ms on 39b5ac792cf9 (executor driver) (51/200)
[2025-07-03T18:02:05.071+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.2 KiB) non-empty blocks including 7 (10.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.071+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.071+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.071+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.072+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.072+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.074+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.075+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.076+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.077+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.078+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.078+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.078+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.078+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.078+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.078+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.082+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000051_82' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000051
[2025-07-03T18:02:05.082+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000051_82: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.082+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 51.0 in stage 7.0 (TID 82). 7255 bytes result sent to driver
[2025-07-03T18:02:05.086+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 83) (39b5ac792cf9, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.086+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 52.0 in stage 7.0 (TID 83)
[2025-07-03T18:02:05.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 82) in 16 ms on 39b5ac792cf9 (executor driver) (52/200)
[2025-07-03T18:02:05.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.088+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.088+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.090+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.091+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.092+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.093+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.094+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.094+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.094+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.094+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.094+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.094+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.094+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.098+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000052_83' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000052
[2025-07-03T18:02:05.098+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000052_83: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.098+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 52.0 in stage 7.0 (TID 83). 7255 bytes result sent to driver
[2025-07-03T18:02:05.098+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 84) (39b5ac792cf9, executor driver, partition 53, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.099+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 53.0 in stage 7.0 (TID 84)
[2025-07-03T18:02:05.102+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 83) in 17 ms on 39b5ac792cf9 (executor driver) (53/200)
[2025-07-03T18:02:05.102+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.104+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.104+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.104+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.105+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.105+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.106+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.107+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.108+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.109+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.110+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.110+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.110+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.110+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.110+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.110+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.110+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.113+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000053_84' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000053
[2025-07-03T18:02:05.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000053_84: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 53.0 in stage 7.0 (TID 84). 7255 bytes result sent to driver
[2025-07-03T18:02:05.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 85) (39b5ac792cf9, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.117+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 54.0 in stage 7.0 (TID 85)
[2025-07-03T18:02:05.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 84) in 16 ms on 39b5ac792cf9 (executor driver) (54/200)
[2025-07-03T18:02:05.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.1 KiB) non-empty blocks including 7 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.120+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.121+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.121+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.121+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.122+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.123+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.124+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.125+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.126+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.126+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.126+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.126+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.126+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.126+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000054_85' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000054
[2025-07-03T18:02:05.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000054_85: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 54.0 in stage 7.0 (TID 85). 7255 bytes result sent to driver
[2025-07-03T18:02:05.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 86) (39b5ac792cf9, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 55.0 in stage 7.0 (TID 86)
[2025-07-03T18:02:05.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 85) in 17 ms on 39b5ac792cf9 (executor driver) (55/200)
[2025-07-03T18:02:05.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.7 KiB) non-empty blocks including 7 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.137+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.138+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.138+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.139+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.139+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.140+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.141+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.142+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.142+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.142+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.142+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.142+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.142+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.143+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.143+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.143+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.143+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.143+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.143+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.143+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.144+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.145+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.145+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.145+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.145+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.145+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.145+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.145+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.146+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.146+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.146+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.146+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.146+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.146+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.147+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.147+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.147+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.147+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000055_86' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000055
[2025-07-03T18:02:05.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000055_86: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 55.0 in stage 7.0 (TID 86). 7255 bytes result sent to driver
[2025-07-03T18:02:05.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 87) (39b5ac792cf9, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.155+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 56.0 in stage 7.0 (TID 87)
[2025-07-03T18:02:05.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 86) in 21 ms on 39b5ac792cf9 (executor driver) (56/200)
[2025-07-03T18:02:05.157+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.4 KiB) non-empty blocks including 7 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.158+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.160+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.160+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.161+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.161+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.161+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.161+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.161+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.162+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.163+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.164+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.165+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.166+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.167+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000056_87' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000056
[2025-07-03T18:02:05.172+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000056_87: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.173+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 56.0 in stage 7.0 (TID 87). 7255 bytes result sent to driver
[2025-07-03T18:02:05.173+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 88) (39b5ac792cf9, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.174+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 57.0 in stage 7.0 (TID 88)
[2025-07-03T18:02:05.174+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 87) in 21 ms on 39b5ac792cf9 (executor driver) (57/200)
[2025-07-03T18:02:05.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.181+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.181+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.181+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.181+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.182+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.183+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.184+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.185+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.186+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.186+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000057_88' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000057
[2025-07-03T18:02:05.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000057_88: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 57.0 in stage 7.0 (TID 88). 7255 bytes result sent to driver
[2025-07-03T18:02:05.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 89) (39b5ac792cf9, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.191+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 58.0 in stage 7.0 (TID 89)
[2025-07-03T18:02:05.191+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 88) in 18 ms on 39b5ac792cf9 (executor driver) (58/200)
[2025-07-03T18:02:05.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.4 KiB) non-empty blocks including 7 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.198+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.199+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.200+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.201+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.202+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000058_89' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000058
[2025-07-03T18:02:05.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000058_89: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 58.0 in stage 7.0 (TID 89). 7255 bytes result sent to driver
[2025-07-03T18:02:05.207+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 90) (39b5ac792cf9, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 59.0 in stage 7.0 (TID 90)
[2025-07-03T18:02:05.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 89) in 17 ms on 39b5ac792cf9 (executor driver) (59/200)
[2025-07-03T18:02:05.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.216+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.217+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.218+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.219+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.220+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.220+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.220+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.220+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.223+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000059_90' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000059
[2025-07-03T18:02:05.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000059_90: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 59.0 in stage 7.0 (TID 90). 7255 bytes result sent to driver
[2025-07-03T18:02:05.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 91) (39b5ac792cf9, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 60.0 in stage 7.0 (TID 91)
[2025-07-03T18:02:05.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 90) in 18 ms on 39b5ac792cf9 (executor driver) (60/200)
[2025-07-03T18:02:05.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (13.6 KiB) non-empty blocks including 7 (13.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.231+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.231+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.233+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.234+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.235+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.236+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.237+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.237+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.237+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.237+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.237+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.237+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000060_91' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000060
[2025-07-03T18:02:05.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000060_91: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 60.0 in stage 7.0 (TID 91). 7255 bytes result sent to driver
[2025-07-03T18:02:05.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 92) (39b5ac792cf9, executor driver, partition 61, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 61.0 in stage 7.0 (TID 92)
[2025-07-03T18:02:05.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 91) in 17 ms on 39b5ac792cf9 (executor driver) (61/200)
[2025-07-03T18:02:05.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.8 KiB) non-empty blocks including 7 (11.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.250+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.251+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.252+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.253+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.254+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000061_92' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000061
[2025-07-03T18:02:05.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000061_92: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 61.0 in stage 7.0 (TID 92). 7255 bytes result sent to driver
[2025-07-03T18:02:05.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 93) (39b5ac792cf9, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.260+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 92) in 19 ms on 39b5ac792cf9 (executor driver) (62/200)
[2025-07-03T18:02:05.263+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 62.0 in stage 7.0 (TID 93)
[2025-07-03T18:02:05.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.270+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.271+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.272+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.273+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.274+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.282+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000062_93' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000062
[2025-07-03T18:02:05.282+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000062_93: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 62.0 in stage 7.0 (TID 93). 7298 bytes result sent to driver
[2025-07-03T18:02:05.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 94) (39b5ac792cf9, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 63.0 in stage 7.0 (TID 94)
[2025-07-03T18:02:05.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 93) in 23 ms on 39b5ac792cf9 (executor driver) (63/200)
[2025-07-03T18:02:05.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.288+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.289+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.290+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.290+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.291+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.292+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.293+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.294+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000063_94' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000063
[2025-07-03T18:02:05.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000063_94: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 63.0 in stage 7.0 (TID 94). 7255 bytes result sent to driver
[2025-07-03T18:02:05.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 95) (39b5ac792cf9, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 64.0 in stage 7.0 (TID 95)
[2025-07-03T18:02:05.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 94) in 17 ms on 39b5ac792cf9 (executor driver) (64/200)
[2025-07-03T18:02:05.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.305+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.305+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.305+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.305+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.305+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.305+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.306+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.307+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.308+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.309+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.312+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000064_95' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000064
[2025-07-03T18:02:05.313+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000064_95: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.313+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 64.0 in stage 7.0 (TID 95). 7255 bytes result sent to driver
[2025-07-03T18:02:05.313+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 96) (39b5ac792cf9, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.314+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 65.0 in stage 7.0 (TID 96)
[2025-07-03T18:02:05.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 95) in 15 ms on 39b5ac792cf9 (executor driver) (65/200)
[2025-07-03T18:02:05.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.8 KiB) non-empty blocks including 7 (10.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.320+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.322+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.323+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000065_96' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000065
[2025-07-03T18:02:05.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000065_96: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 65.0 in stage 7.0 (TID 96). 7255 bytes result sent to driver
[2025-07-03T18:02:05.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 97) (39b5ac792cf9, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 66.0 in stage 7.0 (TID 97)
[2025-07-03T18:02:05.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 96) in 16 ms on 39b5ac792cf9 (executor driver) (66/200)
[2025-07-03T18:02:05.335+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.4 KiB) non-empty blocks including 7 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.338+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.339+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.340+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.341+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.342+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.342+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.342+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.342+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.342+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.342+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000066_97' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000066
[2025-07-03T18:02:05.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000066_97: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 66.0 in stage 7.0 (TID 97). 7255 bytes result sent to driver
[2025-07-03T18:02:05.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 98) (39b5ac792cf9, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 67.0 in stage 7.0 (TID 98)
[2025-07-03T18:02:05.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 97) in 17 ms on 39b5ac792cf9 (executor driver) (67/200)
[2025-07-03T18:02:05.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.351+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.353+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.354+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.355+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.356+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000067_98' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000067
[2025-07-03T18:02:05.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000067_98: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 67.0 in stage 7.0 (TID 98). 7255 bytes result sent to driver
[2025-07-03T18:02:05.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 99) (39b5ac792cf9, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 68.0 in stage 7.0 (TID 99)
[2025-07-03T18:02:05.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 98) in 14 ms on 39b5ac792cf9 (executor driver) (68/200)
[2025-07-03T18:02:05.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (12.2 KiB) non-empty blocks including 7 (12.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.366+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.366+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.366+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.367+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.367+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.368+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.369+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.370+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.371+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000068_99' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000068
[2025-07-03T18:02:05.375+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000068_99: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.375+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 68.0 in stage 7.0 (TID 99). 7255 bytes result sent to driver
[2025-07-03T18:02:05.375+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 100) (39b5ac792cf9, executor driver, partition 69, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.378+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 69.0 in stage 7.0 (TID 100)
[2025-07-03T18:02:05.379+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 99) in 15 ms on 39b5ac792cf9 (executor driver) (69/200)
[2025-07-03T18:02:05.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.2 KiB) non-empty blocks including 7 (11.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.382+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.383+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.384+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.385+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.389+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000069_100' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000069
[2025-07-03T18:02:05.389+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000069_100: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.389+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 69.0 in stage 7.0 (TID 100). 7255 bytes result sent to driver
[2025-07-03T18:02:05.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 101) (39b5ac792cf9, executor driver, partition 70, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.393+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 100) in 15 ms on 39b5ac792cf9 (executor driver) (70/200)
[2025-07-03T18:02:05.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 70.0 in stage 7.0 (TID 101)
[2025-07-03T18:02:05.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.5 KiB) non-empty blocks including 7 (10.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.396+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.396+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.397+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.398+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.399+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.400+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.401+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.404+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000070_101' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000070
[2025-07-03T18:02:05.404+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000070_101: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.404+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 70.0 in stage 7.0 (TID 101). 7255 bytes result sent to driver
[2025-07-03T18:02:05.404+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 102) (39b5ac792cf9, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 71.0 in stage 7.0 (TID 102)
[2025-07-03T18:02:05.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 101) in 15 ms on 39b5ac792cf9 (executor driver) (71/200)
[2025-07-03T18:02:05.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.410+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.410+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.411+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.412+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.413+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.414+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.415+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.415+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.415+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.415+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.415+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.415+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.418+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000071_102' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000071
[2025-07-03T18:02:05.419+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000071_102: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.419+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 71.0 in stage 7.0 (TID 102). 7255 bytes result sent to driver
[2025-07-03T18:02:05.419+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 103) (39b5ac792cf9, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 72.0 in stage 7.0 (TID 103)
[2025-07-03T18:02:05.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 102) in 15 ms on 39b5ac792cf9 (executor driver) (72/200)
[2025-07-03T18:02:05.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.424+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.424+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.424+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.425+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.426+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.427+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.428+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.429+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.430+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.430+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.430+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.430+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.430+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.430+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.433+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000072_103' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000072
[2025-07-03T18:02:05.434+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000072_103: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.434+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 72.0 in stage 7.0 (TID 103). 7255 bytes result sent to driver
[2025-07-03T18:02:05.434+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 104) (39b5ac792cf9, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 73.0 in stage 7.0 (TID 104)
[2025-07-03T18:02:05.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 103) in 15 ms on 39b5ac792cf9 (executor driver) (73/200)
[2025-07-03T18:02:05.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (12.0 KiB) non-empty blocks including 7 (12.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.438+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.439+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.439+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.439+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.441+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.442+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.443+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.444+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000073_104' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000073
[2025-07-03T18:02:05.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000073_104: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 73.0 in stage 7.0 (TID 104). 7255 bytes result sent to driver
[2025-07-03T18:02:05.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 105) (39b5ac792cf9, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.452+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 74.0 in stage 7.0 (TID 105)
[2025-07-03T18:02:05.452+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 104) in 15 ms on 39b5ac792cf9 (executor driver) (74/200)
[2025-07-03T18:02:05.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.1 KiB) non-empty blocks including 7 (10.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.455+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.456+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.457+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.458+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.459+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.460+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.460+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.465+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000074_105' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000074
[2025-07-03T18:02:05.465+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000074_105: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.465+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 74.0 in stage 7.0 (TID 105). 7255 bytes result sent to driver
[2025-07-03T18:02:05.465+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 106) (39b5ac792cf9, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 75.0 in stage 7.0 (TID 106)
[2025-07-03T18:02:05.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 105) in 18 ms on 39b5ac792cf9 (executor driver) (75/200)
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.472+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.473+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.474+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.475+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.476+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.476+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.476+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.476+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000075_106' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000075
[2025-07-03T18:02:05.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000075_106: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 75.0 in stage 7.0 (TID 106). 7255 bytes result sent to driver
[2025-07-03T18:02:05.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 107) (39b5ac792cf9, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 76.0 in stage 7.0 (TID 107)
[2025-07-03T18:02:05.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 106) in 15 ms on 39b5ac792cf9 (executor driver) (76/200)
[2025-07-03T18:02:05.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.1 KiB) non-empty blocks including 7 (9.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.486+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.487+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.488+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.489+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.490+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.490+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000076_107' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000076
[2025-07-03T18:02:05.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000076_107: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 76.0 in stage 7.0 (TID 107). 7255 bytes result sent to driver
[2025-07-03T18:02:05.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 108) (39b5ac792cf9, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 77.0 in stage 7.0 (TID 108)
[2025-07-03T18:02:05.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 107) in 14 ms on 39b5ac792cf9 (executor driver) (77/200)
[2025-07-03T18:02:05.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.0 KiB) non-empty blocks including 7 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.500+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.501+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.502+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.503+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.504+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000077_108' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000077
[2025-07-03T18:02:05.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000077_108: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 77.0 in stage 7.0 (TID 108). 7255 bytes result sent to driver
[2025-07-03T18:02:05.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 109) (39b5ac792cf9, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.512+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 78.0 in stage 7.0 (TID 109)
[2025-07-03T18:02:05.512+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 108) in 15 ms on 39b5ac792cf9 (executor driver) (78/200)
[2025-07-03T18:02:05.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.9 KiB) non-empty blocks including 7 (11.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.515+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.516+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.517+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.518+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.519+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000078_109' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000078
[2025-07-03T18:02:05.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000078_109: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 78.0 in stage 7.0 (TID 109). 7255 bytes result sent to driver
[2025-07-03T18:02:05.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 110) (39b5ac792cf9, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.526+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 79.0 in stage 7.0 (TID 110)
[2025-07-03T18:02:05.526+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 109) in 14 ms on 39b5ac792cf9 (executor driver) (79/200)
[2025-07-03T18:02:05.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.529+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.530+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.531+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.532+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.533+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000079_110' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000079
[2025-07-03T18:02:05.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000079_110: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 79.0 in stage 7.0 (TID 110). 7255 bytes result sent to driver
[2025-07-03T18:02:05.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 111) (39b5ac792cf9, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 80.0 in stage 7.0 (TID 111)
[2025-07-03T18:02:05.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 110) in 15 ms on 39b5ac792cf9 (executor driver) (80/200)
[2025-07-03T18:02:05.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.1 KiB) non-empty blocks including 7 (10.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.542+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.542+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.542+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.543+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.544+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.545+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.546+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.547+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.547+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.547+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.547+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000080_111' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000080
[2025-07-03T18:02:05.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000080_111: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 80.0 in stage 7.0 (TID 111). 7255 bytes result sent to driver
[2025-07-03T18:02:05.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 112) (39b5ac792cf9, executor driver, partition 81, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 81.0 in stage 7.0 (TID 112)
[2025-07-03T18:02:05.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 111) in 15 ms on 39b5ac792cf9 (executor driver) (81/200)
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.556+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.556+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.557+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.558+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.559+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.560+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.561+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.562+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.562+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.562+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.562+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.562+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.562+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.562+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000081_112' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000081
[2025-07-03T18:02:05.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000081_112: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 81.0 in stage 7.0 (TID 112). 7255 bytes result sent to driver
[2025-07-03T18:02:05.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 113) (39b5ac792cf9, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 82.0 in stage 7.0 (TID 113)
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 112) in 18 ms on 39b5ac792cf9 (executor driver) (82/200)
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (12.5 KiB) non-empty blocks including 7 (12.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.574+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.575+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.576+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.577+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.578+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000082_113' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000082
[2025-07-03T18:02:05.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000082_113: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.583+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 82.0 in stage 7.0 (TID 113). 7255 bytes result sent to driver
[2025-07-03T18:02:05.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 114) (39b5ac792cf9, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 83.0 in stage 7.0 (TID 114)
[2025-07-03T18:02:05.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 113) in 17 ms on 39b5ac792cf9 (executor driver) (83/200)
[2025-07-03T18:02:05.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.6 KiB) non-empty blocks including 7 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.589+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.591+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.592+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.593+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.594+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.595+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000083_114' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000083
[2025-07-03T18:02:05.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000083_114: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 83.0 in stage 7.0 (TID 114). 7341 bytes result sent to driver
[2025-07-03T18:02:05.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 115) (39b5ac792cf9, executor driver, partition 84, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 84.0 in stage 7.0 (TID 115)
[2025-07-03T18:02:05.606+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 114) in 20 ms on 39b5ac792cf9 (executor driver) (84/200)
[2025-07-03T18:02:05.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.4 KiB) non-empty blocks including 7 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.610+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.611+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.612+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.613+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.614+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.614+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.614+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.614+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.614+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.614+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000084_115' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000084
[2025-07-03T18:02:05.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000084_115: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 84.0 in stage 7.0 (TID 115). 7255 bytes result sent to driver
[2025-07-03T18:02:05.621+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 116) (39b5ac792cf9, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.621+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 85.0 in stage 7.0 (TID 116)
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 115) in 15 ms on 39b5ac792cf9 (executor driver) (85/200)
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.624+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.625+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.626+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.627+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.631+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000085_116' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000085
[2025-07-03T18:02:05.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000085_116: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 85.0 in stage 7.0 (TID 116). 7255 bytes result sent to driver
[2025-07-03T18:02:05.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 117) (39b5ac792cf9, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 86.0 in stage 7.0 (TID 117)
[2025-07-03T18:02:05.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 116) in 15 ms on 39b5ac792cf9 (executor driver) (86/200)
[2025-07-03T18:02:05.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.2 KiB) non-empty blocks including 7 (11.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.638+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.638+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.638+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.639+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.640+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.640+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.640+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.640+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.640+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.640+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.640+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.641+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.642+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.643+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.643+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.643+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.643+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000086_117' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000086
[2025-07-03T18:02:05.647+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000086_117: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.647+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 86.0 in stage 7.0 (TID 117). 7255 bytes result sent to driver
[2025-07-03T18:02:05.647+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 118) (39b5ac792cf9, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 117) in 15 ms on 39b5ac792cf9 (executor driver) (87/200)
[2025-07-03T18:02:05.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 87.0 in stage 7.0 (TID 118)
[2025-07-03T18:02:05.654+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.656+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.657+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.658+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.658+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.662+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.662+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.663+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.664+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.664+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.665+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.665+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.665+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.666+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.667+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.667+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.668+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.668+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.669+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.669+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.669+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.670+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.671+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.671+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.671+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.671+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.672+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.672+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.673+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.674+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.675+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.676+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.676+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.676+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.678+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.680+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.682+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.683+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.683+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.684+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.686+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.688+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.690+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.691+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.692+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.692+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.694+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.694+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.695+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.695+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.695+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.695+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.696+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.696+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.697+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.697+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.697+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.698+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000087_118' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000087
[2025-07-03T18:02:05.699+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000087_118: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.700+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 87.0 in stage 7.0 (TID 118). 7255 bytes result sent to driver
[2025-07-03T18:02:05.700+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 119) (39b5ac792cf9, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 88.0 in stage 7.0 (TID 119)
[2025-07-03T18:02:05.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 118) in 53 ms on 39b5ac792cf9 (executor driver) (88/200)
[2025-07-03T18:02:05.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.717+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.717+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.717+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.722+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.723+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.723+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.723+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.723+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.724+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.725+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.726+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.726+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.726+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.726+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.726+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.726+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.726+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.727+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.727+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.727+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.727+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.727+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.727+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.728+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.729+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.729+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.729+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000088_119' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000088
[2025-07-03T18:02:05.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000088_119: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 88.0 in stage 7.0 (TID 119). 7255 bytes result sent to driver
[2025-07-03T18:02:05.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 120) (39b5ac792cf9, executor driver, partition 89, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 89.0 in stage 7.0 (TID 120)
[2025-07-03T18:02:05.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 119) in 36 ms on 39b5ac792cf9 (executor driver) (89/200)
[2025-07-03T18:02:05.740+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.8 KiB) non-empty blocks including 7 (9.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.740+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.743+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.743+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.744+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.745+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.746+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.746+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.746+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.746+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.747+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.748+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.749+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.749+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000089_120' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000089
[2025-07-03T18:02:05.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000089_120: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 89.0 in stage 7.0 (TID 120). 7255 bytes result sent to driver
[2025-07-03T18:02:05.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 121) (39b5ac792cf9, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 90.0 in stage 7.0 (TID 121)
[2025-07-03T18:02:05.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 120) in 18 ms on 39b5ac792cf9 (executor driver) (90/200)
[2025-07-03T18:02:05.760+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.760+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.762+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.765+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.765+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.765+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.765+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.765+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.766+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.766+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.766+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.766+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.766+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.766+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.766+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.767+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.768+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.768+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.768+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.768+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.768+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.768+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.769+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.769+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.769+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.769+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.769+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.769+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.769+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.770+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.771+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.771+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.771+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.771+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.772+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000090_121' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000090
[2025-07-03T18:02:05.774+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000090_121: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.774+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 90.0 in stage 7.0 (TID 121). 7255 bytes result sent to driver
[2025-07-03T18:02:05.774+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 122) (39b5ac792cf9, executor driver, partition 91, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 91.0 in stage 7.0 (TID 122)
[2025-07-03T18:02:05.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 121) in 20 ms on 39b5ac792cf9 (executor driver) (91/200)
[2025-07-03T18:02:05.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.1 KiB) non-empty blocks including 7 (9.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-03T18:02:05.786+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.787+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.787+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.787+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.788+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.788+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.791+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.792+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.793+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.794+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.795+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000091_122' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000091
[2025-07-03T18:02:05.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000091_122: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 91.0 in stage 7.0 (TID 122). 7255 bytes result sent to driver
[2025-07-03T18:02:05.800+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 123) (39b5ac792cf9, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.800+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 122) in 26 ms on 39b5ac792cf9 (executor driver) (92/200)
[2025-07-03T18:02:05.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 92.0 in stage 7.0 (TID 123)
[2025-07-03T18:02:05.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.807+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.808+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.809+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.810+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.811+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.811+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.811+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.811+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.811+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.811+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.811+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.815+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000092_123' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000092
[2025-07-03T18:02:05.815+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000092_123: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.815+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 92.0 in stage 7.0 (TID 123). 7255 bytes result sent to driver
[2025-07-03T18:02:05.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 124) (39b5ac792cf9, executor driver, partition 93, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.819+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 93.0 in stage 7.0 (TID 124)
[2025-07-03T18:02:05.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 123) in 17 ms on 39b5ac792cf9 (executor driver) (93/200)
[2025-07-03T18:02:05.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.822+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.822+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.822+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.822+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.823+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.824+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.825+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.826+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.826+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000093_124' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000093
[2025-07-03T18:02:05.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000093_124: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 93.0 in stage 7.0 (TID 124). 7255 bytes result sent to driver
[2025-07-03T18:02:05.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 125) (39b5ac792cf9, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 94.0 in stage 7.0 (TID 125)
[2025-07-03T18:02:05.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 124) in 15 ms on 39b5ac792cf9 (executor driver) (94/200)
[2025-07-03T18:02:05.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.5 KiB) non-empty blocks including 7 (10.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.838+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.839+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.840+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.841+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.842+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.845+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000094_125' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000094
[2025-07-03T18:02:05.845+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000094_125: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 94.0 in stage 7.0 (TID 125). 7255 bytes result sent to driver
[2025-07-03T18:02:05.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 126) (39b5ac792cf9, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 95.0 in stage 7.0 (TID 126)
[2025-07-03T18:02:05.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 125) in 16 ms on 39b5ac792cf9 (executor driver) (95/200)
[2025-07-03T18:02:05.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.4 KiB) non-empty blocks including 7 (9.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.853+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.854+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.855+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.856+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.857+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.857+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.857+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.857+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.860+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000095_126' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000095
[2025-07-03T18:02:05.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000095_126: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 95.0 in stage 7.0 (TID 126). 7255 bytes result sent to driver
[2025-07-03T18:02:05.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 127) (39b5ac792cf9, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 126) in 16 ms on 39b5ac792cf9 (executor driver) (96/200)
[2025-07-03T18:02:05.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 96.0 in stage 7.0 (TID 127)
[2025-07-03T18:02:05.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.867+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.869+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.870+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.871+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.872+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.875+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000096_127' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000096
[2025-07-03T18:02:05.875+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000096_127: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.876+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 96.0 in stage 7.0 (TID 127). 7255 bytes result sent to driver
[2025-07-03T18:02:05.876+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 128) (39b5ac792cf9, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.877+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 97.0 in stage 7.0 (TID 128)
[2025-07-03T18:02:05.877+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 127) in 15 ms on 39b5ac792cf9 (executor driver) (97/200)
[2025-07-03T18:02:05.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (13.3 KiB) non-empty blocks including 7 (13.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.883+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.884+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.885+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.886+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.887+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.887+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.887+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.890+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000097_128' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000097
[2025-07-03T18:02:05.891+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000097_128: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.891+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 97.0 in stage 7.0 (TID 128). 7255 bytes result sent to driver
[2025-07-03T18:02:05.891+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 129) (39b5ac792cf9, executor driver, partition 98, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 98.0 in stage 7.0 (TID 129)
[2025-07-03T18:02:05.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 128) in 15 ms on 39b5ac792cf9 (executor driver) (98/200)
[2025-07-03T18:02:05.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.898+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.898+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.898+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.899+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.900+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.901+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.902+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.903+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000098_129' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000098
[2025-07-03T18:02:05.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000098_129: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 98.0 in stage 7.0 (TID 129). 7255 bytes result sent to driver
[2025-07-03T18:02:05.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 130) (39b5ac792cf9, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 99.0 in stage 7.0 (TID 130)
[2025-07-03T18:02:05.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 129) in 16 ms on 39b5ac792cf9 (executor driver) (99/200)
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.915+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.916+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.917+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.918+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000099_130' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000099
[2025-07-03T18:02:05.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000099_130: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 99.0 in stage 7.0 (TID 130). 7255 bytes result sent to driver
[2025-07-03T18:02:05.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 131) (39b5ac792cf9, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 100.0 in stage 7.0 (TID 131)
[2025-07-03T18:02:05.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 130) in 15 ms on 39b5ac792cf9 (executor driver) (100/200)
[2025-07-03T18:02:05.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.7 KiB) non-empty blocks including 7 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.930+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.931+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.932+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.933+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000100_131' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000100
[2025-07-03T18:02:05.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000100_131: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 100.0 in stage 7.0 (TID 131). 7255 bytes result sent to driver
[2025-07-03T18:02:05.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 132) (39b5ac792cf9, executor driver, partition 101, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 101.0 in stage 7.0 (TID 132)
[2025-07-03T18:02:05.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 131) in 16 ms on 39b5ac792cf9 (executor driver) (101/200)
[2025-07-03T18:02:05.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.944+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.945+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.946+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.947+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000101_132' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000101
[2025-07-03T18:02:05.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000101_132: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 101.0 in stage 7.0 (TID 132). 7255 bytes result sent to driver
[2025-07-03T18:02:05.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 133) (39b5ac792cf9, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 102.0 in stage 7.0 (TID 133)
[2025-07-03T18:02:05.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 132) in 15 ms on 39b5ac792cf9 (executor driver) (102/200)
[2025-07-03T18:02:05.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (12.1 KiB) non-empty blocks including 7 (12.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.959+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.960+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.961+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.962+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.963+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.963+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.963+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.963+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000102_133' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000102
[2025-07-03T18:02:05.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000102_133: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 102.0 in stage 7.0 (TID 133). 7255 bytes result sent to driver
[2025-07-03T18:02:05.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 134) (39b5ac792cf9, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 103.0 in stage 7.0 (TID 134)
[2025-07-03T18:02:05.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 133) in 16 ms on 39b5ac792cf9 (executor driver) (103/200)
[2025-07-03T18:02:05.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.975+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.976+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.977+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.978+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.979+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000103_134' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000103
[2025-07-03T18:02:05.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000103_134: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 103.0 in stage 7.0 (TID 134). 7255 bytes result sent to driver
[2025-07-03T18:02:05.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 135) (39b5ac792cf9, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:05.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 104.0 in stage 7.0 (TID 135)
[2025-07-03T18:02:05.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 134) in 16 ms on 39b5ac792cf9 (executor driver) (104/200)
[2025-07-03T18:02:05.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Getting 7 (11.2 KiB) non-empty blocks including 7 (11.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:05.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:05.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:05.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:05.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:05.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:05.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:05.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.990+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.991+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.992+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:05.993+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:05.994+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.994+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:05.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000104_135' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000104
[2025-07-03T18:02:05.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000104_135: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:05.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Finished task 104.0 in stage 7.0 (TID 135). 7255 bytes result sent to driver
[2025-07-03T18:02:05.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 136) (39b5ac792cf9, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO Executor: Running task 105.0 in stage 7.0 (TID 136)
[2025-07-03T18:02:06.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:05 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 135) in 15 ms on 39b5ac792cf9 (executor driver) (105/200)
[2025-07-03T18:02:06.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (12.1 KiB) non-empty blocks including 7 (12.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.004+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.004+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.004+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.005+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.006+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.007+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.008+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.008+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.008+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.008+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.008+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.008+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000105_136' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000105
[2025-07-03T18:02:06.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000105_136: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 105.0 in stage 7.0 (TID 136). 7298 bytes result sent to driver
[2025-07-03T18:02:06.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 137) (39b5ac792cf9, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 106.0 in stage 7.0 (TID 137)
[2025-07-03T18:02:06.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 136) in 21 ms on 39b5ac792cf9 (executor driver) (106/200)
[2025-07-03T18:02:06.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.027+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.028+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.028+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.028+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.028+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.028+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.029+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.030+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.031+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.032+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000106_137' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000106
[2025-07-03T18:02:06.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000106_137: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 106.0 in stage 7.0 (TID 137). 7255 bytes result sent to driver
[2025-07-03T18:02:06.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 138) (39b5ac792cf9, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 107.0 in stage 7.0 (TID 138)
[2025-07-03T18:02:06.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 137) in 18 ms on 39b5ac792cf9 (executor driver) (107/200)
[2025-07-03T18:02:06.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.044+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.045+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.046+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.047+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.048+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000107_138' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000107
[2025-07-03T18:02:06.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000107_138: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 107.0 in stage 7.0 (TID 138). 7255 bytes result sent to driver
[2025-07-03T18:02:06.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 139) (39b5ac792cf9, executor driver, partition 108, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 108.0 in stage 7.0 (TID 139)
[2025-07-03T18:02:06.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 138) in 17 ms on 39b5ac792cf9 (executor driver) (108/200)
[2025-07-03T18:02:06.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (8.9 KiB) non-empty blocks including 7 (8.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.061+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.062+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.063+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.064+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.065+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.065+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.065+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.069+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000108_139' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000108
[2025-07-03T18:02:06.069+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000108_139: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.069+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 108.0 in stage 7.0 (TID 139). 7255 bytes result sent to driver
[2025-07-03T18:02:06.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 140) (39b5ac792cf9, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 109.0 in stage 7.0 (TID 140)
[2025-07-03T18:02:06.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 139) in 17 ms on 39b5ac792cf9 (executor driver) (109/200)
[2025-07-03T18:02:06.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.076+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.076+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.076+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.077+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.078+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.079+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.080+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.081+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.082+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.082+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.082+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.082+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000109_140' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000109
[2025-07-03T18:02:06.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000109_140: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 109.0 in stage 7.0 (TID 140). 7255 bytes result sent to driver
[2025-07-03T18:02:06.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 141) (39b5ac792cf9, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 110.0 in stage 7.0 (TID 141)
[2025-07-03T18:02:06.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 140) in 16 ms on 39b5ac792cf9 (executor driver) (110/200)
[2025-07-03T18:02:06.091+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (14.3 KiB) non-empty blocks including 7 (14.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.091+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.092+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.092+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.093+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.094+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.095+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.096+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.097+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.098+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.098+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000110_141' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000110
[2025-07-03T18:02:06.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000110_141: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 110.0 in stage 7.0 (TID 141). 7255 bytes result sent to driver
[2025-07-03T18:02:06.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 142) (39b5ac792cf9, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.105+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 111.0 in stage 7.0 (TID 142)
[2025-07-03T18:02:06.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 141) in 17 ms on 39b5ac792cf9 (executor driver) (111/200)
[2025-07-03T18:02:06.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.6 KiB) non-empty blocks including 7 (11.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.109+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.110+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.111+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.111+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.111+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.111+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.111+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.111+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.111+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.112+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.113+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.114+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000111_142' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000111
[2025-07-03T18:02:06.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000111_142: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.120+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 111.0 in stage 7.0 (TID 142). 7255 bytes result sent to driver
[2025-07-03T18:02:06.120+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 143) (39b5ac792cf9, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.123+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 112.0 in stage 7.0 (TID 143)
[2025-07-03T18:02:06.124+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 142) in 19 ms on 39b5ac792cf9 (executor driver) (112/200)
[2025-07-03T18:02:06.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.132+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.132+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.132+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.132+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.133+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.133+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.133+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.133+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.133+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.133+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.133+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.134+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.135+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.136+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.137+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.141+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000112_143' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000112
[2025-07-03T18:02:06.141+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000112_143: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.141+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 112.0 in stage 7.0 (TID 143). 7255 bytes result sent to driver
[2025-07-03T18:02:06.142+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 144) (39b5ac792cf9, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.142+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 113.0 in stage 7.0 (TID 144)
[2025-07-03T18:02:06.142+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 143) in 23 ms on 39b5ac792cf9 (executor driver) (113/200)
[2025-07-03T18:02:06.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.148+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.149+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.149+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.150+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.150+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.150+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.150+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.151+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.152+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.153+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.154+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.158+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000113_144' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000113
[2025-07-03T18:02:06.158+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000113_144: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.158+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 113.0 in stage 7.0 (TID 144). 7255 bytes result sent to driver
[2025-07-03T18:02:06.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 145) (39b5ac792cf9, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 114.0 in stage 7.0 (TID 145)
[2025-07-03T18:02:06.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 144) in 18 ms on 39b5ac792cf9 (executor driver) (114/200)
[2025-07-03T18:02:06.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.186+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.186+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.186+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.186+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.186+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.186+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.187+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.188+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.189+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.190+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.191+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.191+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.191+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.191+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.191+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.191+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.194+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000114_145' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000114
[2025-07-03T18:02:06.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000114_145: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 114.0 in stage 7.0 (TID 145). 7255 bytes result sent to driver
[2025-07-03T18:02:06.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 146) (39b5ac792cf9, executor driver, partition 115, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.199+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 115.0 in stage 7.0 (TID 146)
[2025-07-03T18:02:06.199+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 145) in 37 ms on 39b5ac792cf9 (executor driver) (115/200)
[2025-07-03T18:02:06.201+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (8.9 KiB) non-empty blocks including 7 (8.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.204+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.205+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.206+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.207+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000115_146' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000115
[2025-07-03T18:02:06.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000115_146: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 115.0 in stage 7.0 (TID 146). 7255 bytes result sent to driver
[2025-07-03T18:02:06.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 147) (39b5ac792cf9, executor driver, partition 116, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 116.0 in stage 7.0 (TID 147)
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 146) in 16 ms on 39b5ac792cf9 (executor driver) (116/200)
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.5 KiB) non-empty blocks including 7 (10.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.217+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.217+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.218+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.219+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.220+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.221+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000116_147' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000116
[2025-07-03T18:02:06.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000116_147: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 116.0 in stage 7.0 (TID 147). 7255 bytes result sent to driver
[2025-07-03T18:02:06.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 148) (39b5ac792cf9, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.228+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 117.0 in stage 7.0 (TID 148)
[2025-07-03T18:02:06.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 147) in 14 ms on 39b5ac792cf9 (executor driver) (117/200)
[2025-07-03T18:02:06.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.231+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.232+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.233+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.234+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.235+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.236+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.236+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.236+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.236+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.236+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.239+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000117_148' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000117
[2025-07-03T18:02:06.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000117_148: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 117.0 in stage 7.0 (TID 148). 7255 bytes result sent to driver
[2025-07-03T18:02:06.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 149) (39b5ac792cf9, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.243+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 118.0 in stage 7.0 (TID 149)
[2025-07-03T18:02:06.243+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 148) in 15 ms on 39b5ac792cf9 (executor driver) (118/200)
[2025-07-03T18:02:06.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.246+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.246+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.247+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.247+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.247+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.247+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.248+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.249+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.250+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.251+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.251+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.251+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.251+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.251+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.251+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.254+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000118_149' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000118
[2025-07-03T18:02:06.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000118_149: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 118.0 in stage 7.0 (TID 149). 7255 bytes result sent to driver
[2025-07-03T18:02:06.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 150) (39b5ac792cf9, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.258+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 119.0 in stage 7.0 (TID 150)
[2025-07-03T18:02:06.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 149) in 15 ms on 39b5ac792cf9 (executor driver) (119/200)
[2025-07-03T18:02:06.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.4 KiB) non-empty blocks including 7 (10.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.260+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.261+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.261+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.261+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.262+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.263+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.264+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.265+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.266+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000119_150' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000119
[2025-07-03T18:02:06.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000119_150: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 119.0 in stage 7.0 (TID 150). 7255 bytes result sent to driver
[2025-07-03T18:02:06.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 151) (39b5ac792cf9, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.270+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 150) in 14 ms on 39b5ac792cf9 (executor driver) (120/200)
[2025-07-03T18:02:06.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 120.0 in stage 7.0 (TID 151)
[2025-07-03T18:02:06.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.4 KiB) non-empty blocks including 7 (9.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.278+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.278+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.278+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.278+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.278+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.278+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.278+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.279+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.280+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.281+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.282+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.286+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000120_151' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000120
[2025-07-03T18:02:06.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000120_151: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 120.0 in stage 7.0 (TID 151). 7255 bytes result sent to driver
[2025-07-03T18:02:06.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 152) (39b5ac792cf9, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 121.0 in stage 7.0 (TID 152)
[2025-07-03T18:02:06.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 151) in 18 ms on 39b5ac792cf9 (executor driver) (121/200)
[2025-07-03T18:02:06.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.6 KiB) non-empty blocks including 7 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.297+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.298+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.299+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.300+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.300+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.300+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.300+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.300+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.300+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.300+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.301+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.302+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.303+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.304+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.304+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.304+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.307+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000121_152' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000121
[2025-07-03T18:02:06.308+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000121_152: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.308+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 121.0 in stage 7.0 (TID 152). 7255 bytes result sent to driver
[2025-07-03T18:02:06.308+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 153) (39b5ac792cf9, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.312+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 122.0 in stage 7.0 (TID 153)
[2025-07-03T18:02:06.312+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 152) in 22 ms on 39b5ac792cf9 (executor driver) (122/200)
[2025-07-03T18:02:06.314+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.315+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.316+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.318+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.318+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.318+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.318+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.318+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.319+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.320+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.321+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.321+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.321+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.322+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.323+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.324+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.324+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.324+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000122_153' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000122
[2025-07-03T18:02:06.330+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000122_153: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.330+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 122.0 in stage 7.0 (TID 153). 7255 bytes result sent to driver
[2025-07-03T18:02:06.331+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 154) (39b5ac792cf9, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 123.0 in stage 7.0 (TID 154)
[2025-07-03T18:02:06.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 153) in 23 ms on 39b5ac792cf9 (executor driver) (123/200)
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.7 KiB) non-empty blocks including 7 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.338+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.338+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.338+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.339+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.340+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.340+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.340+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.340+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.341+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.341+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.341+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.341+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.341+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.341+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.342+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.343+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.344+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.344+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.344+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.344+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.344+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.344+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.344+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000123_154' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000123
[2025-07-03T18:02:06.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000123_154: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 123.0 in stage 7.0 (TID 154). 7255 bytes result sent to driver
[2025-07-03T18:02:06.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 155) (39b5ac792cf9, executor driver, partition 124, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.351+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 124.0 in stage 7.0 (TID 155)
[2025-07-03T18:02:06.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 154) in 18 ms on 39b5ac792cf9 (executor driver) (124/200)
[2025-07-03T18:02:06.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.8 KiB) non-empty blocks including 7 (11.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.355+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.355+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.355+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.355+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.356+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.357+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.358+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.359+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.359+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.359+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.359+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.359+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000124_155' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000124
[2025-07-03T18:02:06.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000124_155: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 124.0 in stage 7.0 (TID 155). 7255 bytes result sent to driver
[2025-07-03T18:02:06.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 156) (39b5ac792cf9, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.367+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 125.0 in stage 7.0 (TID 156)
[2025-07-03T18:02:06.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 155) in 15 ms on 39b5ac792cf9 (executor driver) (125/200)
[2025-07-03T18:02:06.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.369+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.369+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.370+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.371+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.372+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.373+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.374+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.378+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000125_156' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000125
[2025-07-03T18:02:06.378+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000125_156: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 125.0 in stage 7.0 (TID 156). 7255 bytes result sent to driver
[2025-07-03T18:02:06.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 157) (39b5ac792cf9, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 126.0 in stage 7.0 (TID 157)
[2025-07-03T18:02:06.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 156) in 16 ms on 39b5ac792cf9 (executor driver) (126/200)
[2025-07-03T18:02:06.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.7 KiB) non-empty blocks including 7 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.384+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.386+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.387+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.388+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.388+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.388+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.388+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.388+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.388+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.388+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.389+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.389+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.389+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.389+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.389+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.389+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.389+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.390+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.390+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.390+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.390+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.390+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.390+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.390+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.391+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.392+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.402+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000126_157' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000126
[2025-07-03T18:02:06.402+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000126_157: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.402+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 126.0 in stage 7.0 (TID 157). 7298 bytes result sent to driver
[2025-07-03T18:02:06.402+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 158) (39b5ac792cf9, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.403+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 127.0 in stage 7.0 (TID 158)
[2025-07-03T18:02:06.406+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 157) in 24 ms on 39b5ac792cf9 (executor driver) (127/200)
[2025-07-03T18:02:06.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (13.5 KiB) non-empty blocks including 7 (13.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.410+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.410+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.410+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.410+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.410+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.411+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.411+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.411+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.411+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.411+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.411+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.411+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.412+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.412+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.412+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.412+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.412+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.413+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.414+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.415+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.416+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.421+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000127_158' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000127
[2025-07-03T18:02:06.421+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000127_158: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.421+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 127.0 in stage 7.0 (TID 158). 7255 bytes result sent to driver
[2025-07-03T18:02:06.421+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 159) (39b5ac792cf9, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.425+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 128.0 in stage 7.0 (TID 159)
[2025-07-03T18:02:06.425+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 158) in 20 ms on 39b5ac792cf9 (executor driver) (128/200)
[2025-07-03T18:02:06.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.1 KiB) non-empty blocks including 7 (9.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.426+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.429+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.430+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.431+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.432+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.433+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.435+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000128_159' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000128
[2025-07-03T18:02:06.436+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000128_159: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.436+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 128.0 in stage 7.0 (TID 159). 7255 bytes result sent to driver
[2025-07-03T18:02:06.436+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 160) (39b5ac792cf9, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.437+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 129.0 in stage 7.0 (TID 160)
[2025-07-03T18:02:06.439+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 159) in 15 ms on 39b5ac792cf9 (executor driver) (129/200)
[2025-07-03T18:02:06.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.442+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.442+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.442+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.442+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.442+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.443+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.444+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.445+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.446+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000129_160' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000129
[2025-07-03T18:02:06.450+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000129_160: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.450+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 129.0 in stage 7.0 (TID 160). 7255 bytes result sent to driver
[2025-07-03T18:02:06.450+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 161) (39b5ac792cf9, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 130.0 in stage 7.0 (TID 161)
[2025-07-03T18:02:06.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 160) in 14 ms on 39b5ac792cf9 (executor driver) (130/200)
[2025-07-03T18:02:06.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.456+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.456+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.456+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.456+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.457+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.458+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.459+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.460+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.464+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000130_161' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000130
[2025-07-03T18:02:06.464+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000130_161: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.464+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 130.0 in stage 7.0 (TID 161). 7255 bytes result sent to driver
[2025-07-03T18:02:06.468+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 162) (39b5ac792cf9, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 131.0 in stage 7.0 (TID 162)
[2025-07-03T18:02:06.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 161) in 15 ms on 39b5ac792cf9 (executor driver) (131/200)
[2025-07-03T18:02:06.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (12.0 KiB) non-empty blocks including 7 (12.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.470+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.471+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.472+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.473+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.474+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.475+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.478+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000131_162' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000131
[2025-07-03T18:02:06.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000131_162: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 131.0 in stage 7.0 (TID 162). 7255 bytes result sent to driver
[2025-07-03T18:02:06.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 163) (39b5ac792cf9, executor driver, partition 132, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.482+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 132.0 in stage 7.0 (TID 163)
[2025-07-03T18:02:06.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 162) in 15 ms on 39b5ac792cf9 (executor driver) (132/200)
[2025-07-03T18:02:06.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.484+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.486+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.487+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.488+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.489+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.490+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000132_163' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000132
[2025-07-03T18:02:06.496+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000132_163: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.496+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 132.0 in stage 7.0 (TID 163). 7255 bytes result sent to driver
[2025-07-03T18:02:06.496+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 164) (39b5ac792cf9, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 133.0 in stage 7.0 (TID 164)
[2025-07-03T18:02:06.501+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 163) in 18 ms on 39b5ac792cf9 (executor driver) (133/200)
[2025-07-03T18:02:06.502+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.502+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.504+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.504+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.504+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.505+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.507+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.507+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.507+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.507+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.507+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.507+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.508+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.509+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.510+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.511+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.512+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.512+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.512+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.512+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.512+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.512+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.515+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000133_164' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000133
[2025-07-03T18:02:06.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000133_164: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 133.0 in stage 7.0 (TID 164). 7255 bytes result sent to driver
[2025-07-03T18:02:06.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 165) (39b5ac792cf9, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 134.0 in stage 7.0 (TID 165)
[2025-07-03T18:02:06.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 164) in 20 ms on 39b5ac792cf9 (executor driver) (134/200)
[2025-07-03T18:02:06.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.2 KiB) non-empty blocks including 7 (10.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.523+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.524+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.525+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.526+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.527+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.527+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.527+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.527+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.527+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.530+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000134_165' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000134
[2025-07-03T18:02:06.530+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000134_165: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.530+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 134.0 in stage 7.0 (TID 165). 7255 bytes result sent to driver
[2025-07-03T18:02:06.530+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 166) (39b5ac792cf9, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.534+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 135.0 in stage 7.0 (TID 166)
[2025-07-03T18:02:06.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 165) in 15 ms on 39b5ac792cf9 (executor driver) (135/200)
[2025-07-03T18:02:06.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.540+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.541+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.542+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.543+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.544+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.544+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.544+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.544+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.544+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.544+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.544+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000135_166' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000135
[2025-07-03T18:02:06.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000135_166: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 135.0 in stage 7.0 (TID 166). 7255 bytes result sent to driver
[2025-07-03T18:02:06.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 167) (39b5ac792cf9, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.551+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 136.0 in stage 7.0 (TID 167)
[2025-07-03T18:02:06.552+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 166) in 18 ms on 39b5ac792cf9 (executor driver) (136/200)
[2025-07-03T18:02:06.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.7 KiB) non-empty blocks including 7 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.556+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.556+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.557+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.558+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.559+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.560+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.561+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.561+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.561+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000136_167' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000136
[2025-07-03T18:02:06.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000136_167: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 136.0 in stage 7.0 (TID 167). 7255 bytes result sent to driver
[2025-07-03T18:02:06.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 168) (39b5ac792cf9, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.569+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 137.0 in stage 7.0 (TID 168)
[2025-07-03T18:02:06.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 167) in 17 ms on 39b5ac792cf9 (executor driver) (137/200)
[2025-07-03T18:02:06.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.4 KiB) non-empty blocks including 7 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.573+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.573+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.573+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.573+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.574+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.575+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.576+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.577+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000137_168' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000137
[2025-07-03T18:02:06.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000137_168: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 137.0 in stage 7.0 (TID 168). 7255 bytes result sent to driver
[2025-07-03T18:02:06.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 169) (39b5ac792cf9, executor driver, partition 138, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 168) in 17 ms on 39b5ac792cf9 (executor driver) (138/200)
[2025-07-03T18:02:06.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 138.0 in stage 7.0 (TID 169)
[2025-07-03T18:02:06.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.3 KiB) non-empty blocks including 7 (9.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.589+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.589+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.592+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.593+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.594+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.595+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.596+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.597+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.597+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.597+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.597+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000138_169' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000138
[2025-07-03T18:02:06.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000138_169: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 138.0 in stage 7.0 (TID 169). 7255 bytes result sent to driver
[2025-07-03T18:02:06.604+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 170) (39b5ac792cf9, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 139.0 in stage 7.0 (TID 170)
[2025-07-03T18:02:06.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 169) in 23 ms on 39b5ac792cf9 (executor driver) (139/200)
[2025-07-03T18:02:06.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.617+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.617+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.618+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.619+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.620+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.621+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.626+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000139_170' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000139
[2025-07-03T18:02:06.626+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000139_170: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.626+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 139.0 in stage 7.0 (TID 170). 7255 bytes result sent to driver
[2025-07-03T18:02:06.630+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 171) (39b5ac792cf9, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.630+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 140.0 in stage 7.0 (TID 171)
[2025-07-03T18:02:06.631+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 170) in 23 ms on 39b5ac792cf9 (executor driver) (140/200)
[2025-07-03T18:02:06.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.0 KiB) non-empty blocks including 7 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.634+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.635+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.636+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.637+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.638+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.639+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.642+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000140_171' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000140
[2025-07-03T18:02:06.642+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000140_171: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 140.0 in stage 7.0 (TID 171). 7255 bytes result sent to driver
[2025-07-03T18:02:06.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 172) (39b5ac792cf9, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 141.0 in stage 7.0 (TID 172)
[2025-07-03T18:02:06.647+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 171) in 17 ms on 39b5ac792cf9 (executor driver) (141/200)
[2025-07-03T18:02:06.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.8 KiB) non-empty blocks including 7 (11.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.651+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.652+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.653+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.654+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.655+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.655+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000141_172' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000141
[2025-07-03T18:02:06.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000141_172: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 141.0 in stage 7.0 (TID 172). 7255 bytes result sent to driver
[2025-07-03T18:02:06.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 173) (39b5ac792cf9, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 142.0 in stage 7.0 (TID 173)
[2025-07-03T18:02:06.665+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 172) in 18 ms on 39b5ac792cf9 (executor driver) (142/200)
[2025-07-03T18:02:06.671+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.6 KiB) non-empty blocks including 7 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.674+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.676+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.677+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.678+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.679+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.680+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000142_173' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000142
[2025-07-03T18:02:06.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000142_173: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 142.0 in stage 7.0 (TID 173). 7255 bytes result sent to driver
[2025-07-03T18:02:06.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 174) (39b5ac792cf9, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.687+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 173) in 24 ms on 39b5ac792cf9 (executor driver) (143/200)
[2025-07-03T18:02:06.688+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 143.0 in stage 7.0 (TID 174)
[2025-07-03T18:02:06.692+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (12.3 KiB) non-empty blocks including 7 (12.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.693+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.694+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.694+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.694+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.695+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.696+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.697+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.698+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.699+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.699+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.699+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.699+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.699+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000143_174' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000143
[2025-07-03T18:02:06.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000143_174: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 143.0 in stage 7.0 (TID 174). 7255 bytes result sent to driver
[2025-07-03T18:02:06.706+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 175) (39b5ac792cf9, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 144.0 in stage 7.0 (TID 175)
[2025-07-03T18:02:06.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 174) in 19 ms on 39b5ac792cf9 (executor driver) (144/200)
[2025-07-03T18:02:06.710+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.5 KiB) non-empty blocks including 7 (10.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.710+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.711+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.715+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.716+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.717+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.718+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.719+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.719+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.719+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.719+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.719+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.719+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.719+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.723+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000144_175' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000144
[2025-07-03T18:02:06.723+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000144_175: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.723+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 144.0 in stage 7.0 (TID 175). 7255 bytes result sent to driver
[2025-07-03T18:02:06.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 176) (39b5ac792cf9, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 145.0 in stage 7.0 (TID 176)
[2025-07-03T18:02:06.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 175) in 22 ms on 39b5ac792cf9 (executor driver) (145/200)
[2025-07-03T18:02:06.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.733+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.735+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.736+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.737+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.738+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.739+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000145_176' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000145
[2025-07-03T18:02:06.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000145_176: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 145.0 in stage 7.0 (TID 176). 7255 bytes result sent to driver
[2025-07-03T18:02:06.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 177) (39b5ac792cf9, executor driver, partition 146, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 146.0 in stage 7.0 (TID 177)
[2025-07-03T18:02:06.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 176) in 20 ms on 39b5ac792cf9 (executor driver) (146/200)
[2025-07-03T18:02:06.749+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.749+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.754+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.754+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.754+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.754+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.755+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.756+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.756+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.756+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.756+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.756+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.756+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.757+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.757+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.757+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.757+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.757+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.757+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.758+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.758+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.758+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.758+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.758+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.759+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.759+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.759+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.759+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.759+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.759+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.760+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.760+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.760+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.760+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.760+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.760+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.760+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.761+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.761+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.761+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.761+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.762+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.762+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.762+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.763+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000146_177' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000146
[2025-07-03T18:02:06.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000146_177: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.775+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 146.0 in stage 7.0 (TID 177). 7341 bytes result sent to driver
[2025-07-03T18:02:06.776+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 178) (39b5ac792cf9, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.776+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 147.0 in stage 7.0 (TID 178)
[2025-07-03T18:02:06.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 177) in 33 ms on 39b5ac792cf9 (executor driver) (147/200)
[2025-07-03T18:02:06.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.785+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.785+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.785+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.785+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.785+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.785+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.786+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.787+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.788+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.789+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.789+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.789+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.789+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.789+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.789+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.789+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.790+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.790+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.790+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.790+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000147_178' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000147
[2025-07-03T18:02:06.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000147_178: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 147.0 in stage 7.0 (TID 178). 7255 bytes result sent to driver
[2025-07-03T18:02:06.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 179) (39b5ac792cf9, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.797+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 148.0 in stage 7.0 (TID 179)
[2025-07-03T18:02:06.797+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 178) in 20 ms on 39b5ac792cf9 (executor driver) (148/200)
[2025-07-03T18:02:06.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.805+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.805+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.805+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.805+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.805+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.805+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.806+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.806+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.806+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.806+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.806+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.806+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.807+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.807+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.807+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.807+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.807+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.807+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.807+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.808+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.808+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.808+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.808+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.808+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.809+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.809+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.809+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.809+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.809+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.810+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.810+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.810+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.810+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.811+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.811+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.811+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.811+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.812+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.812+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.812+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.812+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.812+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.812+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.813+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.813+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.813+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.813+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.813+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.813+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.813+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.814+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.819+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000148_179' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000148
[2025-07-03T18:02:06.819+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000148_179: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 148.0 in stage 7.0 (TID 179). 7255 bytes result sent to driver
[2025-07-03T18:02:06.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 180) (39b5ac792cf9, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 149.0 in stage 7.0 (TID 180)
[2025-07-03T18:02:06.824+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 179) in 24 ms on 39b5ac792cf9 (executor driver) (149/200)
[2025-07-03T18:02:06.827+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (13.2 KiB) non-empty blocks including 7 (13.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.833+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.834+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.835+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.835+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.835+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.835+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.835+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.835+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.835+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.836+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.836+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.836+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.836+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.836+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.836+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.837+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.837+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.837+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.837+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.838+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.838+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.839+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.839+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.839+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.839+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.839+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.839+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.840+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.840+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.840+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.840+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.840+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.841+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.841+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.841+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000149_180' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000149
[2025-07-03T18:02:06.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000149_180: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 149.0 in stage 7.0 (TID 180). 7255 bytes result sent to driver
[2025-07-03T18:02:06.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 181) (39b5ac792cf9, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 150.0 in stage 7.0 (TID 181)
[2025-07-03T18:02:06.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 180) in 30 ms on 39b5ac792cf9 (executor driver) (150/200)
[2025-07-03T18:02:06.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.5 KiB) non-empty blocks including 7 (10.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.859+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.860+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.861+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.862+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.863+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000150_181' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000150
[2025-07-03T18:02:06.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000150_181: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 150.0 in stage 7.0 (TID 181). 7255 bytes result sent to driver
[2025-07-03T18:02:06.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 182) (39b5ac792cf9, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.867+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 151.0 in stage 7.0 (TID 182)
[2025-07-03T18:02:06.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 181) in 16 ms on 39b5ac792cf9 (executor driver) (151/200)
[2025-07-03T18:02:06.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (12.4 KiB) non-empty blocks including 7 (12.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.872+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.873+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.874+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.875+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.876+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.877+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.877+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.877+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.877+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000151_182' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000151
[2025-07-03T18:02:06.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000151_182: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 151.0 in stage 7.0 (TID 182). 7255 bytes result sent to driver
[2025-07-03T18:02:06.881+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 183) (39b5ac792cf9, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.884+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 182) in 15 ms on 39b5ac792cf9 (executor driver) (152/200)
[2025-07-03T18:02:06.884+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 152.0 in stage 7.0 (TID 183)
[2025-07-03T18:02:06.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (12.8 KiB) non-empty blocks including 7 (12.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.888+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.889+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.890+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.891+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.892+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000152_183' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000152
[2025-07-03T18:02:06.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000152_183: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 152.0 in stage 7.0 (TID 183). 7255 bytes result sent to driver
[2025-07-03T18:02:06.899+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 184) (39b5ac792cf9, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.899+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 153.0 in stage 7.0 (TID 184)
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 183) in 15 ms on 39b5ac792cf9 (executor driver) (153/200)
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.3 KiB) non-empty blocks including 7 (11.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.902+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.902+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.903+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.904+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.905+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.906+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.906+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.906+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000153_184' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000153
[2025-07-03T18:02:06.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000153_184: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 153.0 in stage 7.0 (TID 184). 7255 bytes result sent to driver
[2025-07-03T18:02:06.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 185) (39b5ac792cf9, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 184) in 16 ms on 39b5ac792cf9 (executor driver) (154/200)
[2025-07-03T18:02:06.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 154.0 in stage 7.0 (TID 185)
[2025-07-03T18:02:06.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (12.3 KiB) non-empty blocks including 7 (12.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.917+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.917+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.917+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.918+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.919+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.920+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.921+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.925+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000154_185' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000154
[2025-07-03T18:02:06.925+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000154_185: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 154.0 in stage 7.0 (TID 185). 7255 bytes result sent to driver
[2025-07-03T18:02:06.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 186) (39b5ac792cf9, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 155.0 in stage 7.0 (TID 186)
[2025-07-03T18:02:06.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 185) in 15 ms on 39b5ac792cf9 (executor driver) (155/200)
[2025-07-03T18:02:06.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (8.8 KiB) non-empty blocks including 7 (8.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.932+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.933+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.934+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.935+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000155_186' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000155
[2025-07-03T18:02:06.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000155_186: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 155.0 in stage 7.0 (TID 186). 7255 bytes result sent to driver
[2025-07-03T18:02:06.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 187) (39b5ac792cf9, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.940+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 156.0 in stage 7.0 (TID 187)
[2025-07-03T18:02:06.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 186) in 14 ms on 39b5ac792cf9 (executor driver) (156/200)
[2025-07-03T18:02:06.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.946+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.946+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.946+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.946+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.947+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.948+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.949+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.950+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.950+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.950+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.950+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.950+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000156_187' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000156
[2025-07-03T18:02:06.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000156_187: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 156.0 in stage 7.0 (TID 187). 7255 bytes result sent to driver
[2025-07-03T18:02:06.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 188) (39b5ac792cf9, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 157.0 in stage 7.0 (TID 188)
[2025-07-03T18:02:06.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 187) in 15 ms on 39b5ac792cf9 (executor driver) (157/200)
[2025-07-03T18:02:06.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (11.8 KiB) non-empty blocks including 7 (11.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.960+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.961+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.962+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.963+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.964+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000157_188' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000157
[2025-07-03T18:02:06.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000157_188: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 157.0 in stage 7.0 (TID 188). 7255 bytes result sent to driver
[2025-07-03T18:02:06.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 189) (39b5ac792cf9, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 158.0 in stage 7.0 (TID 189)
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 188) in 14 ms on 39b5ac792cf9 (executor driver) (158/200)
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (12.3 KiB) non-empty blocks including 7 (12.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.974+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.975+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.976+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.977+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000158_189' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000158
[2025-07-03T18:02:06.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000158_189: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 158.0 in stage 7.0 (TID 189). 7255 bytes result sent to driver
[2025-07-03T18:02:06.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 190) (39b5ac792cf9, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 159.0 in stage 7.0 (TID 190)
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 189) in 14 ms on 39b5ac792cf9 (executor driver) (159/200)
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:06.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:06.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:06.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:06.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:06.987+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.988+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:06.989+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:06.990+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:06.991+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:06.991+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:06.991+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:06.991+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:06.991+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.991+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:06.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000159_190' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000159
[2025-07-03T18:02:06.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000159_190: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:06.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Finished task 159.0 in stage 7.0 (TID 190). 7255 bytes result sent to driver
[2025-07-03T18:02:06.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 191) (39b5ac792cf9, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:06.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO Executor: Running task 160.0 in stage 7.0 (TID 191)
[2025-07-03T18:02:06.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 190) in 15 ms on 39b5ac792cf9 (executor driver) (160/200)
[2025-07-03T18:02:06.999+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Getting 7 (10.0 KiB) non-empty blocks including 7 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:06.999+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.005+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.005+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.005+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.005+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.005+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.005+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.005+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.006+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.006+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.006+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.006+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.006+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.006+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.006+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.007+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.008+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.009+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.010+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.011+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.011+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.011+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000160_191' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000160
[2025-07-03T18:02:07.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000160_191: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 160.0 in stage 7.0 (TID 191). 7255 bytes result sent to driver
[2025-07-03T18:02:07.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 192) (39b5ac792cf9, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 191) in 22 ms on 39b5ac792cf9 (executor driver) (161/200)
[2025-07-03T18:02:07.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 161.0 in stage 7.0 (TID 192)
[2025-07-03T18:02:07.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.024+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.025+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.026+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.027+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.028+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.028+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.028+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.032+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000161_192' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000161
[2025-07-03T18:02:07.032+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000161_192: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.032+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 161.0 in stage 7.0 (TID 192). 7255 bytes result sent to driver
[2025-07-03T18:02:07.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 193) (39b5ac792cf9, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.036+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 162.0 in stage 7.0 (TID 193)
[2025-07-03T18:02:07.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 192) in 16 ms on 39b5ac792cf9 (executor driver) (162/200)
[2025-07-03T18:02:07.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.039+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.040+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.041+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.042+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.043+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.043+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.046+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000162_193' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000162
[2025-07-03T18:02:07.046+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000162_193: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.046+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 162.0 in stage 7.0 (TID 193). 7255 bytes result sent to driver
[2025-07-03T18:02:07.046+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 194) (39b5ac792cf9, executor driver, partition 163, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.050+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 163.0 in stage 7.0 (TID 194)
[2025-07-03T18:02:07.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 193) in 15 ms on 39b5ac792cf9 (executor driver) (163/200)
[2025-07-03T18:02:07.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (9.1 KiB) non-empty blocks including 7 (9.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.053+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.054+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.055+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.056+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.056+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.056+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.056+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.056+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.056+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.056+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000163_194' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000163
[2025-07-03T18:02:07.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000163_194: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 163.0 in stage 7.0 (TID 194). 7255 bytes result sent to driver
[2025-07-03T18:02:07.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 195) (39b5ac792cf9, executor driver, partition 164, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 164.0 in stage 7.0 (TID 195)
[2025-07-03T18:02:07.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 194) in 14 ms on 39b5ac792cf9 (executor driver) (164/200)
[2025-07-03T18:02:07.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.067+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.068+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.069+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.070+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000164_195' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000164
[2025-07-03T18:02:07.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000164_195: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 164.0 in stage 7.0 (TID 195). 7255 bytes result sent to driver
[2025-07-03T18:02:07.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 196) (39b5ac792cf9, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 165.0 in stage 7.0 (TID 196)
[2025-07-03T18:02:07.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 195) in 14 ms on 39b5ac792cf9 (executor driver) (165/200)
[2025-07-03T18:02:07.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (12.5 KiB) non-empty blocks including 7 (12.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.080+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.081+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.082+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.083+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.084+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.084+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.088+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000165_196' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000165
[2025-07-03T18:02:07.088+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000165_196: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.088+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 165.0 in stage 7.0 (TID 196). 7255 bytes result sent to driver
[2025-07-03T18:02:07.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 197) (39b5ac792cf9, executor driver, partition 166, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.092+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 166.0 in stage 7.0 (TID 197)
[2025-07-03T18:02:07.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 196) in 16 ms on 39b5ac792cf9 (executor driver) (166/200)
[2025-07-03T18:02:07.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.094+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.094+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.095+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.095+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.096+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.097+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.098+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.099+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.099+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.099+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.099+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.099+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.100+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.101+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.102+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.102+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.102+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.102+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.102+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.102+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000166_197' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000166
[2025-07-03T18:02:07.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000166_197: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 166.0 in stage 7.0 (TID 197). 7255 bytes result sent to driver
[2025-07-03T18:02:07.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 198) (39b5ac792cf9, executor driver, partition 167, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 167.0 in stage 7.0 (TID 198)
[2025-07-03T18:02:07.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 197) in 21 ms on 39b5ac792cf9 (executor driver) (167/200)
[2025-07-03T18:02:07.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.116+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.117+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.118+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.119+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.120+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000167_198' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000167
[2025-07-03T18:02:07.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000167_198: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 167.0 in stage 7.0 (TID 198). 7298 bytes result sent to driver
[2025-07-03T18:02:07.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 199) (39b5ac792cf9, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 168.0 in stage 7.0 (TID 199)
[2025-07-03T18:02:07.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 198) in 21 ms on 39b5ac792cf9 (executor driver) (168/200)
[2025-07-03T18:02:07.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.134+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.134+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.134+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.134+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.136+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.137+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.138+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.139+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.140+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.140+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.140+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.143+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000168_199' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000168
[2025-07-03T18:02:07.143+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000168_199: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 168.0 in stage 7.0 (TID 199). 7255 bytes result sent to driver
[2025-07-03T18:02:07.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 200) (39b5ac792cf9, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 169.0 in stage 7.0 (TID 200)
[2025-07-03T18:02:07.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 199) in 15 ms on 39b5ac792cf9 (executor driver) (169/200)
[2025-07-03T18:02:07.149+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.8 KiB) non-empty blocks including 7 (8.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.151+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.152+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.153+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.154+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.155+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.156+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000169_200' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000169
[2025-07-03T18:02:07.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000169_200: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 169.0 in stage 7.0 (TID 200). 7255 bytes result sent to driver
[2025-07-03T18:02:07.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 201) (39b5ac792cf9, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 170.0 in stage 7.0 (TID 201)
[2025-07-03T18:02:07.164+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 200) in 16 ms on 39b5ac792cf9 (executor driver) (170/200)
[2025-07-03T18:02:07.164+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.164+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.164+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.167+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.168+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.169+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.170+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.171+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.171+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.174+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000170_201' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000170
[2025-07-03T18:02:07.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000170_201: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 170.0 in stage 7.0 (TID 201). 7255 bytes result sent to driver
[2025-07-03T18:02:07.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 202) (39b5ac792cf9, executor driver, partition 171, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 201) in 16 ms on 39b5ac792cf9 (executor driver) (171/200)
[2025-07-03T18:02:07.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 171.0 in stage 7.0 (TID 202)
[2025-07-03T18:02:07.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.4 KiB) non-empty blocks including 7 (10.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.182+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.183+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.184+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.185+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000171_202' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000171
[2025-07-03T18:02:07.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000171_202: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 171.0 in stage 7.0 (TID 202). 7255 bytes result sent to driver
[2025-07-03T18:02:07.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 203) (39b5ac792cf9, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 172.0 in stage 7.0 (TID 203)
[2025-07-03T18:02:07.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 202) in 16 ms on 39b5ac792cf9 (executor driver) (172/200)
[2025-07-03T18:02:07.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (13.6 KiB) non-empty blocks including 7 (13.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.198+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.199+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.200+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.201+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000172_203' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000172
[2025-07-03T18:02:07.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000172_203: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 172.0 in stage 7.0 (TID 203). 7255 bytes result sent to driver
[2025-07-03T18:02:07.209+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 204) (39b5ac792cf9, executor driver, partition 173, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.209+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 173.0 in stage 7.0 (TID 204)
[2025-07-03T18:02:07.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 203) in 16 ms on 39b5ac792cf9 (executor driver) (173/200)
[2025-07-03T18:02:07.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.215+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.216+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.217+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.218+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.219+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.219+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.219+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.219+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.219+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.220+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.220+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.220+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.220+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.220+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.220+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.221+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000173_204' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000173
[2025-07-03T18:02:07.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000173_204: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 173.0 in stage 7.0 (TID 204). 7255 bytes result sent to driver
[2025-07-03T18:02:07.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 205) (39b5ac792cf9, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 174.0 in stage 7.0 (TID 205)
[2025-07-03T18:02:07.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 204) in 22 ms on 39b5ac792cf9 (executor driver) (174/200)
[2025-07-03T18:02:07.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.235+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.236+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.236+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.237+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.237+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.239+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.240+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.241+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.241+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.242+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.242+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.242+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.243+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.243+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.244+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.245+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.246+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.247+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000174_205' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000174
[2025-07-03T18:02:07.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000174_205: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 174.0 in stage 7.0 (TID 205). 7255 bytes result sent to driver
[2025-07-03T18:02:07.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 206) (39b5ac792cf9, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 175.0 in stage 7.0 (TID 206)
[2025-07-03T18:02:07.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 205) in 24 ms on 39b5ac792cf9 (executor driver) (175/200)
[2025-07-03T18:02:07.256+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (11.4 KiB) non-empty blocks including 7 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.257+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.257+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.258+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.258+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.260+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.261+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.261+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.261+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.261+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.261+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.261+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.261+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.262+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.263+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.264+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000175_206' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000175
[2025-07-03T18:02:07.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000175_206: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 175.0 in stage 7.0 (TID 206). 7255 bytes result sent to driver
[2025-07-03T18:02:07.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 207) (39b5ac792cf9, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.272+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 176.0 in stage 7.0 (TID 207)
[2025-07-03T18:02:07.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 206) in 17 ms on 39b5ac792cf9 (executor driver) (176/200)
[2025-07-03T18:02:07.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.275+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.276+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.277+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.278+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.279+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.279+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.279+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.279+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.279+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.279+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.279+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000176_207' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000176
[2025-07-03T18:02:07.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000176_207: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 176.0 in stage 7.0 (TID 207). 7255 bytes result sent to driver
[2025-07-03T18:02:07.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 208) (39b5ac792cf9, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 177.0 in stage 7.0 (TID 208)
[2025-07-03T18:02:07.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 207) in 16 ms on 39b5ac792cf9 (executor driver) (177/200)
[2025-07-03T18:02:07.288+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.6 KiB) non-empty blocks including 7 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.288+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.289+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.289+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.291+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.292+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.293+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.294+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.295+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.295+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.295+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.295+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.295+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.295+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.295+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000177_208' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000177
[2025-07-03T18:02:07.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000177_208: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 177.0 in stage 7.0 (TID 208). 7255 bytes result sent to driver
[2025-07-03T18:02:07.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 209) (39b5ac792cf9, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.302+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 178.0 in stage 7.0 (TID 209)
[2025-07-03T18:02:07.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 208) in 15 ms on 39b5ac792cf9 (executor driver) (178/200)
[2025-07-03T18:02:07.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.305+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.305+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.306+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.307+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.308+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.309+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.310+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.310+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.310+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.310+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.313+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000178_209' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000178
[2025-07-03T18:02:07.314+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000178_209: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.314+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 178.0 in stage 7.0 (TID 209). 7255 bytes result sent to driver
[2025-07-03T18:02:07.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 210) (39b5ac792cf9, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 179.0 in stage 7.0 (TID 210)
[2025-07-03T18:02:07.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 209) in 15 ms on 39b5ac792cf9 (executor driver) (179/200)
[2025-07-03T18:02:07.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.321+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.322+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.323+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.327+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000179_210' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000179
[2025-07-03T18:02:07.327+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000179_210: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 179.0 in stage 7.0 (TID 210). 7255 bytes result sent to driver
[2025-07-03T18:02:07.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 211) (39b5ac792cf9, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 210) in 14 ms on 39b5ac792cf9 (executor driver) (180/200)
[2025-07-03T18:02:07.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 180.0 in stage 7.0 (TID 211)
[2025-07-03T18:02:07.331+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.334+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.335+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.336+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.337+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.340+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000180_211' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000180
[2025-07-03T18:02:07.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000180_211: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 180.0 in stage 7.0 (TID 211). 7255 bytes result sent to driver
[2025-07-03T18:02:07.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 212) (39b5ac792cf9, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 181.0 in stage 7.0 (TID 212)
[2025-07-03T18:02:07.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 211) in 14 ms on 39b5ac792cf9 (executor driver) (181/200)
[2025-07-03T18:02:07.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.348+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.349+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.350+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.351+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.352+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.352+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.352+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.352+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.352+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.352+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000181_212' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000181
[2025-07-03T18:02:07.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000181_212: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 181.0 in stage 7.0 (TID 212). 7255 bytes result sent to driver
[2025-07-03T18:02:07.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 213) (39b5ac792cf9, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 182.0 in stage 7.0 (TID 213)
[2025-07-03T18:02:07.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 212) in 14 ms on 39b5ac792cf9 (executor driver) (182/200)
[2025-07-03T18:02:07.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.1 KiB) non-empty blocks including 7 (10.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.361+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.362+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.363+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.364+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.365+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.365+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.367+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000182_213' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000182
[2025-07-03T18:02:07.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000182_213: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 182.0 in stage 7.0 (TID 213). 7255 bytes result sent to driver
[2025-07-03T18:02:07.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 214) (39b5ac792cf9, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 183.0 in stage 7.0 (TID 214)
[2025-07-03T18:02:07.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 213) in 14 ms on 39b5ac792cf9 (executor driver) (183/200)
[2025-07-03T18:02:07.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.374+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.375+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.376+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.377+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000183_214' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000183
[2025-07-03T18:02:07.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000183_214: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 183.0 in stage 7.0 (TID 214). 7255 bytes result sent to driver
[2025-07-03T18:02:07.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 215) (39b5ac792cf9, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 184.0 in stage 7.0 (TID 215)
[2025-07-03T18:02:07.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 214) in 13 ms on 39b5ac792cf9 (executor driver) (184/200)
[2025-07-03T18:02:07.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (11.1 KiB) non-empty blocks including 7 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.387+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.387+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.387+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.388+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.389+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.390+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.391+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.395+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000184_215' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000184
[2025-07-03T18:02:07.395+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000184_215: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.395+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 184.0 in stage 7.0 (TID 215). 7255 bytes result sent to driver
[2025-07-03T18:02:07.395+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 216) (39b5ac792cf9, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.398+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 185.0 in stage 7.0 (TID 216)
[2025-07-03T18:02:07.398+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 215) in 14 ms on 39b5ac792cf9 (executor driver) (185/200)
[2025-07-03T18:02:07.399+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (12.0 KiB) non-empty blocks including 7 (12.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.399+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.402+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.403+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.404+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.405+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000185_216' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000185
[2025-07-03T18:02:07.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000185_216: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 185.0 in stage 7.0 (TID 216). 7255 bytes result sent to driver
[2025-07-03T18:02:07.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 217) (39b5ac792cf9, executor driver, partition 186, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.412+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 186.0 in stage 7.0 (TID 217)
[2025-07-03T18:02:07.412+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 216) in 14 ms on 39b5ac792cf9 (executor driver) (186/200)
[2025-07-03T18:02:07.414+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.415+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.416+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.417+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.418+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.419+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.420+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.420+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.420+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.420+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.420+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000186_217' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000186
[2025-07-03T18:02:07.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000186_217: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.424+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 186.0 in stage 7.0 (TID 217). 7255 bytes result sent to driver
[2025-07-03T18:02:07.424+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 218) (39b5ac792cf9, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.424+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 187.0 in stage 7.0 (TID 218)
[2025-07-03T18:02:07.427+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 217) in 15 ms on 39b5ac792cf9 (executor driver) (187/200)
[2025-07-03T18:02:07.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.429+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.429+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.429+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.430+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.430+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.431+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.432+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.433+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.434+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.435+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.437+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000187_218' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000187
[2025-07-03T18:02:07.437+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000187_218: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.440+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 187.0 in stage 7.0 (TID 218). 7341 bytes result sent to driver
[2025-07-03T18:02:07.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 219) (39b5ac792cf9, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.444+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 218) in 17 ms on 39b5ac792cf9 (executor driver) (188/200)
[2025-07-03T18:02:07.444+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 188.0 in stage 7.0 (TID 219)
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (12.1 KiB) non-empty blocks including 7 (12.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.446+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.446+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.447+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.448+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.449+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.450+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.451+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.451+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000188_219' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000188
[2025-07-03T18:02:07.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000188_219: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.457+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 188.0 in stage 7.0 (TID 219). 7255 bytes result sent to driver
[2025-07-03T18:02:07.458+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 220) (39b5ac792cf9, executor driver, partition 189, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 189.0 in stage 7.0 (TID 220)
[2025-07-03T18:02:07.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 219) in 14 ms on 39b5ac792cf9 (executor driver) (189/200)
[2025-07-03T18:02:07.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.459+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.460+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.460+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.460+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.461+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.462+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.463+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.464+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.465+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.466+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.466+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.466+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.466+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.471+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000189_220' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000189
[2025-07-03T18:02:07.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000189_220: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 189.0 in stage 7.0 (TID 220). 7255 bytes result sent to driver
[2025-07-03T18:02:07.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 221) (39b5ac792cf9, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 220) in 18 ms on 39b5ac792cf9 (executor driver) (190/200)
[2025-07-03T18:02:07.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 190.0 in stage 7.0 (TID 221)
[2025-07-03T18:02:07.478+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.7 KiB) non-empty blocks including 7 (10.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.479+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.481+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.482+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.483+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.484+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.485+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.485+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.485+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.485+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.485+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.485+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.485+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.488+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000190_221' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000190
[2025-07-03T18:02:07.488+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000190_221: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 190.0 in stage 7.0 (TID 221). 7255 bytes result sent to driver
[2025-07-03T18:02:07.489+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 222) (39b5ac792cf9, executor driver, partition 191, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.492+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 191.0 in stage 7.0 (TID 222)
[2025-07-03T18:02:07.492+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 221) in 17 ms on 39b5ac792cf9 (executor driver) (191/200)
[2025-07-03T18:02:07.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.495+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.495+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.496+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.497+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.498+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.499+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.499+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.499+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.499+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.502+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000191_222' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000191
[2025-07-03T18:02:07.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000191_222: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 191.0 in stage 7.0 (TID 222). 7255 bytes result sent to driver
[2025-07-03T18:02:07.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 223) (39b5ac792cf9, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 192.0 in stage 7.0 (TID 223)
[2025-07-03T18:02:07.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 222) in 14 ms on 39b5ac792cf9 (executor driver) (192/200)
[2025-07-03T18:02:07.507+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.0 KiB) non-empty blocks including 7 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.507+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.508+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.509+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.509+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.509+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.509+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.509+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.510+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.511+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.512+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.513+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000192_223' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000192
[2025-07-03T18:02:07.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000192_223: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 192.0 in stage 7.0 (TID 223). 7255 bytes result sent to driver
[2025-07-03T18:02:07.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 224) (39b5ac792cf9, executor driver, partition 193, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 193.0 in stage 7.0 (TID 224)
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 223) in 13 ms on 39b5ac792cf9 (executor driver) (193/200)
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.523+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.523+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.523+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.523+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.524+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.525+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.526+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.527+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.527+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.527+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.527+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.527+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.527+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.530+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000193_224' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000193
[2025-07-03T18:02:07.531+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000193_224: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.531+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 193.0 in stage 7.0 (TID 224). 7255 bytes result sent to driver
[2025-07-03T18:02:07.531+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 225) (39b5ac792cf9, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.534+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 194.0 in stage 7.0 (TID 225)
[2025-07-03T18:02:07.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 224) in 15 ms on 39b5ac792cf9 (executor driver) (194/200)
[2025-07-03T18:02:07.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.0 KiB) non-empty blocks including 7 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.538+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.539+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.540+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.541+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000194_225' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000194
[2025-07-03T18:02:07.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000194_225: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 194.0 in stage 7.0 (TID 225). 7255 bytes result sent to driver
[2025-07-03T18:02:07.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 226) (39b5ac792cf9, executor driver, partition 195, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.547+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 195.0 in stage 7.0 (TID 226)
[2025-07-03T18:02:07.547+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 225) in 13 ms on 39b5ac792cf9 (executor driver) (195/200)
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.9 KiB) non-empty blocks including 7 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.549+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.550+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.550+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.550+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.551+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.552+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.553+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.554+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.554+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.554+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.554+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.554+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.554+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.554+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000195_226' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000195
[2025-07-03T18:02:07.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000195_226: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 195.0 in stage 7.0 (TID 226). 7255 bytes result sent to driver
[2025-07-03T18:02:07.561+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 227) (39b5ac792cf9, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 196.0 in stage 7.0 (TID 227)
[2025-07-03T18:02:07.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 226) in 14 ms on 39b5ac792cf9 (executor driver) (196/200)
[2025-07-03T18:02:07.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.1 KiB) non-empty blocks including 7 (10.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.566+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.567+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.568+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.569+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000196_227' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000196
[2025-07-03T18:02:07.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000196_227: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 196.0 in stage 7.0 (TID 227). 7255 bytes result sent to driver
[2025-07-03T18:02:07.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 228) (39b5ac792cf9, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.576+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 197.0 in stage 7.0 (TID 228)
[2025-07-03T18:02:07.576+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 227) in 16 ms on 39b5ac792cf9 (executor driver) (197/200)
[2025-07-03T18:02:07.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (9.4 KiB) non-empty blocks including 7 (9.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.579+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.581+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.582+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.583+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.584+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000197_228' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000197
[2025-07-03T18:02:07.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000197_228: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 197.0 in stage 7.0 (TID 228). 7255 bytes result sent to driver
[2025-07-03T18:02:07.588+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 229) (39b5ac792cf9, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 198.0 in stage 7.0 (TID 229)
[2025-07-03T18:02:07.592+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 228) in 16 ms on 39b5ac792cf9 (executor driver) (198/200)
[2025-07-03T18:02:07.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (11.5 KiB) non-empty blocks including 7 (11.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.595+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.595+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.595+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.595+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.596+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.597+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.598+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.599+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000198_229' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000198
[2025-07-03T18:02:07.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000198_229: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 198.0 in stage 7.0 (TID 229). 7255 bytes result sent to driver
[2025-07-03T18:02:07.604+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 230) (39b5ac792cf9, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:07.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 199.0 in stage 7.0 (TID 230)
[2025-07-03T18:02:07.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 229) in 16 ms on 39b5ac792cf9 (executor driver) (199/200)
[2025-07-03T18:02:07.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Getting 7 (10.0 KiB) non-empty blocks including 7 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:07.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:07.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-03T18:02:07.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-03T18:02:07.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-03T18:02:07.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodecConfig: Compression: SNAPPY
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - {
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - "type" : "struct",
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - "fields" : [ {
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - "name" : "sport",
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.612+0000] {spark_submit.py:579} INFO - "name" : "medal",
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "name" : "sex",
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "name" : "country_noc",
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "type" : "string",
[2025-07-03T18:02:07.613+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "name" : "avg_height",
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "name" : "avg_weight",
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "type" : "double",
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "nullable" : true,
[2025-07-03T18:02:07.614+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - }, {
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - "name" : "timestamp",
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - "type" : "timestamp",
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - "nullable" : false,
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - "metadata" : { }
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - } ]
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - and corresponding Parquet message type:
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - message spark_schema {
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - optional binary sport (STRING);
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - optional binary medal (STRING);
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - optional binary sex (STRING);
[2025-07-03T18:02:07.615+0000] {spark_submit.py:579} INFO - optional binary country_noc (STRING);
[2025-07-03T18:02:07.616+0000] {spark_submit.py:579} INFO - optional double avg_height;
[2025-07-03T18:02:07.616+0000] {spark_submit.py:579} INFO - optional double avg_weight;
[2025-07-03T18:02:07.616+0000] {spark_submit.py:579} INFO - required int96 timestamp;
[2025-07-03T18:02:07.616+0000] {spark_submit.py:579} INFO - }
[2025-07-03T18:02:07.616+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.616+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:07.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileOutputCommitter: Saved output of task 'attempt_202507031802004865019924538158051_0007_m_000199_230' to file:/opt/shared/gold/avg_stats/_temporary/0/task_202507031802004865019924538158051_0007_m_000199
[2025-07-03T18:02:07.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkHadoopMapRedUtil: attempt_202507031802004865019924538158051_0007_m_000199_230: Committed. Elapsed time: 0 ms.
[2025-07-03T18:02:07.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 199.0 in stage 7.0 (TID 230). 7255 bytes result sent to driver
[2025-07-03T18:02:07.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 230) in 16 ms on 39b5ac792cf9 (executor driver) (200/200)
[2025-07-03T18:02:07.619+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-03T18:02:07.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 3.706 s
[2025-07-03T18:02:07.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:02:07.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-03T18:02:07.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 7.287773 s
[2025-07-03T18:02:07.621+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileFormatWriter: Start to commit write Job 77dcf275-c68c-45a4-b7a5-b440bbd1b1ec.
[2025-07-03T18:02:07.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileFormatWriter: Write Job 77dcf275-c68c-45a4-b7a5-b440bbd1b1ec committed. Elapsed time: 206 ms.
[2025-07-03T18:02:07.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileFormatWriter: Finished processing stats for write job 77dcf275-c68c-45a4-b7a5-b440bbd1b1ec.
[2025-07-03T18:02:07.834+0000] {spark_submit.py:579} INFO - Table successfully aggregated and saved to /opt/shared/gold/avg_stats
[2025-07-03T18:02:07.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:02:07.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#0)
[2025-07-03T18:02:07.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:02:07.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#27)
[2025-07-03T18:02:07.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 201.5 KiB, free 386.1 MiB)
[2025-07-03T18:02:07.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 386.1 MiB)
[2025-07-03T18:02:07.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 39b5ac792cf9:37901 (size: 35.1 KiB, free: 426.9 MiB)
[2025-07-03T18:02:07.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:02:07.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodeGenerator: Code generated in 7.960709 ms
[2025-07-03T18:02:07.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:02:07.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:02:07.899+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 7 output partitions
[2025-07-03T18:02:07.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-03T18:02:07.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Parents of final stage: List()
[2025-07-03T18:02:07.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Missing parents: List()
[2025-07-03T18:02:07.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-03T18:02:07.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 15.6 KiB, free 386.0 MiB)
[2025-07-03T18:02:07.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 386.0 MiB)
[2025-07-03T18:02:07.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 39b5ac792cf9:37901 (size: 6.6 KiB, free: 426.9 MiB)
[2025-07-03T18:02:07.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:07.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:02:07.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSchedulerImpl: Adding task set 8.0 with 7 tasks resource profile 0
[2025-07-03T18:02:07.906+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 231) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:07.906+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 0.0 in stage 8.0 (TID 231)
[2025-07-03T18:02:07.906+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00130-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57587, partition values: [empty row]
[2025-07-03T18:02:07.908+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO CodeGenerator: Code generated in 15.611625 ms
[2025-07-03T18:02:07.909+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00029-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57404, partition values: [empty row]
[2025-07-03T18:02:07.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00025-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56716, partition values: [empty row]
[2025-07-03T18:02:07.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.925+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00094-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56382, partition values: [empty row]
[2025-07-03T18:02:07.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00051-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56298, partition values: [empty row]
[2025-07-03T18:02:07.934+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.937+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00076-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56236, partition values: [empty row]
[2025-07-03T18:02:07.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00193-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56152, partition values: [empty row]
[2025-07-03T18:02:07.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00159-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56131, partition values: [empty row]
[2025-07-03T18:02:07.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.949+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00040-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56041, partition values: [empty row]
[2025-07-03T18:02:07.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00172-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55935, partition values: [empty row]
[2025-07-03T18:02:07.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00101-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55751, partition values: [empty row]
[2025-07-03T18:02:07.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00103-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55611, partition values: [empty row]
[2025-07-03T18:02:07.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.962+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00189-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55606, partition values: [empty row]
[2025-07-03T18:02:07.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00127-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55599, partition values: [empty row]
[2025-07-03T18:02:07.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00063-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55563, partition values: [empty row]
[2025-07-03T18:02:07.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00095-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55516, partition values: [empty row]
[2025-07-03T18:02:07.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00173-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55432, partition values: [empty row]
[2025-07-03T18:02:07.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00188-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55276, partition values: [empty row]
[2025-07-03T18:02:07.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00125-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55207, partition values: [empty row]
[2025-07-03T18:02:07.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00154-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55088, partition values: [empty row]
[2025-07-03T18:02:07.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00010-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55072, partition values: [empty row]
[2025-07-03T18:02:07.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.977+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00005-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55055, partition values: [empty row]
[2025-07-03T18:02:07.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00000-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55054, partition values: [empty row]
[2025-07-03T18:02:07.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00098-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55020, partition values: [empty row]
[2025-07-03T18:02:07.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00168-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54965, partition values: [empty row]
[2025-07-03T18:02:07.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00074-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54962, partition values: [empty row]
[2025-07-03T18:02:07.984+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00108-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54960, partition values: [empty row]
[2025-07-03T18:02:07.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00004-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54956, partition values: [empty row]
[2025-07-03T18:02:07.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00139-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54954, partition values: [empty row]
[2025-07-03T18:02:07.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00182-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54952, partition values: [empty row]
[2025-07-03T18:02:07.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00122-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54947, partition values: [empty row]
[2025-07-03T18:02:07.992+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.992+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00018-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54918, partition values: [empty row]
[2025-07-03T18:02:07.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:07.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Finished task 0.0 in stage 8.0 (TID 231). 742770 bytes result sent to driver
[2025-07-03T18:02:07.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 232) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:07.998+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO Executor: Running task 1.0 in stage 8.0 (TID 232)
[2025-07-03T18:02:07.998+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 231) in 93 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:02:07.998+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00057-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54867, partition values: [empty row]
[2025-07-03T18:02:08.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:07 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00023-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54835, partition values: [empty row]
[2025-07-03T18:02:08.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00143-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54795, partition values: [empty row]
[2025-07-03T18:02:08.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00158-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54737, partition values: [empty row]
[2025-07-03T18:02:08.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00116-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54723, partition values: [empty row]
[2025-07-03T18:02:08.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00042-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54716, partition values: [empty row]
[2025-07-03T18:02:08.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00083-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:02:08.012+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.013+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00119-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:02:08.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00141-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54669, partition values: [empty row]
[2025-07-03T18:02:08.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00186-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54659, partition values: [empty row]
[2025-07-03T18:02:08.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00045-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54586, partition values: [empty row]
[2025-07-03T18:02:08.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00155-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54571, partition values: [empty row]
[2025-07-03T18:02:08.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00162-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54563, partition values: [empty row]
[2025-07-03T18:02:08.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00144-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54516, partition values: [empty row]
[2025-07-03T18:02:08.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00087-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54501, partition values: [empty row]
[2025-07-03T18:02:08.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00009-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54492, partition values: [empty row]
[2025-07-03T18:02:08.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00100-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54461, partition values: [empty row]
[2025-07-03T18:02:08.050+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00032-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54441, partition values: [empty row]
[2025-07-03T18:02:08.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00176-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54386, partition values: [empty row]
[2025-07-03T18:02:08.061+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.062+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00003-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54385, partition values: [empty row]
[2025-07-03T18:02:08.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00058-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54354, partition values: [empty row]
[2025-07-03T18:02:08.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00111-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54349, partition values: [empty row]
[2025-07-03T18:02:08.067+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.068+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00147-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54288, partition values: [empty row]
[2025-07-03T18:02:08.069+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.070+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00091-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54283, partition values: [empty row]
[2025-07-03T18:02:08.071+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.072+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00107-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54279, partition values: [empty row]
[2025-07-03T18:02:08.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.074+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00024-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54230, partition values: [empty row]
[2025-07-03T18:02:08.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.076+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00038-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54190, partition values: [empty row]
[2025-07-03T18:02:08.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00191-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54144, partition values: [empty row]
[2025-07-03T18:02:08.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.080+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00120-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54132, partition values: [empty row]
[2025-07-03T18:02:08.081+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.082+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00194-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54131, partition values: [empty row]
[2025-07-03T18:02:08.083+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.084+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00035-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54124, partition values: [empty row]
[2025-07-03T18:02:08.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.086+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00110-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54080, partition values: [empty row]
[2025-07-03T18:02:08.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 1.0 in stage 8.0 (TID 232). 722273 bytes result sent to driver
[2025-07-03T18:02:08.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 233) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:08.092+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 2.0 in stage 8.0 (TID 233)
[2025-07-03T18:02:08.092+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 232) in 94 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:02:08.092+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00021-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54070, partition values: [empty row]
[2025-07-03T18:02:08.093+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.099+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00114-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54048, partition values: [empty row]
[2025-07-03T18:02:08.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 39b5ac792cf9:37901 in memory (size: 96.8 KiB, free: 427.0 MiB)
[2025-07-03T18:02:08.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.102+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00150-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54032, partition values: [empty row]
[2025-07-03T18:02:08.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.104+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00169-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54022, partition values: [empty row]
[2025-07-03T18:02:08.105+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00082-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54019, partition values: [empty row]
[2025-07-03T18:02:08.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00043-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53970, partition values: [empty row]
[2025-07-03T18:02:08.108+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00015-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53950, partition values: [empty row]
[2025-07-03T18:02:08.110+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.110+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00164-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53947, partition values: [empty row]
[2025-07-03T18:02:08.111+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.112+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00152-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53936, partition values: [empty row]
[2025-07-03T18:02:08.113+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00197-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53935, partition values: [empty row]
[2025-07-03T18:02:08.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00160-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53924, partition values: [empty row]
[2025-07-03T18:02:08.116+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.117+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00002-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53904, partition values: [empty row]
[2025-07-03T18:02:08.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00165-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53870, partition values: [empty row]
[2025-07-03T18:02:08.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.120+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00078-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53867, partition values: [empty row]
[2025-07-03T18:02:08.121+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.121+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00145-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53865, partition values: [empty row]
[2025-07-03T18:02:08.122+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.123+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00153-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53863, partition values: [empty row]
[2025-07-03T18:02:08.124+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.124+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00047-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53839, partition values: [empty row]
[2025-07-03T18:02:08.125+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00077-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53831, partition values: [empty row]
[2025-07-03T18:02:08.127+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.127+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00131-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53770, partition values: [empty row]
[2025-07-03T18:02:08.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00028-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:02:08.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.130+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00022-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:02:08.131+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00126-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53726, partition values: [empty row]
[2025-07-03T18:02:08.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00148-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53681, partition values: [empty row]
[2025-07-03T18:02:08.134+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00179-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53662, partition values: [empty row]
[2025-07-03T18:02:08.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00034-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53650, partition values: [empty row]
[2025-07-03T18:02:08.137+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.137+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00171-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53632, partition values: [empty row]
[2025-07-03T18:02:08.138+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.139+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00137-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53624, partition values: [empty row]
[2025-07-03T18:02:08.140+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.141+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00086-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53620, partition values: [empty row]
[2025-07-03T18:02:08.141+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.142+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00014-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53616, partition values: [empty row]
[2025-07-03T18:02:08.143+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00073-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53614, partition values: [empty row]
[2025-07-03T18:02:08.144+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.145+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00105-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53604, partition values: [empty row]
[2025-07-03T18:02:08.146+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.147+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00199-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53602, partition values: [empty row]
[2025-07-03T18:02:08.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 2.0 in stage 8.0 (TID 233). 713849 bytes result sent to driver
[2025-07-03T18:02:08.157+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 234) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:08.158+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 3.0 in stage 8.0 (TID 234)
[2025-07-03T18:02:08.158+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 233) in 68 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:02:08.158+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00044-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53598, partition values: [empty row]
[2025-07-03T18:02:08.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.160+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00146-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53596, partition values: [empty row]
[2025-07-03T18:02:08.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.164+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00016-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53586, partition values: [empty row]
[2025-07-03T18:02:08.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00070-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53575, partition values: [empty row]
[2025-07-03T18:02:08.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.169+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00037-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53559, partition values: [empty row]
[2025-07-03T18:02:08.170+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00001-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53526, partition values: [empty row]
[2025-07-03T18:02:08.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.172+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00080-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53515, partition values: [empty row]
[2025-07-03T18:02:08.173+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.174+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00056-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53508, partition values: [empty row]
[2025-07-03T18:02:08.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00117-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53501, partition values: [empty row]
[2025-07-03T18:02:08.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00187-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53499, partition values: [empty row]
[2025-07-03T18:02:08.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00007-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53477, partition values: [empty row]
[2025-07-03T18:02:08.182+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.183+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00006-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53475, partition values: [empty row]
[2025-07-03T18:02:08.183+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00039-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53453, partition values: [empty row]
[2025-07-03T18:02:08.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00174-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53442, partition values: [empty row]
[2025-07-03T18:02:08.186+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.187+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00113-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53440, partition values: [empty row]
[2025-07-03T18:02:08.187+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.188+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00106-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53430, partition values: [empty row]
[2025-07-03T18:02:08.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00163-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53416, partition values: [empty row]
[2025-07-03T18:02:08.191+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.192+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00121-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53400, partition values: [empty row]
[2025-07-03T18:02:08.192+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00177-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53349, partition values: [empty row]
[2025-07-03T18:02:08.194+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00128-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53335, partition values: [empty row]
[2025-07-03T18:02:08.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00118-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53325, partition values: [empty row]
[2025-07-03T18:02:08.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00132-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53320, partition values: [empty row]
[2025-07-03T18:02:08.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00140-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53318, partition values: [empty row]
[2025-07-03T18:02:08.199+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.199+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00135-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53317, partition values: [empty row]
[2025-07-03T18:02:08.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.201+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00124-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53308, partition values: [empty row]
[2025-07-03T18:02:08.201+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00096-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53302, partition values: [empty row]
[2025-07-03T18:02:08.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00183-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53295, partition values: [empty row]
[2025-07-03T18:02:08.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00134-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53289, partition values: [empty row]
[2025-07-03T18:02:08.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00151-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53288, partition values: [empty row]
[2025-07-03T18:02:08.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.207+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00067-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53279, partition values: [empty row]
[2025-07-03T18:02:08.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00053-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53278, partition values: [empty row]
[2025-07-03T18:02:08.209+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.209+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00129-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:02:08.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 3.0 in stage 8.0 (TID 234). 709074 bytes result sent to driver
[2025-07-03T18:02:08.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 235) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:08.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 4.0 in stage 8.0 (TID 235)
[2025-07-03T18:02:08.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 234) in 57 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:02:08.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00019-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:02:08.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00198-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53274, partition values: [empty row]
[2025-07-03T18:02:08.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.228+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00046-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53272, partition values: [empty row]
[2025-07-03T18:02:08.231+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.263+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00065-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53261, partition values: [empty row]
[2025-07-03T18:02:08.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00052-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53240, partition values: [empty row]
[2025-07-03T18:02:08.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.276+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00190-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:02:08.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.278+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00196-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:02:08.278+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.279+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00157-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53211, partition values: [empty row]
[2025-07-03T18:02:08.280+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00048-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:02:08.282+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.282+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00185-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:02:08.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00020-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53155, partition values: [empty row]
[2025-07-03T18:02:08.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00180-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53145, partition values: [empty row]
[2025-07-03T18:02:08.286+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00178-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53134, partition values: [empty row]
[2025-07-03T18:02:08.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.288+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00104-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53119, partition values: [empty row]
[2025-07-03T18:02:08.289+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00138-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53103, partition values: [empty row]
[2025-07-03T18:02:08.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00085-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53097, partition values: [empty row]
[2025-07-03T18:02:08.292+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.292+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00112-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53073, partition values: [empty row]
[2025-07-03T18:02:08.293+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00181-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53071, partition values: [empty row]
[2025-07-03T18:02:08.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00075-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53065, partition values: [empty row]
[2025-07-03T18:02:08.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00149-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53062, partition values: [empty row]
[2025-07-03T18:02:08.297+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00012-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53049, partition values: [empty row]
[2025-07-03T18:02:08.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00090-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53047, partition values: [empty row]
[2025-07-03T18:02:08.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.300+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00068-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52969, partition values: [empty row]
[2025-07-03T18:02:08.301+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.301+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00054-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52925, partition values: [empty row]
[2025-07-03T18:02:08.302+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00195-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52882, partition values: [empty row]
[2025-07-03T18:02:08.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00049-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52845, partition values: [empty row]
[2025-07-03T18:02:08.305+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.305+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00092-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52842, partition values: [empty row]
[2025-07-03T18:02:08.306+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.306+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00102-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52835, partition values: [empty row]
[2025-07-03T18:02:08.307+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.308+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00081-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52833, partition values: [empty row]
[2025-07-03T18:02:08.309+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.309+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00072-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:02:08.310+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.311+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00142-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:02:08.311+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.312+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00036-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52790, partition values: [empty row]
[2025-07-03T18:02:08.312+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.322+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 4.0 in stage 8.0 (TID 235). 702824 bytes result sent to driver
[2025-07-03T18:02:08.323+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 236) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:08.323+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 5.0 in stage 8.0 (TID 236)
[2025-07-03T18:02:08.325+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 235) in 111 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:02:08.325+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00109-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52784, partition values: [empty row]
[2025-07-03T18:02:08.326+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.327+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00084-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52779, partition values: [empty row]
[2025-07-03T18:02:08.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00030-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52777, partition values: [empty row]
[2025-07-03T18:02:08.330+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.330+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00156-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52761, partition values: [empty row]
[2025-07-03T18:02:08.331+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00133-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52743, partition values: [empty row]
[2025-07-03T18:02:08.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00123-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52718, partition values: [empty row]
[2025-07-03T18:02:08.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.335+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00184-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52713, partition values: [empty row]
[2025-07-03T18:02:08.335+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00088-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52688, partition values: [empty row]
[2025-07-03T18:02:08.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00136-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52677, partition values: [empty row]
[2025-07-03T18:02:08.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00033-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52557, partition values: [empty row]
[2025-07-03T18:02:08.339+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.339+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00167-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52551, partition values: [empty row]
[2025-07-03T18:02:08.340+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.340+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00060-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52533, partition values: [empty row]
[2025-07-03T18:02:08.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00192-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52518, partition values: [empty row]
[2025-07-03T18:02:08.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.343+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00055-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52503, partition values: [empty row]
[2025-07-03T18:02:08.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00027-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52497, partition values: [empty row]
[2025-07-03T18:02:08.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00066-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52492, partition values: [empty row]
[2025-07-03T18:02:08.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00097-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52439, partition values: [empty row]
[2025-07-03T18:02:08.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00166-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52417, partition values: [empty row]
[2025-07-03T18:02:08.349+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.349+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00050-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52366, partition values: [empty row]
[2025-07-03T18:02:08.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00071-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52346, partition values: [empty row]
[2025-07-03T18:02:08.351+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00008-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52121, partition values: [empty row]
[2025-07-03T18:02:08.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00061-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52118, partition values: [empty row]
[2025-07-03T18:02:08.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00115-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52045, partition values: [empty row]
[2025-07-03T18:02:08.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.355+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00041-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51912, partition values: [empty row]
[2025-07-03T18:02:08.356+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.356+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00089-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51902, partition values: [empty row]
[2025-07-03T18:02:08.357+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00026-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51833, partition values: [empty row]
[2025-07-03T18:02:08.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00062-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51819, partition values: [empty row]
[2025-07-03T18:02:08.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00031-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51818, partition values: [empty row]
[2025-07-03T18:02:08.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00017-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51773, partition values: [empty row]
[2025-07-03T18:02:08.362+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.362+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00175-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51738, partition values: [empty row]
[2025-07-03T18:02:08.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00093-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51630, partition values: [empty row]
[2025-07-03T18:02:08.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00099-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51626, partition values: [empty row]
[2025-07-03T18:02:08.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.367+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 5.0 in stage 8.0 (TID 236). 693371 bytes result sent to driver
[2025-07-03T18:02:08.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 237) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 10881 bytes)
[2025-07-03T18:02:08.369+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 6.0 in stage 8.0 (TID 237)
[2025-07-03T18:02:08.369+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 236) in 46 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:02:08.369+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00011-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51506, partition values: [empty row]
[2025-07-03T18:02:08.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00170-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51479, partition values: [empty row]
[2025-07-03T18:02:08.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00013-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51405, partition values: [empty row]
[2025-07-03T18:02:08.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00059-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51381, partition values: [empty row]
[2025-07-03T18:02:08.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.375+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00064-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51360, partition values: [empty row]
[2025-07-03T18:02:08.375+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.376+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00161-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51349, partition values: [empty row]
[2025-07-03T18:02:08.377+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.377+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00069-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51017, partition values: [empty row]
[2025-07-03T18:02:08.378+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.378+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00079-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-50801, partition values: [empty row]
[2025-07-03T18:02:08.379+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 6.0 in stage 8.0 (TID 237). 171090 bytes result sent to driver
[2025-07-03T18:02:08.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 237) in 13 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:02:08.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-07-03T18:02:08.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.481 s
[2025-07-03T18:02:08.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:02:08.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-07-03T18:02:08.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.483922 s
[2025-07-03T18:02:08.406+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 39b5ac792cf9:37901 in memory (size: 6.6 KiB, free: 427.0 MiB)
[2025-07-03T18:02:08.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 40.0 MiB, free 346.4 MiB)
[2025-07-03T18:02:08.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 342.4 MiB)
[2025-07-03T18:02:08.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 39b5ac792cf9:37901 (size: 4.0 MiB, free: 423.0 MiB)
[2025-07-03T18:02:08.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO MemoryStore: Block broadcast_16_piece1 stored as bytes in memory (estimated size 3.3 MiB, free 339.1 MiB)
[2025-07-03T18:02:08.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO BlockManagerInfo: Added broadcast_16_piece1 in memory on 39b5ac792cf9:37901 (size: 3.3 MiB, free: 419.7 MiB)
[2025-07-03T18:02:08.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO SparkContext: Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:02:08.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO CodeGenerator: Code generated in 14.435583 ms
[2025-07-03T18:02:08.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 201.5 KiB, free 338.9 MiB)
[2025-07-03T18:02:08.518+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 338.9 MiB)
[2025-07-03T18:02:08.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 39b5ac792cf9:37901 (size: 35.0 KiB, free: 419.7 MiB)
[2025-07-03T18:02:08.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO SparkContext: Created broadcast 17 from count at NativeMethodAccessorImpl.java:0
[2025-07-03T18:02:08.520+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:02:08.531+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-07-03T18:02:08.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Registering RDD 33 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-07-03T18:02:08.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Registering RDD 36 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-07-03T18:02:08.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-03T18:02:08.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
[2025-07-03T18:02:08.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-07-03T18:02:08.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
[2025-07-03T18:02:08.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:02:08.534+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 49.6 KiB, free 338.8 MiB)
[2025-07-03T18:02:08.534+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 338.8 MiB)
[2025-07-03T18:02:08.534+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 39b5ac792cf9:37901 (size: 21.2 KiB, free: 419.7 MiB)
[2025-07-03T18:02:08.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:08.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:02:08.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSchedulerImpl: Adding task set 9.0 with 7 tasks resource profile 0
[2025-07-03T18:02:08.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 238) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:08.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 0.0 in stage 9.0 (TID 238)
[2025-07-03T18:02:08.547+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO CodeGenerator: Code generated in 9.064166 ms
[2025-07-03T18:02:08.552+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO CodeGenerator: Code generated in 1.52425 ms
[2025-07-03T18:02:08.552+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00068-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-168362, partition values: [empty row]
[2025-07-03T18:02:08.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00196-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-163710, partition values: [empty row]
[2025-07-03T18:02:08.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.560+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00029-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157967, partition values: [empty row]
[2025-07-03T18:02:08.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00198-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157920, partition values: [empty row]
[2025-07-03T18:02:08.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.566+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00128-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157850, partition values: [empty row]
[2025-07-03T18:02:08.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.568+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00120-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157700, partition values: [empty row]
[2025-07-03T18:02:08.569+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00102-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157204, partition values: [empty row]
[2025-07-03T18:02:08.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.573+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00053-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156699, partition values: [empty row]
[2025-07-03T18:02:08.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.576+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00147-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156146, partition values: [empty row]
[2025-07-03T18:02:08.577+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.579+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00087-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-155444, partition values: [empty row]
[2025-07-03T18:02:08.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00140-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-154024, partition values: [empty row]
[2025-07-03T18:02:08.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.591+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00095-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153497, partition values: [empty row]
[2025-07-03T18:02:08.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.596+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00079-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153486, partition values: [empty row]
[2025-07-03T18:02:08.597+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.599+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00130-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153363, partition values: [empty row]
[2025-07-03T18:02:08.600+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00172-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153223, partition values: [empty row]
[2025-07-03T18:02:08.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.605+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00049-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152868, partition values: [empty row]
[2025-07-03T18:02:08.606+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00031-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152746, partition values: [empty row]
[2025-07-03T18:02:08.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00133-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152572, partition values: [empty row]
[2025-07-03T18:02:08.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00038-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152480, partition values: [empty row]
[2025-07-03T18:02:08.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00097-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152347, partition values: [empty row]
[2025-07-03T18:02:08.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00178-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152161, partition values: [empty row]
[2025-07-03T18:02:08.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.625+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00027-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152149, partition values: [empty row]
[2025-07-03T18:02:08.626+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.629+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00045-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151971, partition values: [empty row]
[2025-07-03T18:02:08.629+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.631+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00135-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151699, partition values: [empty row]
[2025-07-03T18:02:08.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.634+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00187-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151670, partition values: [empty row]
[2025-07-03T18:02:08.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00083-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151205, partition values: [empty row]
[2025-07-03T18:02:08.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.638+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00034-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150976, partition values: [empty row]
[2025-07-03T18:02:08.639+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.641+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00111-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150838, partition values: [empty row]
[2025-07-03T18:02:08.642+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00142-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150787, partition values: [empty row]
[2025-07-03T18:02:08.644+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00011-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150662, partition values: [empty row]
[2025-07-03T18:02:08.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.647+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00030-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150182, partition values: [empty row]
[2025-07-03T18:02:08.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 0.0 in stage 9.0 (TID 238). 3883 bytes result sent to driver
[2025-07-03T18:02:08.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 239) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:08.670+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 1.0 in stage 9.0 (TID 239)
[2025-07-03T18:02:08.671+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 238) in 132 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:02:08.671+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00108-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150170, partition values: [empty row]
[2025-07-03T18:02:08.672+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.673+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00188-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150141, partition values: [empty row]
[2025-07-03T18:02:08.674+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.675+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00092-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150033, partition values: [empty row]
[2025-07-03T18:02:08.676+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.677+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00132-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149955, partition values: [empty row]
[2025-07-03T18:02:08.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.679+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00162-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149789, partition values: [empty row]
[2025-07-03T18:02:08.680+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.681+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00112-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149402, partition values: [empty row]
[2025-07-03T18:02:08.681+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.682+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00146-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149158, partition values: [empty row]
[2025-07-03T18:02:08.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00039-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149155, partition values: [empty row]
[2025-07-03T18:02:08.685+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.686+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00164-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149052, partition values: [empty row]
[2025-07-03T18:02:08.687+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.688+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00123-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148925, partition values: [empty row]
[2025-07-03T18:02:08.689+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.691+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00041-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148678, partition values: [empty row]
[2025-07-03T18:02:08.692+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.694+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00105-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148248, partition values: [empty row]
[2025-07-03T18:02:08.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.698+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00020-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147953, partition values: [empty row]
[2025-07-03T18:02:08.700+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00072-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147680, partition values: [empty row]
[2025-07-03T18:02:08.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.705+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00184-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147353, partition values: [empty row]
[2025-07-03T18:02:08.707+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.709+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00119-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147307, partition values: [empty row]
[2025-07-03T18:02:08.710+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.711+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00160-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147088, partition values: [empty row]
[2025-07-03T18:02:08.713+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00089-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146834, partition values: [empty row]
[2025-07-03T18:02:08.715+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00055-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146628, partition values: [empty row]
[2025-07-03T18:02:08.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00107-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146573, partition values: [empty row]
[2025-07-03T18:02:08.720+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00050-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146529, partition values: [empty row]
[2025-07-03T18:02:08.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.723+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00073-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146322, partition values: [empty row]
[2025-07-03T18:02:08.725+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00182-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146085, partition values: [empty row]
[2025-07-03T18:02:08.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.729+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00124-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145923, partition values: [empty row]
[2025-07-03T18:02:08.729+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.731+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00037-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145736, partition values: [empty row]
[2025-07-03T18:02:08.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.733+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00032-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145483, partition values: [empty row]
[2025-07-03T18:02:08.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00044-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145472, partition values: [empty row]
[2025-07-03T18:02:08.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.738+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00137-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145459, partition values: [empty row]
[2025-07-03T18:02:08.739+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.740+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00009-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145443, partition values: [empty row]
[2025-07-03T18:02:08.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00067-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145348, partition values: [empty row]
[2025-07-03T18:02:08.744+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.745+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00139-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145180, partition values: [empty row]
[2025-07-03T18:02:08.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 1.0 in stage 9.0 (TID 239). 3883 bytes result sent to driver
[2025-07-03T18:02:08.765+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 240) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:08.765+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 2.0 in stage 9.0 (TID 240)
[2025-07-03T18:02:08.765+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 239) in 98 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:02:08.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00114-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145175, partition values: [empty row]
[2025-07-03T18:02:08.775+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00154-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144764, partition values: [empty row]
[2025-07-03T18:02:08.778+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.780+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00115-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144653, partition values: [empty row]
[2025-07-03T18:02:08.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00062-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144636, partition values: [empty row]
[2025-07-03T18:02:08.786+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.788+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00177-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144534, partition values: [empty row]
[2025-07-03T18:02:08.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.792+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00131-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144411, partition values: [empty row]
[2025-07-03T18:02:08.794+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00003-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144247, partition values: [empty row]
[2025-07-03T18:02:08.798+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00159-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144214, partition values: [empty row]
[2025-07-03T18:02:08.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00081-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144124, partition values: [empty row]
[2025-07-03T18:02:08.808+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.809+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00173-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143839, partition values: [empty row]
[2025-07-03T18:02:08.810+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00145-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143692, partition values: [empty row]
[2025-07-03T18:02:08.812+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.814+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00100-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143512, partition values: [empty row]
[2025-07-03T18:02:08.815+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00110-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143491, partition values: [empty row]
[2025-07-03T18:02:08.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.826+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00167-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143463, partition values: [empty row]
[2025-07-03T18:02:08.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00082-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143421, partition values: [empty row]
[2025-07-03T18:02:08.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.842+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00103-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143305, partition values: [empty row]
[2025-07-03T18:02:08.844+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.848+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00094-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143260, partition values: [empty row]
[2025-07-03T18:02:08.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00192-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143248, partition values: [empty row]
[2025-07-03T18:02:08.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00153-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142738, partition values: [empty row]
[2025-07-03T18:02:08.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00028-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142579, partition values: [empty row]
[2025-07-03T18:02:08.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00109-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142500, partition values: [empty row]
[2025-07-03T18:02:08.863+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.864+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00007-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142453, partition values: [empty row]
[2025-07-03T18:02:08.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00197-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142400, partition values: [empty row]
[2025-07-03T18:02:08.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00048-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142344, partition values: [empty row]
[2025-07-03T18:02:08.875+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00024-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142324, partition values: [empty row]
[2025-07-03T18:02:08.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00113-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142107, partition values: [empty row]
[2025-07-03T18:02:08.892+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00179-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141811, partition values: [empty row]
[2025-07-03T18:02:08.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00194-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141737, partition values: [empty row]
[2025-07-03T18:02:08.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00022-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141733, partition values: [empty row]
[2025-07-03T18:02:08.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00006-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141716, partition values: [empty row]
[2025-07-03T18:02:08.908+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00057-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141276, partition values: [empty row]
[2025-07-03T18:02:08.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Finished task 2.0 in stage 9.0 (TID 240). 3926 bytes result sent to driver
[2025-07-03T18:02:08.939+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 241) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:08.940+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO Executor: Running task 3.0 in stage 9.0 (TID 241)
[2025-07-03T18:02:08.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 240) in 175 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:02:08.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00180-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141220, partition values: [empty row]
[2025-07-03T18:02:08.944+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00181-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141147, partition values: [empty row]
[2025-07-03T18:02:08.948+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00134-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141133, partition values: [empty row]
[2025-07-03T18:02:08.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00174-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141104, partition values: [empty row]
[2025-07-03T18:02:08.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00054-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141050, partition values: [empty row]
[2025-07-03T18:02:08.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00085-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140960, partition values: [empty row]
[2025-07-03T18:02:08.961+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00122-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140951, partition values: [empty row]
[2025-07-03T18:02:08.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00064-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140895, partition values: [empty row]
[2025-07-03T18:02:08.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00080-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140405, partition values: [empty row]
[2025-07-03T18:02:08.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00071-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140133, partition values: [empty row]
[2025-07-03T18:02:08.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.977+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00118-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140113, partition values: [empty row]
[2025-07-03T18:02:08.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00136-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140097, partition values: [empty row]
[2025-07-03T18:02:08.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00056-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140011, partition values: [empty row]
[2025-07-03T18:02:08.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.987+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00016-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139898, partition values: [empty row]
[2025-07-03T18:02:08.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00121-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139858, partition values: [empty row]
[2025-07-03T18:02:08.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.992+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00018-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139827, partition values: [empty row]
[2025-07-03T18:02:08.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00002-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139804, partition values: [empty row]
[2025-07-03T18:02:08.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:08.997+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00052-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139763, partition values: [empty row]
[2025-07-03T18:02:08.999+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:08 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00152-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139683, partition values: [empty row]
[2025-07-03T18:02:09.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00170-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139630, partition values: [empty row]
[2025-07-03T18:02:09.009+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.010+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00183-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139299, partition values: [empty row]
[2025-07-03T18:02:09.012+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.013+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00025-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139114, partition values: [empty row]
[2025-07-03T18:02:09.014+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00026-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138875, partition values: [empty row]
[2025-07-03T18:02:09.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00070-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138619, partition values: [empty row]
[2025-07-03T18:02:09.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00117-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138472, partition values: [empty row]
[2025-07-03T18:02:09.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00148-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138343, partition values: [empty row]
[2025-07-03T18:02:09.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00151-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138303, partition values: [empty row]
[2025-07-03T18:02:09.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00190-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137980, partition values: [empty row]
[2025-07-03T18:02:09.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.029+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00116-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137825, partition values: [empty row]
[2025-07-03T18:02:09.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00046-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137502, partition values: [empty row]
[2025-07-03T18:02:09.032+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00063-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137399, partition values: [empty row]
[2025-07-03T18:02:09.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.048+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 3.0 in stage 9.0 (TID 241). 3883 bytes result sent to driver
[2025-07-03T18:02:09.048+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 242) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:09.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 4.0 in stage 9.0 (TID 242)
[2025-07-03T18:02:09.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 241) in 109 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:02:09.052+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00143-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137169, partition values: [empty row]
[2025-07-03T18:02:09.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.054+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00047-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137073, partition values: [empty row]
[2025-07-03T18:02:09.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.057+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00084-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136997, partition values: [empty row]
[2025-07-03T18:02:09.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00156-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136937, partition values: [empty row]
[2025-07-03T18:02:09.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.061+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00193-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136790, partition values: [empty row]
[2025-07-03T18:02:09.062+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00042-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136602, partition values: [empty row]
[2025-07-03T18:02:09.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00088-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136524, partition values: [empty row]
[2025-07-03T18:02:09.067+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.070+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00191-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136091, partition values: [empty row]
[2025-07-03T18:02:09.071+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.072+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00019-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136064, partition values: [empty row]
[2025-07-03T18:02:09.073+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00127-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135998, partition values: [empty row]
[2025-07-03T18:02:09.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00199-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135968, partition values: [empty row]
[2025-07-03T18:02:09.077+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.078+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00013-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135936, partition values: [empty row]
[2025-07-03T18:02:09.079+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.081+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00144-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135783, partition values: [empty row]
[2025-07-03T18:02:09.081+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.082+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00101-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135779, partition values: [empty row]
[2025-07-03T18:02:09.083+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00171-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135629, partition values: [empty row]
[2025-07-03T18:02:09.086+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.087+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00166-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135568, partition values: [empty row]
[2025-07-03T18:02:09.088+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.089+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00165-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135539, partition values: [empty row]
[2025-07-03T18:02:09.090+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.091+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00060-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135477, partition values: [empty row]
[2025-07-03T18:02:09.091+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.094+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00004-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135462, partition values: [empty row]
[2025-07-03T18:02:09.095+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.097+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00010-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135408, partition values: [empty row]
[2025-07-03T18:02:09.098+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.100+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00040-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135398, partition values: [empty row]
[2025-07-03T18:02:09.101+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00033-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135395, partition values: [empty row]
[2025-07-03T18:02:09.103+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.106+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00021-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135250, partition values: [empty row]
[2025-07-03T18:02:09.107+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.109+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00023-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135210, partition values: [empty row]
[2025-07-03T18:02:09.110+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.114+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00185-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135190, partition values: [empty row]
[2025-07-03T18:02:09.115+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.118+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00061-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134981, partition values: [empty row]
[2025-07-03T18:02:09.119+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.122+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00001-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134944, partition values: [empty row]
[2025-07-03T18:02:09.123+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.126+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00189-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134929, partition values: [empty row]
[2025-07-03T18:02:09.127+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.128+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00091-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134926, partition values: [empty row]
[2025-07-03T18:02:09.129+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00161-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134806, partition values: [empty row]
[2025-07-03T18:02:09.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.135+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00012-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134703, partition values: [empty row]
[2025-07-03T18:02:09.136+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 4.0 in stage 9.0 (TID 242). 3883 bytes result sent to driver
[2025-07-03T18:02:09.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 243) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:09.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 242) in 130 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:02:09.182+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 5.0 in stage 9.0 (TID 243)
[2025-07-03T18:02:09.182+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00014-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134651, partition values: [empty row]
[2025-07-03T18:02:09.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.188+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00075-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134649, partition values: [empty row]
[2025-07-03T18:02:09.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.194+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00168-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134557, partition values: [empty row]
[2025-07-03T18:02:09.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00176-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134495, partition values: [empty row]
[2025-07-03T18:02:09.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00157-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134432, partition values: [empty row]
[2025-07-03T18:02:09.199+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00069-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134344, partition values: [empty row]
[2025-07-03T18:02:09.201+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00051-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134093, partition values: [empty row]
[2025-07-03T18:02:09.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.207+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00035-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133957, partition values: [empty row]
[2025-07-03T18:02:09.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00175-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133736, partition values: [empty row]
[2025-07-03T18:02:09.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00058-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133517, partition values: [empty row]
[2025-07-03T18:02:09.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.219+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00008-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133312, partition values: [empty row]
[2025-07-03T18:02:09.222+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00036-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133250, partition values: [empty row]
[2025-07-03T18:02:09.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00017-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133244, partition values: [empty row]
[2025-07-03T18:02:09.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.237+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00195-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133115, partition values: [empty row]
[2025-07-03T18:02:09.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00086-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132787, partition values: [empty row]
[2025-07-03T18:02:09.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00106-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132496, partition values: [empty row]
[2025-07-03T18:02:09.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00149-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132477, partition values: [empty row]
[2025-07-03T18:02:09.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00126-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132427, partition values: [empty row]
[2025-07-03T18:02:09.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00099-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132405, partition values: [empty row]
[2025-07-03T18:02:09.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.254+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00186-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132164, partition values: [empty row]
[2025-07-03T18:02:09.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.256+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00093-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131331, partition values: [empty row]
[2025-07-03T18:02:09.257+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00074-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131260, partition values: [empty row]
[2025-07-03T18:02:09.260+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.263+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00078-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130578, partition values: [empty row]
[2025-07-03T18:02:09.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00141-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130266, partition values: [empty row]
[2025-07-03T18:02:09.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00005-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130222, partition values: [empty row]
[2025-07-03T18:02:09.270+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.272+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00065-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130083, partition values: [empty row]
[2025-07-03T18:02:09.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00125-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130011, partition values: [empty row]
[2025-07-03T18:02:09.276+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00077-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129832, partition values: [empty row]
[2025-07-03T18:02:09.278+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00169-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129566, partition values: [empty row]
[2025-07-03T18:02:09.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00150-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129448, partition values: [empty row]
[2025-07-03T18:02:09.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00163-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129300, partition values: [empty row]
[2025-07-03T18:02:09.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 5.0 in stage 9.0 (TID 243). 3926 bytes result sent to driver
[2025-07-03T18:02:09.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 244) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 11762 bytes)
[2025-07-03T18:02:09.323+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 243) in 142 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:02:09.324+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 6.0 in stage 9.0 (TID 244)
[2025-07-03T18:02:09.325+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00129-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129243, partition values: [empty row]
[2025-07-03T18:02:09.327+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00155-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128963, partition values: [empty row]
[2025-07-03T18:02:09.330+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00076-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128747, partition values: [empty row]
[2025-07-03T18:02:09.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00098-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128595, partition values: [empty row]
[2025-07-03T18:02:09.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00066-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128097, partition values: [empty row]
[2025-07-03T18:02:09.339+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00090-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-127202, partition values: [empty row]
[2025-07-03T18:02:09.343+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00138-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-126507, partition values: [empty row]
[2025-07-03T18:02:09.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00043-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125123, partition values: [empty row]
[2025-07-03T18:02:09.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00158-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125003, partition values: [empty row]
[2025-07-03T18:02:09.349+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00059-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123983, partition values: [empty row]
[2025-07-03T18:02:09.351+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00104-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123468, partition values: [empty row]
[2025-07-03T18:02:09.355+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.356+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00000-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123063, partition values: [empty row]
[2025-07-03T18:02:09.356+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00015-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-122798, partition values: [empty row]
[2025-07-03T18:02:09.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00096-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-118888, partition values: [empty row]
[2025-07-03T18:02:09.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:09.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 6.0 in stage 9.0 (TID 244). 3883 bytes result sent to driver
[2025-07-03T18:02:09.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 244) in 53 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:02:09.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-03T18:02:09.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.840 s
[2025-07-03T18:02:09.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO DAGScheduler: looking for newly runnable stages
[2025-07-03T18:02:09.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO DAGScheduler: running: Set()
[2025-07-03T18:02:09.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 10, ResultStage 11)
[2025-07-03T18:02:09.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO DAGScheduler: failed: Set()
[2025-07-03T18:02:09.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:02:09.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 55.8 KiB, free 338.8 MiB)
[2025-07-03T18:02:09.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 338.7 MiB)
[2025-07-03T18:02:09.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 39b5ac792cf9:37901 (size: 25.0 KiB, free: 419.6 MiB)
[2025-07-03T18:02:09.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:09.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO DAGScheduler: Submitting 200 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-03T18:02:09.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSchedulerImpl: Adding task set 10.0 with 200 tasks resource profile 0
[2025-07-03T18:02:09.384+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 245) (39b5ac792cf9, executor driver, partition 0, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 0.0 in stage 10.0 (TID 245)
[2025-07-03T18:02:09.402+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.403+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.420+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO CodeGenerator: Code generated in 17.629708 ms
[2025-07-03T18:02:09.427+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 0.0 in stage 10.0 (TID 245). 6756 bytes result sent to driver
[2025-07-03T18:02:09.428+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 246) (39b5ac792cf9, executor driver, partition 1, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.430+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 1.0 in stage 10.0 (TID 246)
[2025-07-03T18:02:09.430+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 245) in 45 ms on 39b5ac792cf9 (executor driver) (1/200)
[2025-07-03T18:02:09.433+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.2 KiB) non-empty blocks including 7 (8.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.433+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 1.0 in stage 10.0 (TID 246). 6799 bytes result sent to driver
[2025-07-03T18:02:09.441+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 247) (39b5ac792cf9, executor driver, partition 2, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.442+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 246) in 14 ms on 39b5ac792cf9 (executor driver) (2/200)
[2025-07-03T18:02:09.443+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 2.0 in stage 10.0 (TID 247)
[2025-07-03T18:02:09.444+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.5 KiB) non-empty blocks including 7 (8.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.445+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 2.0 in stage 10.0 (TID 247). 6756 bytes result sent to driver
[2025-07-03T18:02:09.448+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 248) (39b5ac792cf9, executor driver, partition 3, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.449+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 247) in 8 ms on 39b5ac792cf9 (executor driver) (3/200)
[2025-07-03T18:02:09.450+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 3.0 in stage 10.0 (TID 248)
[2025-07-03T18:02:09.451+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.6 KiB) non-empty blocks including 7 (6.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.451+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.453+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 3.0 in stage 10.0 (TID 248). 6756 bytes result sent to driver
[2025-07-03T18:02:09.454+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 249) (39b5ac792cf9, executor driver, partition 4, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 4.0 in stage 10.0 (TID 249)
[2025-07-03T18:02:09.455+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 248) in 6 ms on 39b5ac792cf9 (executor driver) (4/200)
[2025-07-03T18:02:09.456+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.457+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.462+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 4.0 in stage 10.0 (TID 249). 6799 bytes result sent to driver
[2025-07-03T18:02:09.463+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 250) (39b5ac792cf9, executor driver, partition 5, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.464+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 39b5ac792cf9:37901 in memory (size: 21.2 KiB, free: 419.6 MiB)
[2025-07-03T18:02:09.464+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 249) in 9 ms on 39b5ac792cf9 (executor driver) (5/200)
[2025-07-03T18:02:09.465+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 5.0 in stage 10.0 (TID 250)
[2025-07-03T18:02:09.468+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.469+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.472+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 5.0 in stage 10.0 (TID 250). 6756 bytes result sent to driver
[2025-07-03T18:02:09.473+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 251) (39b5ac792cf9, executor driver, partition 6, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.473+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 6.0 in stage 10.0 (TID 251)
[2025-07-03T18:02:09.475+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 250) in 10 ms on 39b5ac792cf9 (executor driver) (6/200)
[2025-07-03T18:02:09.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.4 KiB) non-empty blocks including 7 (7.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.476+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.477+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 6.0 in stage 10.0 (TID 251). 6756 bytes result sent to driver
[2025-07-03T18:02:09.477+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 252) (39b5ac792cf9, executor driver, partition 7, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.478+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 7.0 in stage 10.0 (TID 252)
[2025-07-03T18:02:09.478+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 251) in 6 ms on 39b5ac792cf9 (executor driver) (7/200)
[2025-07-03T18:02:09.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.8 KiB) non-empty blocks including 7 (6.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.480+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.482+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 7.0 in stage 10.0 (TID 252). 6756 bytes result sent to driver
[2025-07-03T18:02:09.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 253) (39b5ac792cf9, executor driver, partition 8, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.483+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 8.0 in stage 10.0 (TID 253)
[2025-07-03T18:02:09.485+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 252) in 6 ms on 39b5ac792cf9 (executor driver) (8/200)
[2025-07-03T18:02:09.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.486+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 8.0 in stage 10.0 (TID 253). 6756 bytes result sent to driver
[2025-07-03T18:02:09.487+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 254) (39b5ac792cf9, executor driver, partition 9, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.488+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 253) in 5 ms on 39b5ac792cf9 (executor driver) (9/200)
[2025-07-03T18:02:09.490+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 9.0 in stage 10.0 (TID 254)
[2025-07-03T18:02:09.490+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 9.0 in stage 10.0 (TID 254). 6756 bytes result sent to driver
[2025-07-03T18:02:09.494+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 255) (39b5ac792cf9, executor driver, partition 10, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.495+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 10.0 in stage 10.0 (TID 255)
[2025-07-03T18:02:09.496+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 254) in 4 ms on 39b5ac792cf9 (executor driver) (10/200)
[2025-07-03T18:02:09.496+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.9 KiB) non-empty blocks including 7 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.496+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 10.0 in stage 10.0 (TID 255). 6756 bytes result sent to driver
[2025-07-03T18:02:09.497+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 11.0 in stage 10.0 (TID 256) (39b5ac792cf9, executor driver, partition 11, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 255) in 4 ms on 39b5ac792cf9 (executor driver) (11/200)
[2025-07-03T18:02:09.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 11.0 in stage 10.0 (TID 256)
[2025-07-03T18:02:09.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.9 KiB) non-empty blocks including 7 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 11.0 in stage 10.0 (TID 256). 6799 bytes result sent to driver
[2025-07-03T18:02:09.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 12.0 in stage 10.0 (TID 257) (39b5ac792cf9, executor driver, partition 12, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 12.0 in stage 10.0 (TID 257)
[2025-07-03T18:02:09.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 11.0 in stage 10.0 (TID 256) in 6 ms on 39b5ac792cf9 (executor driver) (12/200)
[2025-07-03T18:02:09.505+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.5 KiB) non-empty blocks including 7 (6.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 12.0 in stage 10.0 (TID 257). 6756 bytes result sent to driver
[2025-07-03T18:02:09.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 13.0 in stage 10.0 (TID 258) (39b5ac792cf9, executor driver, partition 13, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 12.0 in stage 10.0 (TID 257) in 3 ms on 39b5ac792cf9 (executor driver) (13/200)
[2025-07-03T18:02:09.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 13.0 in stage 10.0 (TID 258)
[2025-07-03T18:02:09.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.507+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 13.0 in stage 10.0 (TID 258). 6756 bytes result sent to driver
[2025-07-03T18:02:09.507+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 14.0 in stage 10.0 (TID 259) (39b5ac792cf9, executor driver, partition 14, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.509+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 14.0 in stage 10.0 (TID 259)
[2025-07-03T18:02:09.510+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 13.0 in stage 10.0 (TID 258) in 4 ms on 39b5ac792cf9 (executor driver) (14/200)
[2025-07-03T18:02:09.510+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (5.5 KiB) non-empty blocks including 7 (5.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.513+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 14.0 in stage 10.0 (TID 259). 6713 bytes result sent to driver
[2025-07-03T18:02:09.515+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 15.0 in stage 10.0 (TID 260) (39b5ac792cf9, executor driver, partition 15, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 15.0 in stage 10.0 (TID 260)
[2025-07-03T18:02:09.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 14.0 in stage 10.0 (TID 259) in 3 ms on 39b5ac792cf9 (executor driver) (15/200)
[2025-07-03T18:02:09.516+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 15.0 in stage 10.0 (TID 260). 6756 bytes result sent to driver
[2025-07-03T18:02:09.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 16.0 in stage 10.0 (TID 261) (39b5ac792cf9, executor driver, partition 16, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.519+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 15.0 in stage 10.0 (TID 260) in 3 ms on 39b5ac792cf9 (executor driver) (16/200)
[2025-07-03T18:02:09.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 16.0 in stage 10.0 (TID 261)
[2025-07-03T18:02:09.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.521+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 16.0 in stage 10.0 (TID 261). 6756 bytes result sent to driver
[2025-07-03T18:02:09.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 17.0 in stage 10.0 (TID 262) (39b5ac792cf9, executor driver, partition 17, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 16.0 in stage 10.0 (TID 261) in 3 ms on 39b5ac792cf9 (executor driver) (17/200)
[2025-07-03T18:02:09.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 17.0 in stage 10.0 (TID 262)
[2025-07-03T18:02:09.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.7 KiB) non-empty blocks including 7 (9.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.522+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 17.0 in stage 10.0 (TID 262). 6713 bytes result sent to driver
[2025-07-03T18:02:09.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 18.0 in stage 10.0 (TID 263) (39b5ac792cf9, executor driver, partition 18, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 17.0 in stage 10.0 (TID 262) in 3 ms on 39b5ac792cf9 (executor driver) (18/200)
[2025-07-03T18:02:09.524+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 18.0 in stage 10.0 (TID 263)
[2025-07-03T18:02:09.524+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.3 KiB) non-empty blocks including 7 (6.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.525+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 18.0 in stage 10.0 (TID 263). 6799 bytes result sent to driver
[2025-07-03T18:02:09.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 19.0 in stage 10.0 (TID 264) (39b5ac792cf9, executor driver, partition 19, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.530+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 18.0 in stage 10.0 (TID 263) in 6 ms on 39b5ac792cf9 (executor driver) (19/200)
[2025-07-03T18:02:09.531+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 19.0 in stage 10.0 (TID 264)
[2025-07-03T18:02:09.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.4 KiB) non-empty blocks including 7 (7.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 19.0 in stage 10.0 (TID 264). 6756 bytes result sent to driver
[2025-07-03T18:02:09.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 20.0 in stage 10.0 (TID 265) (39b5ac792cf9, executor driver, partition 20, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 19.0 in stage 10.0 (TID 264) in 4 ms on 39b5ac792cf9 (executor driver) (20/200)
[2025-07-03T18:02:09.535+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 20.0 in stage 10.0 (TID 265)
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 20.0 in stage 10.0 (TID 265). 6713 bytes result sent to driver
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 21.0 in stage 10.0 (TID 266) (39b5ac792cf9, executor driver, partition 21, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 20.0 in stage 10.0 (TID 265) in 3 ms on 39b5ac792cf9 (executor driver) (21/200)
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 21.0 in stage 10.0 (TID 266)
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 21.0 in stage 10.0 (TID 266). 6713 bytes result sent to driver
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 22.0 in stage 10.0 (TID 267) (39b5ac792cf9, executor driver, partition 22, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 22.0 in stage 10.0 (TID 267)
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 21.0 in stage 10.0 (TID 266) in 3 ms on 39b5ac792cf9 (executor driver) (22/200)
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.9 KiB) non-empty blocks including 7 (8.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 22.0 in stage 10.0 (TID 267). 6713 bytes result sent to driver
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 23.0 in stage 10.0 (TID 268) (39b5ac792cf9, executor driver, partition 23, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 23.0 in stage 10.0 (TID 268)
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 22.0 in stage 10.0 (TID 267) in 3 ms on 39b5ac792cf9 (executor driver) (23/200)
[2025-07-03T18:02:09.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.538+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.538+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 23.0 in stage 10.0 (TID 268). 6713 bytes result sent to driver
[2025-07-03T18:02:09.538+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 24.0 in stage 10.0 (TID 269) (39b5ac792cf9, executor driver, partition 24, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.538+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 24.0 in stage 10.0 (TID 269)
[2025-07-03T18:02:09.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 23.0 in stage 10.0 (TID 268) in 3 ms on 39b5ac792cf9 (executor driver) (24/200)
[2025-07-03T18:02:09.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 24.0 in stage 10.0 (TID 269). 6713 bytes result sent to driver
[2025-07-03T18:02:09.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 25.0 in stage 10.0 (TID 270) (39b5ac792cf9, executor driver, partition 25, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 25.0 in stage 10.0 (TID 270)
[2025-07-03T18:02:09.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 24.0 in stage 10.0 (TID 269) in 3 ms on 39b5ac792cf9 (executor driver) (25/200)
[2025-07-03T18:02:09.542+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.542+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.546+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 25.0 in stage 10.0 (TID 270). 6756 bytes result sent to driver
[2025-07-03T18:02:09.546+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 26.0 in stage 10.0 (TID 271) (39b5ac792cf9, executor driver, partition 26, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.549+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 26.0 in stage 10.0 (TID 271)
[2025-07-03T18:02:09.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 25.0 in stage 10.0 (TID 270) in 5 ms on 39b5ac792cf9 (executor driver) (26/200)
[2025-07-03T18:02:09.551+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.556+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 26.0 in stage 10.0 (TID 271). 6756 bytes result sent to driver
[2025-07-03T18:02:09.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 27.0 in stage 10.0 (TID 272) (39b5ac792cf9, executor driver, partition 27, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 26.0 in stage 10.0 (TID 271) in 3 ms on 39b5ac792cf9 (executor driver) (27/200)
[2025-07-03T18:02:09.559+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 27.0 in stage 10.0 (TID 272)
[2025-07-03T18:02:09.560+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.560+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 27.0 in stage 10.0 (TID 272). 6713 bytes result sent to driver
[2025-07-03T18:02:09.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 28.0 in stage 10.0 (TID 273) (39b5ac792cf9, executor driver, partition 28, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 27.0 in stage 10.0 (TID 272) in 2 ms on 39b5ac792cf9 (executor driver) (28/200)
[2025-07-03T18:02:09.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 28.0 in stage 10.0 (TID 273)
[2025-07-03T18:02:09.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.1 KiB) non-empty blocks including 7 (7.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 28.0 in stage 10.0 (TID 273). 6713 bytes result sent to driver
[2025-07-03T18:02:09.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 29.0 in stage 10.0 (TID 274) (39b5ac792cf9, executor driver, partition 29, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 28.0 in stage 10.0 (TID 273) in 3 ms on 39b5ac792cf9 (executor driver) (29/200)
[2025-07-03T18:02:09.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 29.0 in stage 10.0 (TID 274)
[2025-07-03T18:02:09.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 29.0 in stage 10.0 (TID 274). 6713 bytes result sent to driver
[2025-07-03T18:02:09.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 30.0 in stage 10.0 (TID 275) (39b5ac792cf9, executor driver, partition 30, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 30.0 in stage 10.0 (TID 275)
[2025-07-03T18:02:09.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 29.0 in stage 10.0 (TID 274) in 3 ms on 39b5ac792cf9 (executor driver) (30/200)
[2025-07-03T18:02:09.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 30.0 in stage 10.0 (TID 275). 6713 bytes result sent to driver
[2025-07-03T18:02:09.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 31.0 in stage 10.0 (TID 276) (39b5ac792cf9, executor driver, partition 31, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 31.0 in stage 10.0 (TID 276)
[2025-07-03T18:02:09.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 30.0 in stage 10.0 (TID 275) in 2 ms on 39b5ac792cf9 (executor driver) (31/200)
[2025-07-03T18:02:09.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 31.0 in stage 10.0 (TID 276). 6713 bytes result sent to driver
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 32.0 in stage 10.0 (TID 277) (39b5ac792cf9, executor driver, partition 32, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 31.0 in stage 10.0 (TID 276) in 3 ms on 39b5ac792cf9 (executor driver) (32/200)
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 32.0 in stage 10.0 (TID 277)
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 32.0 in stage 10.0 (TID 277). 6756 bytes result sent to driver
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 33.0 in stage 10.0 (TID 278) (39b5ac792cf9, executor driver, partition 33, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 33.0 in stage 10.0 (TID 278)
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 32.0 in stage 10.0 (TID 277) in 5 ms on 39b5ac792cf9 (executor driver) (33/200)
[2025-07-03T18:02:09.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 33.0 in stage 10.0 (TID 278). 6756 bytes result sent to driver
[2025-07-03T18:02:09.576+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 34.0 in stage 10.0 (TID 279) (39b5ac792cf9, executor driver, partition 34, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.576+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 34.0 in stage 10.0 (TID 279)
[2025-07-03T18:02:09.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 33.0 in stage 10.0 (TID 278) in 3 ms on 39b5ac792cf9 (executor driver) (34/200)
[2025-07-03T18:02:09.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.6 KiB) non-empty blocks including 7 (6.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-03T18:02:09.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 34.0 in stage 10.0 (TID 279). 6713 bytes result sent to driver
[2025-07-03T18:02:09.583+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 35.0 in stage 10.0 (TID 280) (39b5ac792cf9, executor driver, partition 35, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.583+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 34.0 in stage 10.0 (TID 279) in 4 ms on 39b5ac792cf9 (executor driver) (35/200)
[2025-07-03T18:02:09.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 35.0 in stage 10.0 (TID 280)
[2025-07-03T18:02:09.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 35.0 in stage 10.0 (TID 280). 6713 bytes result sent to driver
[2025-07-03T18:02:09.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 36.0 in stage 10.0 (TID 281) (39b5ac792cf9, executor driver, partition 36, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 36.0 in stage 10.0 (TID 281)
[2025-07-03T18:02:09.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 35.0 in stage 10.0 (TID 280) in 2 ms on 39b5ac792cf9 (executor driver) (36/200)
[2025-07-03T18:02:09.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 36.0 in stage 10.0 (TID 281). 6713 bytes result sent to driver
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 37.0 in stage 10.0 (TID 282) (39b5ac792cf9, executor driver, partition 37, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 36.0 in stage 10.0 (TID 281) in 2 ms on 39b5ac792cf9 (executor driver) (37/200)
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 37.0 in stage 10.0 (TID 282)
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 37.0 in stage 10.0 (TID 282). 6713 bytes result sent to driver
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 38.0 in stage 10.0 (TID 283) (39b5ac792cf9, executor driver, partition 38, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 38.0 in stage 10.0 (TID 283)
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 37.0 in stage 10.0 (TID 282) in 3 ms on 39b5ac792cf9 (executor driver) (38/200)
[2025-07-03T18:02:09.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.9 KiB) non-empty blocks including 7 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 38.0 in stage 10.0 (TID 283). 6713 bytes result sent to driver
[2025-07-03T18:02:09.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 39.0 in stage 10.0 (TID 284) (39b5ac792cf9, executor driver, partition 39, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 39.0 in stage 10.0 (TID 284)
[2025-07-03T18:02:09.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 38.0 in stage 10.0 (TID 283) in 2 ms on 39b5ac792cf9 (executor driver) (39/200)
[2025-07-03T18:02:09.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 39.0 in stage 10.0 (TID 284). 6756 bytes result sent to driver
[2025-07-03T18:02:09.590+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 40.0 in stage 10.0 (TID 285) (39b5ac792cf9, executor driver, partition 40, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.593+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 40.0 in stage 10.0 (TID 285)
[2025-07-03T18:02:09.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 39.0 in stage 10.0 (TID 284) in 7 ms on 39b5ac792cf9 (executor driver) (40/200)
[2025-07-03T18:02:09.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.9 KiB) non-empty blocks including 7 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 40.0 in stage 10.0 (TID 285). 6756 bytes result sent to driver
[2025-07-03T18:02:09.594+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 41.0 in stage 10.0 (TID 286) (39b5ac792cf9, executor driver, partition 41, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.595+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 40.0 in stage 10.0 (TID 285) in 4 ms on 39b5ac792cf9 (executor driver) (41/200)
[2025-07-03T18:02:09.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 41.0 in stage 10.0 (TID 286)
[2025-07-03T18:02:09.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 41.0 in stage 10.0 (TID 286). 6756 bytes result sent to driver
[2025-07-03T18:02:09.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 42.0 in stage 10.0 (TID 287) (39b5ac792cf9, executor driver, partition 42, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 42.0 in stage 10.0 (TID 287)
[2025-07-03T18:02:09.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 41.0 in stage 10.0 (TID 286) in 5 ms on 39b5ac792cf9 (executor driver) (42/200)
[2025-07-03T18:02:09.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 42.0 in stage 10.0 (TID 287). 6756 bytes result sent to driver
[2025-07-03T18:02:09.607+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 43.0 in stage 10.0 (TID 288) (39b5ac792cf9, executor driver, partition 43, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 42.0 in stage 10.0 (TID 287) in 5 ms on 39b5ac792cf9 (executor driver) (43/200)
[2025-07-03T18:02:09.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 43.0 in stage 10.0 (TID 288)
[2025-07-03T18:02:09.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.7 KiB) non-empty blocks including 7 (6.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 43.0 in stage 10.0 (TID 288). 6756 bytes result sent to driver
[2025-07-03T18:02:09.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 44.0 in stage 10.0 (TID 289) (39b5ac792cf9, executor driver, partition 44, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 44.0 in stage 10.0 (TID 289)
[2025-07-03T18:02:09.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 43.0 in stage 10.0 (TID 288) in 5 ms on 39b5ac792cf9 (executor driver) (44/200)
[2025-07-03T18:02:09.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 44.0 in stage 10.0 (TID 289). 6756 bytes result sent to driver
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 45.0 in stage 10.0 (TID 290) (39b5ac792cf9, executor driver, partition 45, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 44.0 in stage 10.0 (TID 289) in 4 ms on 39b5ac792cf9 (executor driver) (45/200)
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 45.0 in stage 10.0 (TID 290)
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.4 KiB) non-empty blocks including 7 (7.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 45.0 in stage 10.0 (TID 290). 6756 bytes result sent to driver
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 46.0 in stage 10.0 (TID 291) (39b5ac792cf9, executor driver, partition 46, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 45.0 in stage 10.0 (TID 290) in 6 ms on 39b5ac792cf9 (executor driver) (46/200)
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 46.0 in stage 10.0 (TID 291)
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.5 KiB) non-empty blocks including 7 (6.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 46.0 in stage 10.0 (TID 291). 6756 bytes result sent to driver
[2025-07-03T18:02:09.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 47.0 in stage 10.0 (TID 292) (39b5ac792cf9, executor driver, partition 47, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 47.0 in stage 10.0 (TID 292)
[2025-07-03T18:02:09.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 46.0 in stage 10.0 (TID 291) in 6 ms on 39b5ac792cf9 (executor driver) (47/200)
[2025-07-03T18:02:09.625+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.625+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.627+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 47.0 in stage 10.0 (TID 292). 6756 bytes result sent to driver
[2025-07-03T18:02:09.627+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 48.0 in stage 10.0 (TID 293) (39b5ac792cf9, executor driver, partition 48, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 48.0 in stage 10.0 (TID 293)
[2025-07-03T18:02:09.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 47.0 in stage 10.0 (TID 292) in 5 ms on 39b5ac792cf9 (executor driver) (48/200)
[2025-07-03T18:02:09.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.3 KiB) non-empty blocks including 7 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.634+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 48.0 in stage 10.0 (TID 293). 6842 bytes result sent to driver
[2025-07-03T18:02:09.634+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 49.0 in stage 10.0 (TID 294) (39b5ac792cf9, executor driver, partition 49, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 49.0 in stage 10.0 (TID 294)
[2025-07-03T18:02:09.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 48.0 in stage 10.0 (TID 293) in 8 ms on 39b5ac792cf9 (executor driver) (49/200)
[2025-07-03T18:02:09.640+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.7 KiB) non-empty blocks including 7 (6.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.641+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.641+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 49.0 in stage 10.0 (TID 294). 6756 bytes result sent to driver
[2025-07-03T18:02:09.642+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 50.0 in stage 10.0 (TID 295) (39b5ac792cf9, executor driver, partition 50, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 49.0 in stage 10.0 (TID 294) in 4 ms on 39b5ac792cf9 (executor driver) (50/200)
[2025-07-03T18:02:09.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 50.0 in stage 10.0 (TID 295)
[2025-07-03T18:02:09.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 50.0 in stage 10.0 (TID 295). 6713 bytes result sent to driver
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 51.0 in stage 10.0 (TID 296) (39b5ac792cf9, executor driver, partition 51, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 50.0 in stage 10.0 (TID 295) in 3 ms on 39b5ac792cf9 (executor driver) (51/200)
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 51.0 in stage 10.0 (TID 296)
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.7 KiB) non-empty blocks including 7 (7.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 51.0 in stage 10.0 (TID 296). 6713 bytes result sent to driver
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 52.0 in stage 10.0 (TID 297) (39b5ac792cf9, executor driver, partition 52, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 52.0 in stage 10.0 (TID 297)
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 51.0 in stage 10.0 (TID 296) in 3 ms on 39b5ac792cf9 (executor driver) (52/200)
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 52.0 in stage 10.0 (TID 297). 6713 bytes result sent to driver
[2025-07-03T18:02:09.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 53.0 in stage 10.0 (TID 298) (39b5ac792cf9, executor driver, partition 53, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 53.0 in stage 10.0 (TID 298)
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 52.0 in stage 10.0 (TID 297) in 3 ms on 39b5ac792cf9 (executor driver) (53/200)
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 53.0 in stage 10.0 (TID 298). 6713 bytes result sent to driver
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 54.0 in stage 10.0 (TID 299) (39b5ac792cf9, executor driver, partition 54, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 53.0 in stage 10.0 (TID 298) in 3 ms on 39b5ac792cf9 (executor driver) (54/200)
[2025-07-03T18:02:09.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 54.0 in stage 10.0 (TID 299)
[2025-07-03T18:02:09.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.651+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 54.0 in stage 10.0 (TID 299). 6756 bytes result sent to driver
[2025-07-03T18:02:09.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 55.0 in stage 10.0 (TID 300) (39b5ac792cf9, executor driver, partition 55, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.656+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 55.0 in stage 10.0 (TID 300)
[2025-07-03T18:02:09.656+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 54.0 in stage 10.0 (TID 299) in 5 ms on 39b5ac792cf9 (executor driver) (55/200)
[2025-07-03T18:02:09.657+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.2 KiB) non-empty blocks including 7 (8.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.657+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.658+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 55.0 in stage 10.0 (TID 300). 6756 bytes result sent to driver
[2025-07-03T18:02:09.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 56.0 in stage 10.0 (TID 301) (39b5ac792cf9, executor driver, partition 56, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.659+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 55.0 in stage 10.0 (TID 300) in 6 ms on 39b5ac792cf9 (executor driver) (56/200)
[2025-07-03T18:02:09.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 56.0 in stage 10.0 (TID 301)
[2025-07-03T18:02:09.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.662+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 56.0 in stage 10.0 (TID 301). 6756 bytes result sent to driver
[2025-07-03T18:02:09.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 57.0 in stage 10.0 (TID 302) (39b5ac792cf9, executor driver, partition 57, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.665+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 57.0 in stage 10.0 (TID 302)
[2025-07-03T18:02:09.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 56.0 in stage 10.0 (TID 301) in 6 ms on 39b5ac792cf9 (executor driver) (57/200)
[2025-07-03T18:02:09.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.8 KiB) non-empty blocks including 7 (6.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 57.0 in stage 10.0 (TID 302). 6756 bytes result sent to driver
[2025-07-03T18:02:09.669+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 58.0 in stage 10.0 (TID 303) (39b5ac792cf9, executor driver, partition 58, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.670+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 57.0 in stage 10.0 (TID 302) in 5 ms on 39b5ac792cf9 (executor driver) (58/200)
[2025-07-03T18:02:09.670+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 58.0 in stage 10.0 (TID 303)
[2025-07-03T18:02:09.671+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.671+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.674+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 58.0 in stage 10.0 (TID 303). 6799 bytes result sent to driver
[2025-07-03T18:02:09.674+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 59.0 in stage 10.0 (TID 304) (39b5ac792cf9, executor driver, partition 59, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.677+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 59.0 in stage 10.0 (TID 304)
[2025-07-03T18:02:09.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 58.0 in stage 10.0 (TID 303) in 5 ms on 39b5ac792cf9 (executor driver) (59/200)
[2025-07-03T18:02:09.678+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.680+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.683+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 59.0 in stage 10.0 (TID 304). 6756 bytes result sent to driver
[2025-07-03T18:02:09.684+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 60.0 in stage 10.0 (TID 305) (39b5ac792cf9, executor driver, partition 60, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.686+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 60.0 in stage 10.0 (TID 305)
[2025-07-03T18:02:09.686+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 59.0 in stage 10.0 (TID 304) in 3 ms on 39b5ac792cf9 (executor driver) (60/200)
[2025-07-03T18:02:09.688+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.689+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.692+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 60.0 in stage 10.0 (TID 305). 6756 bytes result sent to driver
[2025-07-03T18:02:09.693+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 61.0 in stage 10.0 (TID 306) (39b5ac792cf9, executor driver, partition 61, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.693+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 60.0 in stage 10.0 (TID 305) in 3 ms on 39b5ac792cf9 (executor driver) (61/200)
[2025-07-03T18:02:09.694+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 61.0 in stage 10.0 (TID 306)
[2025-07-03T18:02:09.695+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 61.0 in stage 10.0 (TID 306). 6713 bytes result sent to driver
[2025-07-03T18:02:09.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 62.0 in stage 10.0 (TID 307) (39b5ac792cf9, executor driver, partition 62, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.696+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 61.0 in stage 10.0 (TID 306) in 3 ms on 39b5ac792cf9 (executor driver) (62/200)
[2025-07-03T18:02:09.699+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 62.0 in stage 10.0 (TID 307)
[2025-07-03T18:02:09.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.9 KiB) non-empty blocks including 7 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.701+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 62.0 in stage 10.0 (TID 307). 6713 bytes result sent to driver
[2025-07-03T18:02:09.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 63.0 in stage 10.0 (TID 308) (39b5ac792cf9, executor driver, partition 63, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 63.0 in stage 10.0 (TID 308)
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 62.0 in stage 10.0 (TID 307) in 3 ms on 39b5ac792cf9 (executor driver) (63/200)
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 63.0 in stage 10.0 (TID 308). 6713 bytes result sent to driver
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 64.0 in stage 10.0 (TID 309) (39b5ac792cf9, executor driver, partition 64, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 64.0 in stage 10.0 (TID 309)
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 63.0 in stage 10.0 (TID 308) in 3 ms on 39b5ac792cf9 (executor driver) (64/200)
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.703+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.704+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 64.0 in stage 10.0 (TID 309). 6756 bytes result sent to driver
[2025-07-03T18:02:09.704+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 65.0 in stage 10.0 (TID 310) (39b5ac792cf9, executor driver, partition 65, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.704+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 65.0 in stage 10.0 (TID 310)
[2025-07-03T18:02:09.704+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 64.0 in stage 10.0 (TID 309) in 4 ms on 39b5ac792cf9 (executor driver) (65/200)
[2025-07-03T18:02:09.707+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.707+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.710+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 65.0 in stage 10.0 (TID 310). 6756 bytes result sent to driver
[2025-07-03T18:02:09.710+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 66.0 in stage 10.0 (TID 311) (39b5ac792cf9, executor driver, partition 66, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.713+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 65.0 in stage 10.0 (TID 310) in 4 ms on 39b5ac792cf9 (executor driver) (66/200)
[2025-07-03T18:02:09.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 66.0 in stage 10.0 (TID 311)
[2025-07-03T18:02:09.715+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 66.0 in stage 10.0 (TID 311). 6756 bytes result sent to driver
[2025-07-03T18:02:09.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 67.0 in stage 10.0 (TID 312) (39b5ac792cf9, executor driver, partition 67, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 66.0 in stage 10.0 (TID 311) in 3 ms on 39b5ac792cf9 (executor driver) (67/200)
[2025-07-03T18:02:09.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 67.0 in stage 10.0 (TID 312)
[2025-07-03T18:02:09.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.7 KiB) non-empty blocks including 7 (7.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.725+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 67.0 in stage 10.0 (TID 312). 6799 bytes result sent to driver
[2025-07-03T18:02:09.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 68.0 in stage 10.0 (TID 313) (39b5ac792cf9, executor driver, partition 68, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.729+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 68.0 in stage 10.0 (TID 313)
[2025-07-03T18:02:09.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 67.0 in stage 10.0 (TID 312) in 5 ms on 39b5ac792cf9 (executor driver) (68/200)
[2025-07-03T18:02:09.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.9 KiB) non-empty blocks including 7 (8.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.731+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 68.0 in stage 10.0 (TID 313). 6756 bytes result sent to driver
[2025-07-03T18:02:09.731+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 69.0 in stage 10.0 (TID 314) (39b5ac792cf9, executor driver, partition 69, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.731+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 69.0 in stage 10.0 (TID 314)
[2025-07-03T18:02:09.731+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 68.0 in stage 10.0 (TID 313) in 3 ms on 39b5ac792cf9 (executor driver) (69/200)
[2025-07-03T18:02:09.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 69.0 in stage 10.0 (TID 314). 6713 bytes result sent to driver
[2025-07-03T18:02:09.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 70.0 in stage 10.0 (TID 315) (39b5ac792cf9, executor driver, partition 70, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 70.0 in stage 10.0 (TID 315)
[2025-07-03T18:02:09.732+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 69.0 in stage 10.0 (TID 314) in 3 ms on 39b5ac792cf9 (executor driver) (70/200)
[2025-07-03T18:02:09.733+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.9 KiB) non-empty blocks including 7 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 70.0 in stage 10.0 (TID 315). 6713 bytes result sent to driver
[2025-07-03T18:02:09.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 71.0 in stage 10.0 (TID 316) (39b5ac792cf9, executor driver, partition 71, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.736+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 71.0 in stage 10.0 (TID 316)
[2025-07-03T18:02:09.738+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 70.0 in stage 10.0 (TID 315) in 3 ms on 39b5ac792cf9 (executor driver) (71/200)
[2025-07-03T18:02:09.739+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 71.0 in stage 10.0 (TID 316). 6713 bytes result sent to driver
[2025-07-03T18:02:09.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 72.0 in stage 10.0 (TID 317) (39b5ac792cf9, executor driver, partition 72, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.743+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 71.0 in stage 10.0 (TID 316) in 3 ms on 39b5ac792cf9 (executor driver) (72/200)
[2025-07-03T18:02:09.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 72.0 in stage 10.0 (TID 317)
[2025-07-03T18:02:09.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 72.0 in stage 10.0 (TID 317). 6756 bytes result sent to driver
[2025-07-03T18:02:09.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 73.0 in stage 10.0 (TID 318) (39b5ac792cf9, executor driver, partition 73, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 72.0 in stage 10.0 (TID 317) in 3 ms on 39b5ac792cf9 (executor driver) (73/200)
[2025-07-03T18:02:09.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 73.0 in stage 10.0 (TID 318)
[2025-07-03T18:02:09.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.9 KiB) non-empty blocks including 7 (8.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 73.0 in stage 10.0 (TID 318). 6713 bytes result sent to driver
[2025-07-03T18:02:09.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 74.0 in stage 10.0 (TID 319) (39b5ac792cf9, executor driver, partition 74, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 74.0 in stage 10.0 (TID 319)
[2025-07-03T18:02:09.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 73.0 in stage 10.0 (TID 318) in 3 ms on 39b5ac792cf9 (executor driver) (74/200)
[2025-07-03T18:02:09.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 74.0 in stage 10.0 (TID 319). 6713 bytes result sent to driver
[2025-07-03T18:02:09.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 75.0 in stage 10.0 (TID 320) (39b5ac792cf9, executor driver, partition 75, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 75.0 in stage 10.0 (TID 320)
[2025-07-03T18:02:09.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 74.0 in stage 10.0 (TID 319) in 3 ms on 39b5ac792cf9 (executor driver) (75/200)
[2025-07-03T18:02:09.757+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.2 KiB) non-empty blocks including 7 (8.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.757+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.757+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 75.0 in stage 10.0 (TID 320). 6713 bytes result sent to driver
[2025-07-03T18:02:09.757+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 76.0 in stage 10.0 (TID 321) (39b5ac792cf9, executor driver, partition 76, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 75.0 in stage 10.0 (TID 320) in 3 ms on 39b5ac792cf9 (executor driver) (76/200)
[2025-07-03T18:02:09.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 76.0 in stage 10.0 (TID 321)
[2025-07-03T18:02:09.763+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.8 KiB) non-empty blocks including 7 (6.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 76.0 in stage 10.0 (TID 321). 6713 bytes result sent to driver
[2025-07-03T18:02:09.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 77.0 in stage 10.0 (TID 322) (39b5ac792cf9, executor driver, partition 77, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 76.0 in stage 10.0 (TID 321) in 2 ms on 39b5ac792cf9 (executor driver) (77/200)
[2025-07-03T18:02:09.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 77.0 in stage 10.0 (TID 322)
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.4 KiB) non-empty blocks including 7 (7.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 77.0 in stage 10.0 (TID 322). 6756 bytes result sent to driver
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 78.0 in stage 10.0 (TID 323) (39b5ac792cf9, executor driver, partition 78, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 78.0 in stage 10.0 (TID 323)
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 77.0 in stage 10.0 (TID 322) in 5 ms on 39b5ac792cf9 (executor driver) (78/200)
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.8 KiB) non-empty blocks including 7 (8.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 78.0 in stage 10.0 (TID 323). 6756 bytes result sent to driver
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 79.0 in stage 10.0 (TID 324) (39b5ac792cf9, executor driver, partition 79, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 78.0 in stage 10.0 (TID 323) in 3 ms on 39b5ac792cf9 (executor driver) (79/200)
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 79.0 in stage 10.0 (TID 324)
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 79.0 in stage 10.0 (TID 324). 6713 bytes result sent to driver
[2025-07-03T18:02:09.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 80.0 in stage 10.0 (TID 325) (39b5ac792cf9, executor driver, partition 80, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 80.0 in stage 10.0 (TID 325)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 79.0 in stage 10.0 (TID 324) in 3 ms on 39b5ac792cf9 (executor driver) (80/200)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.6 KiB) non-empty blocks including 7 (7.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 80.0 in stage 10.0 (TID 325). 6713 bytes result sent to driver
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 81.0 in stage 10.0 (TID 326) (39b5ac792cf9, executor driver, partition 81, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 81.0 in stage 10.0 (TID 326)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 80.0 in stage 10.0 (TID 325) in 2 ms on 39b5ac792cf9 (executor driver) (81/200)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 81.0 in stage 10.0 (TID 326). 6713 bytes result sent to driver
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 82.0 in stage 10.0 (TID 327) (39b5ac792cf9, executor driver, partition 82, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 82.0 in stage 10.0 (TID 327)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 81.0 in stage 10.0 (TID 326) in 3 ms on 39b5ac792cf9 (executor driver) (82/200)
[2025-07-03T18:02:09.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 82.0 in stage 10.0 (TID 327). 6713 bytes result sent to driver
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 83.0 in stage 10.0 (TID 328) (39b5ac792cf9, executor driver, partition 83, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 82.0 in stage 10.0 (TID 327) in 3 ms on 39b5ac792cf9 (executor driver) (83/200)
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 83.0 in stage 10.0 (TID 328)
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 83.0 in stage 10.0 (TID 328). 6713 bytes result sent to driver
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 84.0 in stage 10.0 (TID 329) (39b5ac792cf9, executor driver, partition 84, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 84.0 in stage 10.0 (TID 329)
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 83.0 in stage 10.0 (TID 328) in 2 ms on 39b5ac792cf9 (executor driver) (84/200)
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 84.0 in stage 10.0 (TID 329). 6713 bytes result sent to driver
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 85.0 in stage 10.0 (TID 330) (39b5ac792cf9, executor driver, partition 85, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 84.0 in stage 10.0 (TID 329) in 2 ms on 39b5ac792cf9 (executor driver) (85/200)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 85.0 in stage 10.0 (TID 330)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.9 KiB) non-empty blocks including 7 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 85.0 in stage 10.0 (TID 330). 6713 bytes result sent to driver
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 86.0 in stage 10.0 (TID 331) (39b5ac792cf9, executor driver, partition 86, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 85.0 in stage 10.0 (TID 330) in 3 ms on 39b5ac792cf9 (executor driver) (86/200)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 86.0 in stage 10.0 (TID 331)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 86.0 in stage 10.0 (TID 331). 6799 bytes result sent to driver
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 87.0 in stage 10.0 (TID 332) (39b5ac792cf9, executor driver, partition 87, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 87.0 in stage 10.0 (TID 332)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 86.0 in stage 10.0 (TID 331) in 5 ms on 39b5ac792cf9 (executor driver) (87/200)
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.3 KiB) non-empty blocks including 7 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 87.0 in stage 10.0 (TID 332). 6756 bytes result sent to driver
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 88.0 in stage 10.0 (TID 333) (39b5ac792cf9, executor driver, partition 88, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 87.0 in stage 10.0 (TID 332) in 4 ms on 39b5ac792cf9 (executor driver) (88/200)
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 88.0 in stage 10.0 (TID 333)
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.5 KiB) non-empty blocks including 7 (6.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 88.0 in stage 10.0 (TID 333). 6713 bytes result sent to driver
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 89.0 in stage 10.0 (TID 334) (39b5ac792cf9, executor driver, partition 89, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 88.0 in stage 10.0 (TID 333) in 3 ms on 39b5ac792cf9 (executor driver) (89/200)
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 89.0 in stage 10.0 (TID 334)
[2025-07-03T18:02:09.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.775+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.775+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 89.0 in stage 10.0 (TID 334). 6713 bytes result sent to driver
[2025-07-03T18:02:09.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 90.0 in stage 10.0 (TID 335) (39b5ac792cf9, executor driver, partition 90, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.778+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 89.0 in stage 10.0 (TID 334) in 3 ms on 39b5ac792cf9 (executor driver) (90/200)
[2025-07-03T18:02:09.779+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 90.0 in stage 10.0 (TID 335)
[2025-07-03T18:02:09.780+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 90.0 in stage 10.0 (TID 335). 6713 bytes result sent to driver
[2025-07-03T18:02:09.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 91.0 in stage 10.0 (TID 336) (39b5ac792cf9, executor driver, partition 91, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 91.0 in stage 10.0 (TID 336)
[2025-07-03T18:02:09.781+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 90.0 in stage 10.0 (TID 335) in 3 ms on 39b5ac792cf9 (executor driver) (91/200)
[2025-07-03T18:02:09.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 91.0 in stage 10.0 (TID 336). 6713 bytes result sent to driver
[2025-07-03T18:02:09.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 92.0 in stage 10.0 (TID 337) (39b5ac792cf9, executor driver, partition 92, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.782+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 92.0 in stage 10.0 (TID 337)
[2025-07-03T18:02:09.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 91.0 in stage 10.0 (TID 336) in 3 ms on 39b5ac792cf9 (executor driver) (92/200)
[2025-07-03T18:02:09.783+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.784+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 92.0 in stage 10.0 (TID 337). 6713 bytes result sent to driver
[2025-07-03T18:02:09.786+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 93.0 in stage 10.0 (TID 338) (39b5ac792cf9, executor driver, partition 93, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.788+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 93.0 in stage 10.0 (TID 338)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 92.0 in stage 10.0 (TID 337) in 2 ms on 39b5ac792cf9 (executor driver) (93/200)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.3 KiB) non-empty blocks including 7 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 93.0 in stage 10.0 (TID 338). 6713 bytes result sent to driver
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 94.0 in stage 10.0 (TID 339) (39b5ac792cf9, executor driver, partition 94, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 94.0 in stage 10.0 (TID 339)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 93.0 in stage 10.0 (TID 338) in 3 ms on 39b5ac792cf9 (executor driver) (94/200)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.9 KiB) non-empty blocks including 7 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 94.0 in stage 10.0 (TID 339). 6670 bytes result sent to driver
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 95.0 in stage 10.0 (TID 340) (39b5ac792cf9, executor driver, partition 95, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 95.0 in stage 10.0 (TID 340)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 94.0 in stage 10.0 (TID 339) in 3 ms on 39b5ac792cf9 (executor driver) (95/200)
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.8 KiB) non-empty blocks including 7 (6.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.789+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 95.0 in stage 10.0 (TID 340). 6670 bytes result sent to driver
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 96.0 in stage 10.0 (TID 341) (39b5ac792cf9, executor driver, partition 96, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 95.0 in stage 10.0 (TID 340) in 3 ms on 39b5ac792cf9 (executor driver) (96/200)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 96.0 in stage 10.0 (TID 341)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 96.0 in stage 10.0 (TID 341). 6756 bytes result sent to driver
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 97.0 in stage 10.0 (TID 342) (39b5ac792cf9, executor driver, partition 97, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 96.0 in stage 10.0 (TID 341) in 5 ms on 39b5ac792cf9 (executor driver) (97/200)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 97.0 in stage 10.0 (TID 342)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 97.0 in stage 10.0 (TID 342). 6713 bytes result sent to driver
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 98.0 in stage 10.0 (TID 343) (39b5ac792cf9, executor driver, partition 98, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 97.0 in stage 10.0 (TID 342) in 3 ms on 39b5ac792cf9 (executor driver) (98/200)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 98.0 in stage 10.0 (TID 343)
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.790+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 98.0 in stage 10.0 (TID 343). 6713 bytes result sent to driver
[2025-07-03T18:02:09.791+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 99.0 in stage 10.0 (TID 344) (39b5ac792cf9, executor driver, partition 99, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.791+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 98.0 in stage 10.0 (TID 343) in 3 ms on 39b5ac792cf9 (executor driver) (99/200)
[2025-07-03T18:02:09.791+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 99.0 in stage 10.0 (TID 344)
[2025-07-03T18:02:09.791+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.792+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.793+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 99.0 in stage 10.0 (TID 344). 6756 bytes result sent to driver
[2025-07-03T18:02:09.793+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 100.0 in stage 10.0 (TID 345) (39b5ac792cf9, executor driver, partition 100, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.795+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 100.0 in stage 10.0 (TID 345)
[2025-07-03T18:02:09.796+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 99.0 in stage 10.0 (TID 344) in 4 ms on 39b5ac792cf9 (executor driver) (100/200)
[2025-07-03T18:02:09.797+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.9 KiB) non-empty blocks including 7 (8.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.798+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.798+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 100.0 in stage 10.0 (TID 345). 6713 bytes result sent to driver
[2025-07-03T18:02:09.800+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 101.0 in stage 10.0 (TID 346) (39b5ac792cf9, executor driver, partition 101, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.801+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 101.0 in stage 10.0 (TID 346)
[2025-07-03T18:02:09.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 100.0 in stage 10.0 (TID 345) in 3 ms on 39b5ac792cf9 (executor driver) (101/200)
[2025-07-03T18:02:09.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 101.0 in stage 10.0 (TID 346). 6713 bytes result sent to driver
[2025-07-03T18:02:09.804+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 102.0 in stage 10.0 (TID 347) (39b5ac792cf9, executor driver, partition 102, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 101.0 in stage 10.0 (TID 346) in 3 ms on 39b5ac792cf9 (executor driver) (102/200)
[2025-07-03T18:02:09.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 102.0 in stage 10.0 (TID 347)
[2025-07-03T18:02:09.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.1 KiB) non-empty blocks including 7 (9.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.806+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 102.0 in stage 10.0 (TID 347). 6713 bytes result sent to driver
[2025-07-03T18:02:09.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 103.0 in stage 10.0 (TID 348) (39b5ac792cf9, executor driver, partition 103, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 103.0 in stage 10.0 (TID 348)
[2025-07-03T18:02:09.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 102.0 in stage 10.0 (TID 347) in 2 ms on 39b5ac792cf9 (executor driver) (103/200)
[2025-07-03T18:02:09.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.1 KiB) non-empty blocks including 7 (7.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.808+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.810+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 103.0 in stage 10.0 (TID 348). 6713 bytes result sent to driver
[2025-07-03T18:02:09.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 104.0 in stage 10.0 (TID 349) (39b5ac792cf9, executor driver, partition 104, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 103.0 in stage 10.0 (TID 348) in 2 ms on 39b5ac792cf9 (executor driver) (104/200)
[2025-07-03T18:02:09.814+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 104.0 in stage 10.0 (TID 349)
[2025-07-03T18:02:09.815+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.5 KiB) non-empty blocks including 7 (8.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 104.0 in stage 10.0 (TID 349). 6713 bytes result sent to driver
[2025-07-03T18:02:09.816+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 105.0 in stage 10.0 (TID 350) (39b5ac792cf9, executor driver, partition 105, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 105.0 in stage 10.0 (TID 350)
[2025-07-03T18:02:09.820+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 104.0 in stage 10.0 (TID 349) in 3 ms on 39b5ac792cf9 (executor driver) (105/200)
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 105.0 in stage 10.0 (TID 350). 6756 bytes result sent to driver
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 106.0 in stage 10.0 (TID 351) (39b5ac792cf9, executor driver, partition 106, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 106.0 in stage 10.0 (TID 351)
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 105.0 in stage 10.0 (TID 350) in 6 ms on 39b5ac792cf9 (executor driver) (106/200)
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 106.0 in stage 10.0 (TID 351). 6756 bytes result sent to driver
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 107.0 in stage 10.0 (TID 352) (39b5ac792cf9, executor driver, partition 107, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 107.0 in stage 10.0 (TID 352)
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 106.0 in stage 10.0 (TID 351) in 7 ms on 39b5ac792cf9 (executor driver) (107/200)
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.3 KiB) non-empty blocks including 7 (6.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 107.0 in stage 10.0 (TID 352). 6756 bytes result sent to driver
[2025-07-03T18:02:09.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 108.0 in stage 10.0 (TID 353) (39b5ac792cf9, executor driver, partition 108, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 107.0 in stage 10.0 (TID 352) in 4 ms on 39b5ac792cf9 (executor driver) (108/200)
[2025-07-03T18:02:09.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 108.0 in stage 10.0 (TID 353)
[2025-07-03T18:02:09.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.6 KiB) non-empty blocks including 7 (6.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.822+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 108.0 in stage 10.0 (TID 353). 6713 bytes result sent to driver
[2025-07-03T18:02:09.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 109.0 in stage 10.0 (TID 354) (39b5ac792cf9, executor driver, partition 109, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.826+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 109.0 in stage 10.0 (TID 354)
[2025-07-03T18:02:09.826+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 108.0 in stage 10.0 (TID 353) in 3 ms on 39b5ac792cf9 (executor driver) (109/200)
[2025-07-03T18:02:09.827+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.1 KiB) non-empty blocks including 7 (7.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 109.0 in stage 10.0 (TID 354). 6713 bytes result sent to driver
[2025-07-03T18:02:09.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 110.0 in stage 10.0 (TID 355) (39b5ac792cf9, executor driver, partition 110, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 110.0 in stage 10.0 (TID 355)
[2025-07-03T18:02:09.833+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 109.0 in stage 10.0 (TID 354) in 3 ms on 39b5ac792cf9 (executor driver) (110/200)
[2025-07-03T18:02:09.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (10.3 KiB) non-empty blocks including 7 (10.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 110.0 in stage 10.0 (TID 355). 6713 bytes result sent to driver
[2025-07-03T18:02:09.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 111.0 in stage 10.0 (TID 356) (39b5ac792cf9, executor driver, partition 111, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 111.0 in stage 10.0 (TID 356)
[2025-07-03T18:02:09.836+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 110.0 in stage 10.0 (TID 355) in 2 ms on 39b5ac792cf9 (executor driver) (111/200)
[2025-07-03T18:02:09.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 111.0 in stage 10.0 (TID 356). 6713 bytes result sent to driver
[2025-07-03T18:02:09.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 112.0 in stage 10.0 (TID 357) (39b5ac792cf9, executor driver, partition 112, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 111.0 in stage 10.0 (TID 356) in 3 ms on 39b5ac792cf9 (executor driver) (112/200)
[2025-07-03T18:02:09.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 112.0 in stage 10.0 (TID 357)
[2025-07-03T18:02:09.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.2 KiB) non-empty blocks including 7 (8.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 112.0 in stage 10.0 (TID 357). 6713 bytes result sent to driver
[2025-07-03T18:02:09.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 113.0 in stage 10.0 (TID 358) (39b5ac792cf9, executor driver, partition 113, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 112.0 in stage 10.0 (TID 357) in 3 ms on 39b5ac792cf9 (executor driver) (113/200)
[2025-07-03T18:02:09.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 113.0 in stage 10.0 (TID 358)
[2025-07-03T18:02:09.843+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.843+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 113.0 in stage 10.0 (TID 358). 6713 bytes result sent to driver
[2025-07-03T18:02:09.846+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 114.0 in stage 10.0 (TID 359) (39b5ac792cf9, executor driver, partition 114, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.848+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 114.0 in stage 10.0 (TID 359)
[2025-07-03T18:02:09.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 113.0 in stage 10.0 (TID 358) in 3 ms on 39b5ac792cf9 (executor driver) (114/200)
[2025-07-03T18:02:09.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 114.0 in stage 10.0 (TID 359). 6799 bytes result sent to driver
[2025-07-03T18:02:09.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 115.0 in stage 10.0 (TID 360) (39b5ac792cf9, executor driver, partition 115, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.853+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 114.0 in stage 10.0 (TID 359) in 6 ms on 39b5ac792cf9 (executor driver) (115/200)
[2025-07-03T18:02:09.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 115.0 in stage 10.0 (TID 360)
[2025-07-03T18:02:09.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.7 KiB) non-empty blocks including 7 (6.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 115.0 in stage 10.0 (TID 360). 6713 bytes result sent to driver
[2025-07-03T18:02:09.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 116.0 in stage 10.0 (TID 361) (39b5ac792cf9, executor driver, partition 116, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 115.0 in stage 10.0 (TID 360) in 2 ms on 39b5ac792cf9 (executor driver) (116/200)
[2025-07-03T18:02:09.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 116.0 in stage 10.0 (TID 361)
[2025-07-03T18:02:09.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.7 KiB) non-empty blocks including 7 (7.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 116.0 in stage 10.0 (TID 361). 6713 bytes result sent to driver
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 117.0 in stage 10.0 (TID 362) (39b5ac792cf9, executor driver, partition 117, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 116.0 in stage 10.0 (TID 361) in 3 ms on 39b5ac792cf9 (executor driver) (117/200)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 117.0 in stage 10.0 (TID 362)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.6 KiB) non-empty blocks including 7 (7.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 117.0 in stage 10.0 (TID 362). 6713 bytes result sent to driver
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 118.0 in stage 10.0 (TID 363) (39b5ac792cf9, executor driver, partition 118, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 118.0 in stage 10.0 (TID 363)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 117.0 in stage 10.0 (TID 362) in 3 ms on 39b5ac792cf9 (executor driver) (118/200)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.5 KiB) non-empty blocks including 7 (8.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 118.0 in stage 10.0 (TID 363). 6713 bytes result sent to driver
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 119.0 in stage 10.0 (TID 364) (39b5ac792cf9, executor driver, partition 119, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 119.0 in stage 10.0 (TID 364)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 118.0 in stage 10.0 (TID 363) in 3 ms on 39b5ac792cf9 (executor driver) (119/200)
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 119.0 in stage 10.0 (TID 364). 6713 bytes result sent to driver
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 120.0 in stage 10.0 (TID 365) (39b5ac792cf9, executor driver, partition 120, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 119.0 in stage 10.0 (TID 364) in 2 ms on 39b5ac792cf9 (executor driver) (120/200)
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 120.0 in stage 10.0 (TID 365)
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 120.0 in stage 10.0 (TID 365). 6713 bytes result sent to driver
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 121.0 in stage 10.0 (TID 366) (39b5ac792cf9, executor driver, partition 121, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 121.0 in stage 10.0 (TID 366)
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 120.0 in stage 10.0 (TID 365) in 3 ms on 39b5ac792cf9 (executor driver) (121/200)
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.9 KiB) non-empty blocks including 7 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 121.0 in stage 10.0 (TID 366). 6713 bytes result sent to driver
[2025-07-03T18:02:09.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 122.0 in stage 10.0 (TID 367) (39b5ac792cf9, executor driver, partition 122, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 121.0 in stage 10.0 (TID 366) in 2 ms on 39b5ac792cf9 (executor driver) (122/200)
[2025-07-03T18:02:09.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 122.0 in stage 10.0 (TID 367)
[2025-07-03T18:02:09.860+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.860+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 122.0 in stage 10.0 (TID 367). 6713 bytes result sent to driver
[2025-07-03T18:02:09.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 123.0 in stage 10.0 (TID 368) (39b5ac792cf9, executor driver, partition 123, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 123.0 in stage 10.0 (TID 368)
[2025-07-03T18:02:09.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 122.0 in stage 10.0 (TID 367) in 3 ms on 39b5ac792cf9 (executor driver) (123/200)
[2025-07-03T18:02:09.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 123.0 in stage 10.0 (TID 368). 6756 bytes result sent to driver
[2025-07-03T18:02:09.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 124.0 in stage 10.0 (TID 369) (39b5ac792cf9, executor driver, partition 124, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 124.0 in stage 10.0 (TID 369)
[2025-07-03T18:02:09.869+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 123.0 in stage 10.0 (TID 368) in 4 ms on 39b5ac792cf9 (executor driver) (124/200)
[2025-07-03T18:02:09.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.8 KiB) non-empty blocks including 7 (8.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.870+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.871+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 124.0 in stage 10.0 (TID 369). 6713 bytes result sent to driver
[2025-07-03T18:02:09.873+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 125.0 in stage 10.0 (TID 370) (39b5ac792cf9, executor driver, partition 125, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.874+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 124.0 in stage 10.0 (TID 369) in 3 ms on 39b5ac792cf9 (executor driver) (125/200)
[2025-07-03T18:02:09.875+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 125.0 in stage 10.0 (TID 370)
[2025-07-03T18:02:09.875+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (5.8 KiB) non-empty blocks including 7 (5.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.878+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.879+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 125.0 in stage 10.0 (TID 370). 6713 bytes result sent to driver
[2025-07-03T18:02:09.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 126.0 in stage 10.0 (TID 371) (39b5ac792cf9, executor driver, partition 126, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.880+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 126.0 in stage 10.0 (TID 371)
[2025-07-03T18:02:09.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 125.0 in stage 10.0 (TID 370) in 3 ms on 39b5ac792cf9 (executor driver) (126/200)
[2025-07-03T18:02:09.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.8 KiB) non-empty blocks including 7 (8.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 126.0 in stage 10.0 (TID 371). 6713 bytes result sent to driver
[2025-07-03T18:02:09.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 127.0 in stage 10.0 (TID 372) (39b5ac792cf9, executor driver, partition 127, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 126.0 in stage 10.0 (TID 371) in 3 ms on 39b5ac792cf9 (executor driver) (127/200)
[2025-07-03T18:02:09.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 127.0 in stage 10.0 (TID 372)
[2025-07-03T18:02:09.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.8 KiB) non-empty blocks including 7 (9.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 127.0 in stage 10.0 (TID 372). 6713 bytes result sent to driver
[2025-07-03T18:02:09.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 128.0 in stage 10.0 (TID 373) (39b5ac792cf9, executor driver, partition 128, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 128.0 in stage 10.0 (TID 373)
[2025-07-03T18:02:09.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 127.0 in stage 10.0 (TID 372) in 3 ms on 39b5ac792cf9 (executor driver) (128/200)
[2025-07-03T18:02:09.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.9 KiB) non-empty blocks including 7 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 128.0 in stage 10.0 (TID 373). 6713 bytes result sent to driver
[2025-07-03T18:02:09.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 129.0 in stage 10.0 (TID 374) (39b5ac792cf9, executor driver, partition 129, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.889+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 129.0 in stage 10.0 (TID 374)
[2025-07-03T18:02:09.889+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 128.0 in stage 10.0 (TID 373) in 2 ms on 39b5ac792cf9 (executor driver) (129/200)
[2025-07-03T18:02:09.889+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.892+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.893+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 129.0 in stage 10.0 (TID 374). 6713 bytes result sent to driver
[2025-07-03T18:02:09.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 130.0 in stage 10.0 (TID 375) (39b5ac792cf9, executor driver, partition 130, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 129.0 in stage 10.0 (TID 374) in 2 ms on 39b5ac792cf9 (executor driver) (130/200)
[2025-07-03T18:02:09.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 130.0 in stage 10.0 (TID 375)
[2025-07-03T18:02:09.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.7 KiB) non-empty blocks including 7 (7.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 130.0 in stage 10.0 (TID 375). 6713 bytes result sent to driver
[2025-07-03T18:02:09.899+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 131.0 in stage 10.0 (TID 376) (39b5ac792cf9, executor driver, partition 131, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.899+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 130.0 in stage 10.0 (TID 375) in 3 ms on 39b5ac792cf9 (executor driver) (131/200)
[2025-07-03T18:02:09.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 131.0 in stage 10.0 (TID 376)
[2025-07-03T18:02:09.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 131.0 in stage 10.0 (TID 376). 6713 bytes result sent to driver
[2025-07-03T18:02:09.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 132.0 in stage 10.0 (TID 377) (39b5ac792cf9, executor driver, partition 132, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.906+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 131.0 in stage 10.0 (TID 376) in 3 ms on 39b5ac792cf9 (executor driver) (132/200)
[2025-07-03T18:02:09.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 132.0 in stage 10.0 (TID 377)
[2025-07-03T18:02:09.909+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.7 KiB) non-empty blocks including 7 (7.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.910+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 132.0 in stage 10.0 (TID 377). 6756 bytes result sent to driver
[2025-07-03T18:02:09.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 133.0 in stage 10.0 (TID 378) (39b5ac792cf9, executor driver, partition 133, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 133.0 in stage 10.0 (TID 378)
[2025-07-03T18:02:09.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 132.0 in stage 10.0 (TID 377) in 4 ms on 39b5ac792cf9 (executor driver) (133/200)
[2025-07-03T18:02:09.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 133.0 in stage 10.0 (TID 378). 6756 bytes result sent to driver
[2025-07-03T18:02:09.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 134.0 in stage 10.0 (TID 379) (39b5ac792cf9, executor driver, partition 134, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 133.0 in stage 10.0 (TID 378) in 3 ms on 39b5ac792cf9 (executor driver) (134/200)
[2025-07-03T18:02:09.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 134.0 in stage 10.0 (TID 379)
[2025-07-03T18:02:09.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 134.0 in stage 10.0 (TID 379). 6713 bytes result sent to driver
[2025-07-03T18:02:09.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 135.0 in stage 10.0 (TID 380) (39b5ac792cf9, executor driver, partition 135, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 134.0 in stage 10.0 (TID 379) in 3 ms on 39b5ac792cf9 (executor driver) (135/200)
[2025-07-03T18:02:09.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 135.0 in stage 10.0 (TID 380)
[2025-07-03T18:02:09.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.6 KiB) non-empty blocks including 7 (7.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 135.0 in stage 10.0 (TID 380). 6713 bytes result sent to driver
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 136.0 in stage 10.0 (TID 381) (39b5ac792cf9, executor driver, partition 136, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 136.0 in stage 10.0 (TID 381)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 135.0 in stage 10.0 (TID 380) in 3 ms on 39b5ac792cf9 (executor driver) (136/200)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.5 KiB) non-empty blocks including 7 (8.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 136.0 in stage 10.0 (TID 381). 6713 bytes result sent to driver
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 137.0 in stage 10.0 (TID 382) (39b5ac792cf9, executor driver, partition 137, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 136.0 in stage 10.0 (TID 381) in 2 ms on 39b5ac792cf9 (executor driver) (137/200)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 137.0 in stage 10.0 (TID 382)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.5 KiB) non-empty blocks including 7 (8.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 137.0 in stage 10.0 (TID 382). 6713 bytes result sent to driver
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 138.0 in stage 10.0 (TID 383) (39b5ac792cf9, executor driver, partition 138, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 138.0 in stage 10.0 (TID 383)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 137.0 in stage 10.0 (TID 382) in 3 ms on 39b5ac792cf9 (executor driver) (138/200)
[2025-07-03T18:02:09.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 138.0 in stage 10.0 (TID 383). 6713 bytes result sent to driver
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 139.0 in stage 10.0 (TID 384) (39b5ac792cf9, executor driver, partition 139, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 139.0 in stage 10.0 (TID 384)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 138.0 in stage 10.0 (TID 383) in 3 ms on 39b5ac792cf9 (executor driver) (139/200)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 139.0 in stage 10.0 (TID 384). 6713 bytes result sent to driver
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 140.0 in stage 10.0 (TID 385) (39b5ac792cf9, executor driver, partition 140, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 139.0 in stage 10.0 (TID 384) in 2 ms on 39b5ac792cf9 (executor driver) (140/200)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 140.0 in stage 10.0 (TID 385)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 140.0 in stage 10.0 (TID 385). 6713 bytes result sent to driver
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 141.0 in stage 10.0 (TID 386) (39b5ac792cf9, executor driver, partition 141, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 140.0 in stage 10.0 (TID 385) in 3 ms on 39b5ac792cf9 (executor driver) (141/200)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 141.0 in stage 10.0 (TID 386)
[2025-07-03T18:02:09.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 141.0 in stage 10.0 (TID 386). 6756 bytes result sent to driver
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 142.0 in stage 10.0 (TID 387) (39b5ac792cf9, executor driver, partition 142, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 141.0 in stage 10.0 (TID 386) in 5 ms on 39b5ac792cf9 (executor driver) (142/200)
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 142.0 in stage 10.0 (TID 387)
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 142.0 in stage 10.0 (TID 387). 6713 bytes result sent to driver
[2025-07-03T18:02:09.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 143.0 in stage 10.0 (TID 388) (39b5ac792cf9, executor driver, partition 143, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 143.0 in stage 10.0 (TID 388)
[2025-07-03T18:02:09.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 142.0 in stage 10.0 (TID 387) in 3 ms on 39b5ac792cf9 (executor driver) (143/200)
[2025-07-03T18:02:09.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.925+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 143.0 in stage 10.0 (TID 388). 6713 bytes result sent to driver
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 144.0 in stage 10.0 (TID 389) (39b5ac792cf9, executor driver, partition 144, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 143.0 in stage 10.0 (TID 388) in 2 ms on 39b5ac792cf9 (executor driver) (144/200)
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 144.0 in stage 10.0 (TID 389)
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.7 KiB) non-empty blocks including 7 (7.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 144.0 in stage 10.0 (TID 389). 6756 bytes result sent to driver
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 145.0 in stage 10.0 (TID 390) (39b5ac792cf9, executor driver, partition 145, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 144.0 in stage 10.0 (TID 389) in 5 ms on 39b5ac792cf9 (executor driver) (145/200)
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 145.0 in stage 10.0 (TID 390)
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 145.0 in stage 10.0 (TID 390). 6713 bytes result sent to driver
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 146.0 in stage 10.0 (TID 391) (39b5ac792cf9, executor driver, partition 146, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 146.0 in stage 10.0 (TID 391)
[2025-07-03T18:02:09.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 145.0 in stage 10.0 (TID 390) in 2 ms on 39b5ac792cf9 (executor driver) (146/200)
[2025-07-03T18:02:09.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.3 KiB) non-empty blocks including 7 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 146.0 in stage 10.0 (TID 391). 6713 bytes result sent to driver
[2025-07-03T18:02:09.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 147.0 in stage 10.0 (TID 392) (39b5ac792cf9, executor driver, partition 147, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 147.0 in stage 10.0 (TID 392)
[2025-07-03T18:02:09.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 146.0 in stage 10.0 (TID 391) in 3 ms on 39b5ac792cf9 (executor driver) (147/200)
[2025-07-03T18:02:09.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.3 KiB) non-empty blocks including 7 (8.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 147.0 in stage 10.0 (TID 392). 6713 bytes result sent to driver
[2025-07-03T18:02:09.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 148.0 in stage 10.0 (TID 393) (39b5ac792cf9, executor driver, partition 148, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 148.0 in stage 10.0 (TID 393)
[2025-07-03T18:02:09.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 147.0 in stage 10.0 (TID 392) in 2 ms on 39b5ac792cf9 (executor driver) (148/200)
[2025-07-03T18:02:09.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.931+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 148.0 in stage 10.0 (TID 393). 6713 bytes result sent to driver
[2025-07-03T18:02:09.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 149.0 in stage 10.0 (TID 394) (39b5ac792cf9, executor driver, partition 149, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 148.0 in stage 10.0 (TID 393) in 2 ms on 39b5ac792cf9 (executor driver) (149/200)
[2025-07-03T18:02:09.932+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 149.0 in stage 10.0 (TID 394)
[2025-07-03T18:02:09.933+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.6 KiB) non-empty blocks including 7 (9.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.933+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.934+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 149.0 in stage 10.0 (TID 394). 6713 bytes result sent to driver
[2025-07-03T18:02:09.934+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 150.0 in stage 10.0 (TID 395) (39b5ac792cf9, executor driver, partition 150, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 150.0 in stage 10.0 (TID 395)
[2025-07-03T18:02:09.935+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 149.0 in stage 10.0 (TID 394) in 3 ms on 39b5ac792cf9 (executor driver) (150/200)
[2025-07-03T18:02:09.936+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.936+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 150.0 in stage 10.0 (TID 395). 6756 bytes result sent to driver
[2025-07-03T18:02:09.938+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 151.0 in stage 10.0 (TID 396) (39b5ac792cf9, executor driver, partition 151, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.941+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 151.0 in stage 10.0 (TID 396)
[2025-07-03T18:02:09.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 150.0 in stage 10.0 (TID 395) in 4 ms on 39b5ac792cf9 (executor driver) (151/200)
[2025-07-03T18:02:09.943+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.1 KiB) non-empty blocks including 7 (9.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 151.0 in stage 10.0 (TID 396). 6713 bytes result sent to driver
[2025-07-03T18:02:09.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 152.0 in stage 10.0 (TID 397) (39b5ac792cf9, executor driver, partition 152, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.947+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 152.0 in stage 10.0 (TID 397)
[2025-07-03T18:02:09.949+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 151.0 in stage 10.0 (TID 396) in 3 ms on 39b5ac792cf9 (executor driver) (152/200)
[2025-07-03T18:02:09.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.5 KiB) non-empty blocks including 7 (9.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 152.0 in stage 10.0 (TID 397). 6670 bytes result sent to driver
[2025-07-03T18:02:09.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 153.0 in stage 10.0 (TID 398) (39b5ac792cf9, executor driver, partition 153, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 153.0 in stage 10.0 (TID 398)
[2025-07-03T18:02:09.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 152.0 in stage 10.0 (TID 397) in 2 ms on 39b5ac792cf9 (executor driver) (153/200)
[2025-07-03T18:02:09.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.5 KiB) non-empty blocks including 7 (8.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 153.0 in stage 10.0 (TID 398). 6670 bytes result sent to driver
[2025-07-03T18:02:09.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 154.0 in stage 10.0 (TID 399) (39b5ac792cf9, executor driver, partition 154, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 154.0 in stage 10.0 (TID 399)
[2025-07-03T18:02:09.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 153.0 in stage 10.0 (TID 398) in 2 ms on 39b5ac792cf9 (executor driver) (154/200)
[2025-07-03T18:02:09.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 154.0 in stage 10.0 (TID 399). 6713 bytes result sent to driver
[2025-07-03T18:02:09.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 155.0 in stage 10.0 (TID 400) (39b5ac792cf9, executor driver, partition 155, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 154.0 in stage 10.0 (TID 399) in 2 ms on 39b5ac792cf9 (executor driver) (155/200)
[2025-07-03T18:02:09.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 155.0 in stage 10.0 (TID 400)
[2025-07-03T18:02:09.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 155.0 in stage 10.0 (TID 400). 6713 bytes result sent to driver
[2025-07-03T18:02:09.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 156.0 in stage 10.0 (TID 401) (39b5ac792cf9, executor driver, partition 156, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 156.0 in stage 10.0 (TID 401)
[2025-07-03T18:02:09.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 155.0 in stage 10.0 (TID 400) in 2 ms on 39b5ac792cf9 (executor driver) (156/200)
[2025-07-03T18:02:09.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.3 KiB) non-empty blocks including 7 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 156.0 in stage 10.0 (TID 401). 6713 bytes result sent to driver
[2025-07-03T18:02:09.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 157.0 in stage 10.0 (TID 402) (39b5ac792cf9, executor driver, partition 157, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 156.0 in stage 10.0 (TID 401) in 2 ms on 39b5ac792cf9 (executor driver) (157/200)
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 157.0 in stage 10.0 (TID 402)
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 157.0 in stage 10.0 (TID 402). 6670 bytes result sent to driver
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 158.0 in stage 10.0 (TID 403) (39b5ac792cf9, executor driver, partition 158, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 157.0 in stage 10.0 (TID 402) in 3 ms on 39b5ac792cf9 (executor driver) (158/200)
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 158.0 in stage 10.0 (TID 403)
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 158.0 in stage 10.0 (TID 403). 6713 bytes result sent to driver
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 159.0 in stage 10.0 (TID 404) (39b5ac792cf9, executor driver, partition 159, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 158.0 in stage 10.0 (TID 403) in 3 ms on 39b5ac792cf9 (executor driver) (159/200)
[2025-07-03T18:02:09.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 159.0 in stage 10.0 (TID 404)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.7 KiB) non-empty blocks including 7 (6.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 159.0 in stage 10.0 (TID 404). 6756 bytes result sent to driver
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 160.0 in stage 10.0 (TID 405) (39b5ac792cf9, executor driver, partition 160, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 159.0 in stage 10.0 (TID 404) in 4 ms on 39b5ac792cf9 (executor driver) (160/200)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 160.0 in stage 10.0 (TID 405)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.1 KiB) non-empty blocks including 7 (7.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 160.0 in stage 10.0 (TID 405). 6713 bytes result sent to driver
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 161.0 in stage 10.0 (TID 406) (39b5ac792cf9, executor driver, partition 161, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 161.0 in stage 10.0 (TID 406)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 160.0 in stage 10.0 (TID 405) in 3 ms on 39b5ac792cf9 (executor driver) (161/200)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.2 KiB) non-empty blocks including 7 (8.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 161.0 in stage 10.0 (TID 406). 6756 bytes result sent to driver
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 162.0 in stage 10.0 (TID 407) (39b5ac792cf9, executor driver, partition 162, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 161.0 in stage 10.0 (TID 406) in 3 ms on 39b5ac792cf9 (executor driver) (162/200)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 162.0 in stage 10.0 (TID 407)
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 162.0 in stage 10.0 (TID 407). 6713 bytes result sent to driver
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 163.0 in stage 10.0 (TID 408) (39b5ac792cf9, executor driver, partition 163, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 163.0 in stage 10.0 (TID 408)
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 162.0 in stage 10.0 (TID 407) in 3 ms on 39b5ac792cf9 (executor driver) (163/200)
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.0 KiB) non-empty blocks including 7 (7.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 163.0 in stage 10.0 (TID 408). 6713 bytes result sent to driver
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 164.0 in stage 10.0 (TID 409) (39b5ac792cf9, executor driver, partition 164, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 164.0 in stage 10.0 (TID 409)
[2025-07-03T18:02:09.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 163.0 in stage 10.0 (TID 408) in 2 ms on 39b5ac792cf9 (executor driver) (164/200)
[2025-07-03T18:02:09.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 164.0 in stage 10.0 (TID 409). 6713 bytes result sent to driver
[2025-07-03T18:02:09.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 165.0 in stage 10.0 (TID 410) (39b5ac792cf9, executor driver, partition 165, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 165.0 in stage 10.0 (TID 410)
[2025-07-03T18:02:09.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 164.0 in stage 10.0 (TID 409) in 2 ms on 39b5ac792cf9 (executor driver) (165/200)
[2025-07-03T18:02:09.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.4 KiB) non-empty blocks including 7 (9.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 165.0 in stage 10.0 (TID 410). 6713 bytes result sent to driver
[2025-07-03T18:02:09.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 166.0 in stage 10.0 (TID 411) (39b5ac792cf9, executor driver, partition 166, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 166.0 in stage 10.0 (TID 411)
[2025-07-03T18:02:09.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 165.0 in stage 10.0 (TID 410) in 2 ms on 39b5ac792cf9 (executor driver) (166/200)
[2025-07-03T18:02:09.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.7 KiB) non-empty blocks including 7 (6.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.977+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 166.0 in stage 10.0 (TID 411). 6670 bytes result sent to driver
[2025-07-03T18:02:09.977+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 167.0 in stage 10.0 (TID 412) (39b5ac792cf9, executor driver, partition 167, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.977+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 167.0 in stage 10.0 (TID 412)
[2025-07-03T18:02:09.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 166.0 in stage 10.0 (TID 411) in 2 ms on 39b5ac792cf9 (executor driver) (167/200)
[2025-07-03T18:02:09.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.2 KiB) non-empty blocks including 7 (6.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 167.0 in stage 10.0 (TID 412). 6713 bytes result sent to driver
[2025-07-03T18:02:09.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 168.0 in stage 10.0 (TID 413) (39b5ac792cf9, executor driver, partition 168, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 168.0 in stage 10.0 (TID 413)
[2025-07-03T18:02:09.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 167.0 in stage 10.0 (TID 412) in 3 ms on 39b5ac792cf9 (executor driver) (168/200)
[2025-07-03T18:02:09.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.6 KiB) non-empty blocks including 7 (7.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 168.0 in stage 10.0 (TID 413). 6756 bytes result sent to driver
[2025-07-03T18:02:09.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 169.0 in stage 10.0 (TID 414) (39b5ac792cf9, executor driver, partition 169, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 169.0 in stage 10.0 (TID 414)
[2025-07-03T18:02:09.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 168.0 in stage 10.0 (TID 413) in 5 ms on 39b5ac792cf9 (executor driver) (169/200)
[2025-07-03T18:02:09.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.4 KiB) non-empty blocks including 7 (6.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 169.0 in stage 10.0 (TID 414). 6713 bytes result sent to driver
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 170.0 in stage 10.0 (TID 415) (39b5ac792cf9, executor driver, partition 170, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 169.0 in stage 10.0 (TID 414) in 3 ms on 39b5ac792cf9 (executor driver) (170/200)
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 170.0 in stage 10.0 (TID 415)
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.2 KiB) non-empty blocks including 7 (6.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 170.0 in stage 10.0 (TID 415). 6713 bytes result sent to driver
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 171.0 in stage 10.0 (TID 416) (39b5ac792cf9, executor driver, partition 171, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 171.0 in stage 10.0 (TID 416)
[2025-07-03T18:02:09.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 170.0 in stage 10.0 (TID 415) in 2 ms on 39b5ac792cf9 (executor driver) (171/200)
[2025-07-03T18:02:09.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 171.0 in stage 10.0 (TID 416). 6756 bytes result sent to driver
[2025-07-03T18:02:09.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 172.0 in stage 10.0 (TID 417) (39b5ac792cf9, executor driver, partition 172, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:09.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 172.0 in stage 10.0 (TID 417)
[2025-07-03T18:02:09.994+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 171.0 in stage 10.0 (TID 416) in 3 ms on 39b5ac792cf9 (executor driver) (172/200)
[2025-07-03T18:02:09.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (9.9 KiB) non-empty blocks including 7 (9.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:09.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:09.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 172.0 in stage 10.0 (TID 417). 6713 bytes result sent to driver
[2025-07-03T18:02:09.998+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 173.0 in stage 10.0 (TID 418) (39b5ac792cf9, executor driver, partition 173, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 173.0 in stage 10.0 (TID 418)
[2025-07-03T18:02:10.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 172.0 in stage 10.0 (TID 417) in 3 ms on 39b5ac792cf9 (executor driver) (173/200)
[2025-07-03T18:02:10.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (6.9 KiB) non-empty blocks including 7 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 173.0 in stage 10.0 (TID 418). 6713 bytes result sent to driver
[2025-07-03T18:02:10.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 174.0 in stage 10.0 (TID 419) (39b5ac792cf9, executor driver, partition 174, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.003+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 174.0 in stage 10.0 (TID 419)
[2025-07-03T18:02:10.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 173.0 in stage 10.0 (TID 418) in 3 ms on 39b5ac792cf9 (executor driver) (174/200)
[2025-07-03T18:02:10.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (7.1 KiB) non-empty blocks including 7 (7.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Finished task 174.0 in stage 10.0 (TID 419). 6670 bytes result sent to driver
[2025-07-03T18:02:10.004+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Starting task 175.0 in stage 10.0 (TID 420) (39b5ac792cf9, executor driver, partition 175, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO Executor: Running task 175.0 in stage 10.0 (TID 420)
[2025-07-03T18:02:10.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO TaskSetManager: Finished task 174.0 in stage 10.0 (TID 419) in 2 ms on 39b5ac792cf9 (executor driver) (175/200)
[2025-07-03T18:02:10.005+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.006+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 175.0 in stage 10.0 (TID 420). 6670 bytes result sent to driver
[2025-07-03T18:02:10.007+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 176.0 in stage 10.0 (TID 421) (39b5ac792cf9, executor driver, partition 176, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 175.0 in stage 10.0 (TID 420) in 2 ms on 39b5ac792cf9 (executor driver) (176/200)
[2025-07-03T18:02:10.008+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 176.0 in stage 10.0 (TID 421)
[2025-07-03T18:02:10.011+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (6.1 KiB) non-empty blocks including 7 (6.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.013+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.013+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 176.0 in stage 10.0 (TID 421). 6713 bytes result sent to driver
[2025-07-03T18:02:10.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 177.0 in stage 10.0 (TID 422) (39b5ac792cf9, executor driver, partition 177, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 176.0 in stage 10.0 (TID 421) in 2 ms on 39b5ac792cf9 (executor driver) (177/200)
[2025-07-03T18:02:10.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 177.0 in stage 10.0 (TID 422)
[2025-07-03T18:02:10.015+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 177.0 in stage 10.0 (TID 422). 6756 bytes result sent to driver
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 178.0 in stage 10.0 (TID 423) (39b5ac792cf9, executor driver, partition 178, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 178.0 in stage 10.0 (TID 423)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 177.0 in stage 10.0 (TID 422) in 4 ms on 39b5ac792cf9 (executor driver) (178/200)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (6.0 KiB) non-empty blocks including 7 (6.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 178.0 in stage 10.0 (TID 423). 6713 bytes result sent to driver
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 179.0 in stage 10.0 (TID 424) (39b5ac792cf9, executor driver, partition 179, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 178.0 in stage 10.0 (TID 423) in 3 ms on 39b5ac792cf9 (executor driver) (179/200)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 179.0 in stage 10.0 (TID 424)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (6.6 KiB) non-empty blocks including 7 (6.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 179.0 in stage 10.0 (TID 424). 6713 bytes result sent to driver
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 180.0 in stage 10.0 (TID 425) (39b5ac792cf9, executor driver, partition 180, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 179.0 in stage 10.0 (TID 424) in 3 ms on 39b5ac792cf9 (executor driver) (180/200)
[2025-07-03T18:02:10.016+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 180.0 in stage 10.0 (TID 425)
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (6.8 KiB) non-empty blocks including 7 (6.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 180.0 in stage 10.0 (TID 425). 6713 bytes result sent to driver
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 181.0 in stage 10.0 (TID 426) (39b5ac792cf9, executor driver, partition 181, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 180.0 in stage 10.0 (TID 425) in 2 ms on 39b5ac792cf9 (executor driver) (181/200)
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 181.0 in stage 10.0 (TID 426)
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 181.0 in stage 10.0 (TID 426). 6713 bytes result sent to driver
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 182.0 in stage 10.0 (TID 427) (39b5ac792cf9, executor driver, partition 182, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 181.0 in stage 10.0 (TID 426) in 2 ms on 39b5ac792cf9 (executor driver) (182/200)
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 182.0 in stage 10.0 (TID 427)
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.6 KiB) non-empty blocks including 7 (7.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 182.0 in stage 10.0 (TID 427). 6713 bytes result sent to driver
[2025-07-03T18:02:10.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 183.0 in stage 10.0 (TID 428) (39b5ac792cf9, executor driver, partition 183, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 183.0 in stage 10.0 (TID 428)
[2025-07-03T18:02:10.018+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 182.0 in stage 10.0 (TID 427) in 3 ms on 39b5ac792cf9 (executor driver) (183/200)
[2025-07-03T18:02:10.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (6.6 KiB) non-empty blocks including 7 (6.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.019+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 183.0 in stage 10.0 (TID 428). 6713 bytes result sent to driver
[2025-07-03T18:02:10.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 184.0 in stage 10.0 (TID 429) (39b5ac792cf9, executor driver, partition 184, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 184.0 in stage 10.0 (TID 429)
[2025-07-03T18:02:10.021+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 183.0 in stage 10.0 (TID 428) in 2 ms on 39b5ac792cf9 (executor driver) (184/200)
[2025-07-03T18:02:10.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 184.0 in stage 10.0 (TID 429). 6713 bytes result sent to driver
[2025-07-03T18:02:10.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 185.0 in stage 10.0 (TID 430) (39b5ac792cf9, executor driver, partition 185, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 185.0 in stage 10.0 (TID 430)
[2025-07-03T18:02:10.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 184.0 in stage 10.0 (TID 429) in 3 ms on 39b5ac792cf9 (executor driver) (185/200)
[2025-07-03T18:02:10.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (9.0 KiB) non-empty blocks including 7 (9.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 185.0 in stage 10.0 (TID 430). 6713 bytes result sent to driver
[2025-07-03T18:02:10.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 186.0 in stage 10.0 (TID 431) (39b5ac792cf9, executor driver, partition 186, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 186.0 in stage 10.0 (TID 431)
[2025-07-03T18:02:10.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 185.0 in stage 10.0 (TID 430) in 2 ms on 39b5ac792cf9 (executor driver) (186/200)
[2025-07-03T18:02:10.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.7 KiB) non-empty blocks including 7 (8.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.029+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 186.0 in stage 10.0 (TID 431). 6756 bytes result sent to driver
[2025-07-03T18:02:10.029+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 187.0 in stage 10.0 (TID 432) (39b5ac792cf9, executor driver, partition 187, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 186.0 in stage 10.0 (TID 431) in 4 ms on 39b5ac792cf9 (executor driver) (187/200)
[2025-07-03T18:02:10.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 187.0 in stage 10.0 (TID 432)
[2025-07-03T18:02:10.033+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.2 KiB) non-empty blocks including 7 (7.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 187.0 in stage 10.0 (TID 432). 6713 bytes result sent to driver
[2025-07-03T18:02:10.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 188.0 in stage 10.0 (TID 433) (39b5ac792cf9, executor driver, partition 188, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.036+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 188.0 in stage 10.0 (TID 433)
[2025-07-03T18:02:10.036+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 187.0 in stage 10.0 (TID 432) in 2 ms on 39b5ac792cf9 (executor driver) (188/200)
[2025-07-03T18:02:10.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.6 KiB) non-empty blocks including 7 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 188.0 in stage 10.0 (TID 433). 6713 bytes result sent to driver
[2025-07-03T18:02:10.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 189.0 in stage 10.0 (TID 434) (39b5ac792cf9, executor driver, partition 189, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 188.0 in stage 10.0 (TID 433) in 3 ms on 39b5ac792cf9 (executor driver) (189/200)
[2025-07-03T18:02:10.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 189.0 in stage 10.0 (TID 434)
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 189.0 in stage 10.0 (TID 434). 6713 bytes result sent to driver
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 190.0 in stage 10.0 (TID 435) (39b5ac792cf9, executor driver, partition 190, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 190.0 in stage 10.0 (TID 435)
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 189.0 in stage 10.0 (TID 434) in 2 ms on 39b5ac792cf9 (executor driver) (190/200)
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.1 KiB) non-empty blocks including 7 (8.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 190.0 in stage 10.0 (TID 435). 6670 bytes result sent to driver
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 191.0 in stage 10.0 (TID 436) (39b5ac792cf9, executor driver, partition 191, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 191.0 in stage 10.0 (TID 436)
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 190.0 in stage 10.0 (TID 435) in 2 ms on 39b5ac792cf9 (executor driver) (191/200)
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.9 KiB) non-empty blocks including 7 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 191.0 in stage 10.0 (TID 436). 6713 bytes result sent to driver
[2025-07-03T18:02:10.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 192.0 in stage 10.0 (TID 437) (39b5ac792cf9, executor driver, partition 192, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 192.0 in stage 10.0 (TID 437)
[2025-07-03T18:02:10.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 191.0 in stage 10.0 (TID 436) in 2 ms on 39b5ac792cf9 (executor driver) (192/200)
[2025-07-03T18:02:10.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.3 KiB) non-empty blocks including 7 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 192.0 in stage 10.0 (TID 437). 6713 bytes result sent to driver
[2025-07-03T18:02:10.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 193.0 in stage 10.0 (TID 438) (39b5ac792cf9, executor driver, partition 193, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 192.0 in stage 10.0 (TID 437) in 2 ms on 39b5ac792cf9 (executor driver) (193/200)
[2025-07-03T18:02:10.045+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 193.0 in stage 10.0 (TID 438)
[2025-07-03T18:02:10.046+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.046+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 193.0 in stage 10.0 (TID 438). 6670 bytes result sent to driver
[2025-07-03T18:02:10.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 194.0 in stage 10.0 (TID 439) (39b5ac792cf9, executor driver, partition 194, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 194.0 in stage 10.0 (TID 439)
[2025-07-03T18:02:10.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 193.0 in stage 10.0 (TID 438) in 2 ms on 39b5ac792cf9 (executor driver) (194/200)
[2025-07-03T18:02:10.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.8 KiB) non-empty blocks including 7 (7.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.047+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 194.0 in stage 10.0 (TID 439). 6713 bytes result sent to driver
[2025-07-03T18:02:10.049+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 195.0 in stage 10.0 (TID 440) (39b5ac792cf9, executor driver, partition 195, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.050+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 195.0 in stage 10.0 (TID 440)
[2025-07-03T18:02:10.050+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 194.0 in stage 10.0 (TID 439) in 5 ms on 39b5ac792cf9 (executor driver) (195/200)
[2025-07-03T18:02:10.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.0 KiB) non-empty blocks including 7 (8.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.051+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 195.0 in stage 10.0 (TID 440). 6756 bytes result sent to driver
[2025-07-03T18:02:10.053+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 196.0 in stage 10.0 (TID 441) (39b5ac792cf9, executor driver, partition 196, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 196.0 in stage 10.0 (TID 441)
[2025-07-03T18:02:10.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 195.0 in stage 10.0 (TID 440) in 6 ms on 39b5ac792cf9 (executor driver) (196/200)
[2025-07-03T18:02:10.057+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.058+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 196.0 in stage 10.0 (TID 441). 6713 bytes result sent to driver
[2025-07-03T18:02:10.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 197.0 in stage 10.0 (TID 442) (39b5ac792cf9, executor driver, partition 197, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.060+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 196.0 in stage 10.0 (TID 441) in 3 ms on 39b5ac792cf9 (executor driver) (197/200)
[2025-07-03T18:02:10.061+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 197.0 in stage 10.0 (TID 442)
[2025-07-03T18:02:10.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (6.9 KiB) non-empty blocks including 7 (6.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 197.0 in stage 10.0 (TID 442). 6670 bytes result sent to driver
[2025-07-03T18:02:10.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 198.0 in stage 10.0 (TID 443) (39b5ac792cf9, executor driver, partition 198, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 198.0 in stage 10.0 (TID 443)
[2025-07-03T18:02:10.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 197.0 in stage 10.0 (TID 442) in 2 ms on 39b5ac792cf9 (executor driver) (198/200)
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (8.4 KiB) non-empty blocks including 7 (8.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 198.0 in stage 10.0 (TID 443). 6713 bytes result sent to driver
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 199.0 in stage 10.0 (TID 444) (39b5ac792cf9, executor driver, partition 199, NODE_LOCAL, 8988 bytes)
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 198.0 in stage 10.0 (TID 443) in 2 ms on 39b5ac792cf9 (executor driver) (199/200)
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 199.0 in stage 10.0 (TID 444)
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 7 (7.5 KiB) non-empty blocks including 7 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 199.0 in stage 10.0 (TID 444). 6713 bytes result sent to driver
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 199.0 in stage 10.0 (TID 444) in 3 ms on 39b5ac792cf9 (executor driver) (200/200)
[2025-07-03T18:02:10.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.684 s
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: looking for newly runnable stages
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: running: Set()
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: waiting: Set(ResultStage 11)
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: failed: Set()
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[39] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 12.5 KiB, free 338.8 MiB)
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 338.8 MiB)
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 39b5ac792cf9:37901 (size: 5.9 KiB, free: 419.6 MiB)
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-03T18:02:10.065+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-07-03T18:02:10.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 445) (39b5ac792cf9, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:10.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 0.0 in stage 11.0 (TID 445)
[2025-07-03T18:02:10.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Getting 200 (11.7 KiB) non-empty blocks including 200 (11.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:10.066+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:10.070+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO CodeGenerator: Code generated in 2.582708 ms
[2025-07-03T18:02:10.084+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 0.0 in stage 11.0 (TID 445). 3952 bytes result sent to driver
[2025-07-03T18:02:10.084+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 445) in 19 ms on 39b5ac792cf9 (executor driver) (1/1)
[2025-07-03T18:02:10.084+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-07-03T18:02:10.084+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.021 s
[2025-07-03T18:02:10.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:02:10.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2025-07-03T18:02:10.085+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 1.553588 s
[2025-07-03T18:02:10.087+0000] {spark_submit.py:579} INFO - Result records: 12666
[2025-07-03T18:02:10.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:02:10.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#0)
[2025-07-03T18:02:10.132+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(athlete_id)
[2025-07-03T18:02:10.133+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(athlete_id#27)
[2025-07-03T18:02:10.150+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-07-03T18:02:10.153+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 201.5 KiB, free 338.6 MiB)
[2025-07-03T18:02:10.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 338.6 MiB)
[2025-07-03T18:02:10.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 39b5ac792cf9:37901 (size: 35.1 KiB, free: 419.6 MiB)
[2025-07-03T18:02:10.156+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Created broadcast 21 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:02:10.157+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:02:10.159+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO CodeGenerator: Code generated in 6.366292 ms
[2025-07-03T18:02:10.161+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:02:10.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Got job 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 7 output partitions
[2025-07-03T18:02:10.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-03T18:02:10.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Parents of final stage: List()
[2025-07-03T18:02:10.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Missing parents: List()
[2025-07-03T18:02:10.162+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[43] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-03T18:02:10.163+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 15.6 KiB, free 338.5 MiB)
[2025-07-03T18:02:10.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 338.5 MiB)
[2025-07-03T18:02:10.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 39b5ac792cf9:37901 (size: 6.6 KiB, free: 419.6 MiB)
[2025-07-03T18:02:10.165+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:10.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 12 (MapPartitionsRDD[43] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:02:10.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Adding task set 12.0 with 7 tasks resource profile 0
[2025-07-03T18:02:10.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 39b5ac792cf9:37901 in memory (size: 5.9 KiB, free: 419.6 MiB)
[2025-07-03T18:02:10.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 446) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:10.166+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 0.0 in stage 12.0 (TID 446)
[2025-07-03T18:02:10.167+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00130-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57587, partition values: [empty row]
[2025-07-03T18:02:10.169+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.170+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00029-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-57404, partition values: [empty row]
[2025-07-03T18:02:10.170+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.171+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00025-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56716, partition values: [empty row]
[2025-07-03T18:02:10.172+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.172+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00094-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56382, partition values: [empty row]
[2025-07-03T18:02:10.173+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.173+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00051-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56298, partition values: [empty row]
[2025-07-03T18:02:10.174+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.175+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00076-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56236, partition values: [empty row]
[2025-07-03T18:02:10.175+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00193-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56152, partition values: [empty row]
[2025-07-03T18:02:10.176+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00159-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56131, partition values: [empty row]
[2025-07-03T18:02:10.177+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.178+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00040-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-56041, partition values: [empty row]
[2025-07-03T18:02:10.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.179+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00172-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55935, partition values: [empty row]
[2025-07-03T18:02:10.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.180+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00101-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55751, partition values: [empty row]
[2025-07-03T18:02:10.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.181+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00103-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55611, partition values: [empty row]
[2025-07-03T18:02:10.182+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.182+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00189-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55606, partition values: [empty row]
[2025-07-03T18:02:10.183+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00127-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55599, partition values: [empty row]
[2025-07-03T18:02:10.184+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00063-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55563, partition values: [empty row]
[2025-07-03T18:02:10.185+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.186+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00095-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55516, partition values: [empty row]
[2025-07-03T18:02:10.187+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.187+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00173-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55432, partition values: [empty row]
[2025-07-03T18:02:10.188+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.188+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00188-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55276, partition values: [empty row]
[2025-07-03T18:02:10.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.189+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00125-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55207, partition values: [empty row]
[2025-07-03T18:02:10.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.190+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00154-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55088, partition values: [empty row]
[2025-07-03T18:02:10.191+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.191+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00010-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55072, partition values: [empty row]
[2025-07-03T18:02:10.192+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.192+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00005-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55055, partition values: [empty row]
[2025-07-03T18:02:10.193+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.194+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00000-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55054, partition values: [empty row]
[2025-07-03T18:02:10.194+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00098-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-55020, partition values: [empty row]
[2025-07-03T18:02:10.195+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00168-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54965, partition values: [empty row]
[2025-07-03T18:02:10.196+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00074-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54962, partition values: [empty row]
[2025-07-03T18:02:10.197+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00108-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54960, partition values: [empty row]
[2025-07-03T18:02:10.198+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.199+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00004-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54956, partition values: [empty row]
[2025-07-03T18:02:10.199+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00139-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54954, partition values: [empty row]
[2025-07-03T18:02:10.200+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.201+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00182-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54952, partition values: [empty row]
[2025-07-03T18:02:10.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.202+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00122-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54947, partition values: [empty row]
[2025-07-03T18:02:10.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.203+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00018-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54918, partition values: [empty row]
[2025-07-03T18:02:10.204+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 0.0 in stage 12.0 (TID 446). 742727 bytes result sent to driver
[2025-07-03T18:02:10.205+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 447) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:10.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 1.0 in stage 12.0 (TID 447)
[2025-07-03T18:02:10.206+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 446) in 40 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:02:10.207+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00057-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54867, partition values: [empty row]
[2025-07-03T18:02:10.207+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.208+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00023-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54835, partition values: [empty row]
[2025-07-03T18:02:10.209+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.209+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00143-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54795, partition values: [empty row]
[2025-07-03T18:02:10.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.210+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00158-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54737, partition values: [empty row]
[2025-07-03T18:02:10.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.211+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00116-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54723, partition values: [empty row]
[2025-07-03T18:02:10.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.212+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00042-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54716, partition values: [empty row]
[2025-07-03T18:02:10.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.213+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00083-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:02:10.214+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00119-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54679, partition values: [empty row]
[2025-07-03T18:02:10.215+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00141-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54669, partition values: [empty row]
[2025-07-03T18:02:10.216+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00186-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54659, partition values: [empty row]
[2025-07-03T18:02:10.217+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.218+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00045-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54586, partition values: [empty row]
[2025-07-03T18:02:10.218+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.219+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00155-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54571, partition values: [empty row]
[2025-07-03T18:02:10.220+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.220+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00162-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54563, partition values: [empty row]
[2025-07-03T18:02:10.221+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.221+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00144-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54516, partition values: [empty row]
[2025-07-03T18:02:10.222+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.222+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00087-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54501, partition values: [empty row]
[2025-07-03T18:02:10.223+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.223+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00009-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54492, partition values: [empty row]
[2025-07-03T18:02:10.224+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00100-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54461, partition values: [empty row]
[2025-07-03T18:02:10.225+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00032-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54441, partition values: [empty row]
[2025-07-03T18:02:10.226+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.227+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00176-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54386, partition values: [empty row]
[2025-07-03T18:02:10.228+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.228+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00003-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54385, partition values: [empty row]
[2025-07-03T18:02:10.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.229+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00058-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54354, partition values: [empty row]
[2025-07-03T18:02:10.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.230+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00111-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54349, partition values: [empty row]
[2025-07-03T18:02:10.231+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00147-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54288, partition values: [empty row]
[2025-07-03T18:02:10.232+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00091-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54283, partition values: [empty row]
[2025-07-03T18:02:10.233+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.234+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00107-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54279, partition values: [empty row]
[2025-07-03T18:02:10.234+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.235+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00024-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54230, partition values: [empty row]
[2025-07-03T18:02:10.236+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.236+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00038-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54190, partition values: [empty row]
[2025-07-03T18:02:10.237+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.237+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00191-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54144, partition values: [empty row]
[2025-07-03T18:02:10.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.238+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00120-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54132, partition values: [empty row]
[2025-07-03T18:02:10.239+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00194-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54131, partition values: [empty row]
[2025-07-03T18:02:10.240+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00035-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54124, partition values: [empty row]
[2025-07-03T18:02:10.241+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.242+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00110-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54080, partition values: [empty row]
[2025-07-03T18:02:10.242+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.243+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 1.0 in stage 12.0 (TID 447). 722273 bytes result sent to driver
[2025-07-03T18:02:10.243+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 448) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:10.244+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 2.0 in stage 12.0 (TID 448)
[2025-07-03T18:02:10.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 447) in 39 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:02:10.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00021-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54070, partition values: [empty row]
[2025-07-03T18:02:10.245+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.246+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00114-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54048, partition values: [empty row]
[2025-07-03T18:02:10.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.247+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00150-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54032, partition values: [empty row]
[2025-07-03T18:02:10.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.248+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00169-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54022, partition values: [empty row]
[2025-07-03T18:02:10.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.249+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00082-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-54019, partition values: [empty row]
[2025-07-03T18:02:10.250+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00043-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53970, partition values: [empty row]
[2025-07-03T18:02:10.251+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00015-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53950, partition values: [empty row]
[2025-07-03T18:02:10.252+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.253+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00164-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53947, partition values: [empty row]
[2025-07-03T18:02:10.253+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.254+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00152-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53936, partition values: [empty row]
[2025-07-03T18:02:10.254+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.255+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00197-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53935, partition values: [empty row]
[2025-07-03T18:02:10.256+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.256+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00160-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53924, partition values: [empty row]
[2025-07-03T18:02:10.257+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.257+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00002-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53904, partition values: [empty row]
[2025-07-03T18:02:10.258+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00165-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53870, partition values: [empty row]
[2025-07-03T18:02:10.259+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.260+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00078-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53867, partition values: [empty row]
[2025-07-03T18:02:10.261+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.261+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00145-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53865, partition values: [empty row]
[2025-07-03T18:02:10.262+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.263+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00153-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53863, partition values: [empty row]
[2025-07-03T18:02:10.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.264+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00047-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53839, partition values: [empty row]
[2025-07-03T18:02:10.265+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.266+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00077-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53831, partition values: [empty row]
[2025-07-03T18:02:10.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.267+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00131-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53770, partition values: [empty row]
[2025-07-03T18:02:10.268+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.269+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00028-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:02:10.270+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.270+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00022-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53761, partition values: [empty row]
[2025-07-03T18:02:10.271+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.272+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00126-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53726, partition values: [empty row]
[2025-07-03T18:02:10.272+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00148-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53681, partition values: [empty row]
[2025-07-03T18:02:10.273+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.274+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00179-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53662, partition values: [empty row]
[2025-07-03T18:02:10.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.275+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00034-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53650, partition values: [empty row]
[2025-07-03T18:02:10.276+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00171-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53632, partition values: [empty row]
[2025-07-03T18:02:10.277+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.278+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00137-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53624, partition values: [empty row]
[2025-07-03T18:02:10.279+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.279+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00086-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53620, partition values: [empty row]
[2025-07-03T18:02:10.280+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00014-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53616, partition values: [empty row]
[2025-07-03T18:02:10.281+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.282+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00073-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53614, partition values: [empty row]
[2025-07-03T18:02:10.283+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00105-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53604, partition values: [empty row]
[2025-07-03T18:02:10.284+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.285+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00199-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53602, partition values: [empty row]
[2025-07-03T18:02:10.286+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.287+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 2.0 in stage 12.0 (TID 448). 713806 bytes result sent to driver
[2025-07-03T18:02:10.289+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 449) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:10.289+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 3.0 in stage 12.0 (TID 449)
[2025-07-03T18:02:10.289+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 448) in 46 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:02:10.290+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00044-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53598, partition values: [empty row]
[2025-07-03T18:02:10.291+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.292+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00146-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53596, partition values: [empty row]
[2025-07-03T18:02:10.292+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.293+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00016-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53586, partition values: [empty row]
[2025-07-03T18:02:10.293+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00070-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53575, partition values: [empty row]
[2025-07-03T18:02:10.294+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.295+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00037-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53559, partition values: [empty row]
[2025-07-03T18:02:10.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.296+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00001-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53526, partition values: [empty row]
[2025-07-03T18:02:10.297+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.297+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00080-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53515, partition values: [empty row]
[2025-07-03T18:02:10.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.298+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00056-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53508, partition values: [empty row]
[2025-07-03T18:02:10.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.299+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00117-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53501, partition values: [empty row]
[2025-07-03T18:02:10.300+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.300+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00187-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53499, partition values: [empty row]
[2025-07-03T18:02:10.301+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.302+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00007-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53477, partition values: [empty row]
[2025-07-03T18:02:10.302+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00006-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53475, partition values: [empty row]
[2025-07-03T18:02:10.303+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00039-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53453, partition values: [empty row]
[2025-07-03T18:02:10.304+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.305+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00174-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53442, partition values: [empty row]
[2025-07-03T18:02:10.307+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.307+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00113-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53440, partition values: [empty row]
[2025-07-03T18:02:10.309+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.309+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00106-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53430, partition values: [empty row]
[2025-07-03T18:02:10.310+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.311+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00163-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53416, partition values: [empty row]
[2025-07-03T18:02:10.311+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.312+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00121-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53400, partition values: [empty row]
[2025-07-03T18:02:10.314+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.314+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00177-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53349, partition values: [empty row]
[2025-07-03T18:02:10.315+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.315+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00128-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53335, partition values: [empty row]
[2025-07-03T18:02:10.317+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.318+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00118-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53325, partition values: [empty row]
[2025-07-03T18:02:10.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.319+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00132-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53320, partition values: [empty row]
[2025-07-03T18:02:10.320+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.321+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00140-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53318, partition values: [empty row]
[2025-07-03T18:02:10.321+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.322+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00135-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53317, partition values: [empty row]
[2025-07-03T18:02:10.322+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.323+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00124-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53308, partition values: [empty row]
[2025-07-03T18:02:10.324+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.324+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00096-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53302, partition values: [empty row]
[2025-07-03T18:02:10.325+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.325+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00183-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53295, partition values: [empty row]
[2025-07-03T18:02:10.326+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.326+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00134-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53289, partition values: [empty row]
[2025-07-03T18:02:10.327+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.327+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00151-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53288, partition values: [empty row]
[2025-07-03T18:02:10.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.328+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00067-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53279, partition values: [empty row]
[2025-07-03T18:02:10.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.329+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00053-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53278, partition values: [empty row]
[2025-07-03T18:02:10.330+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.331+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00129-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:02:10.331+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.332+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 3.0 in stage 12.0 (TID 449). 709074 bytes result sent to driver
[2025-07-03T18:02:10.333+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 4.0 in stage 12.0 (TID 450) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:10.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 4.0 in stage 12.0 (TID 450)
[2025-07-03T18:02:10.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 449) in 44 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:02:10.334+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00019-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53275, partition values: [empty row]
[2025-07-03T18:02:10.335+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00198-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53274, partition values: [empty row]
[2025-07-03T18:02:10.336+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.337+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00046-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53272, partition values: [empty row]
[2025-07-03T18:02:10.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.338+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00065-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53261, partition values: [empty row]
[2025-07-03T18:02:10.339+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.340+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00052-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53240, partition values: [empty row]
[2025-07-03T18:02:10.340+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.341+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00190-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:02:10.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.342+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00196-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53218, partition values: [empty row]
[2025-07-03T18:02:10.343+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.343+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00157-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53211, partition values: [empty row]
[2025-07-03T18:02:10.344+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00048-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:02:10.345+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.346+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00185-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53191, partition values: [empty row]
[2025-07-03T18:02:10.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.347+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00020-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53155, partition values: [empty row]
[2025-07-03T18:02:10.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.348+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00180-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53145, partition values: [empty row]
[2025-07-03T18:02:10.349+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00178-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53134, partition values: [empty row]
[2025-07-03T18:02:10.350+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.351+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00104-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53119, partition values: [empty row]
[2025-07-03T18:02:10.351+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.352+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00138-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53103, partition values: [empty row]
[2025-07-03T18:02:10.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.353+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00085-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53097, partition values: [empty row]
[2025-07-03T18:02:10.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.354+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00112-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53073, partition values: [empty row]
[2025-07-03T18:02:10.355+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.356+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00181-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53071, partition values: [empty row]
[2025-07-03T18:02:10.356+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.357+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00075-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53065, partition values: [empty row]
[2025-07-03T18:02:10.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.358+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00149-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53062, partition values: [empty row]
[2025-07-03T18:02:10.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.359+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00012-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53049, partition values: [empty row]
[2025-07-03T18:02:10.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.360+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00090-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-53047, partition values: [empty row]
[2025-07-03T18:02:10.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.361+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00068-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52969, partition values: [empty row]
[2025-07-03T18:02:10.362+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.362+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00054-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52925, partition values: [empty row]
[2025-07-03T18:02:10.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.363+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00195-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52882, partition values: [empty row]
[2025-07-03T18:02:10.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.364+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00049-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52845, partition values: [empty row]
[2025-07-03T18:02:10.365+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.366+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00092-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52842, partition values: [empty row]
[2025-07-03T18:02:10.366+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.367+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00102-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52835, partition values: [empty row]
[2025-07-03T18:02:10.367+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00081-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52833, partition values: [empty row]
[2025-07-03T18:02:10.368+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.369+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00072-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:02:10.369+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00142-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52827, partition values: [empty row]
[2025-07-03T18:02:10.370+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.371+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00036-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52790, partition values: [empty row]
[2025-07-03T18:02:10.372+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 4.0 in stage 12.0 (TID 450). 702781 bytes result sent to driver
[2025-07-03T18:02:10.373+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 5.0 in stage 12.0 (TID 451) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 15009 bytes)
[2025-07-03T18:02:10.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 5.0 in stage 12.0 (TID 451)
[2025-07-03T18:02:10.374+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 4.0 in stage 12.0 (TID 450) in 42 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:02:10.375+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00109-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52784, partition values: [empty row]
[2025-07-03T18:02:10.375+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.376+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00084-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52779, partition values: [empty row]
[2025-07-03T18:02:10.376+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.377+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00030-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52777, partition values: [empty row]
[2025-07-03T18:02:10.377+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.378+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00156-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52761, partition values: [empty row]
[2025-07-03T18:02:10.379+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.379+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00133-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52743, partition values: [empty row]
[2025-07-03T18:02:10.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.380+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00123-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52718, partition values: [empty row]
[2025-07-03T18:02:10.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.381+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00184-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52713, partition values: [empty row]
[2025-07-03T18:02:10.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.382+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00088-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52688, partition values: [empty row]
[2025-07-03T18:02:10.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.383+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00136-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52677, partition values: [empty row]
[2025-07-03T18:02:10.384+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.384+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00033-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52557, partition values: [empty row]
[2025-07-03T18:02:10.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.385+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00167-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52551, partition values: [empty row]
[2025-07-03T18:02:10.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.386+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00060-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52533, partition values: [empty row]
[2025-07-03T18:02:10.387+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.387+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00192-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52518, partition values: [empty row]
[2025-07-03T18:02:10.388+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.388+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00055-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52503, partition values: [empty row]
[2025-07-03T18:02:10.389+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00027-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52497, partition values: [empty row]
[2025-07-03T18:02:10.390+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.391+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00066-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52492, partition values: [empty row]
[2025-07-03T18:02:10.391+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.392+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00097-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52439, partition values: [empty row]
[2025-07-03T18:02:10.392+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.393+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00166-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52417, partition values: [empty row]
[2025-07-03T18:02:10.393+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00050-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52366, partition values: [empty row]
[2025-07-03T18:02:10.394+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.395+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00071-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52346, partition values: [empty row]
[2025-07-03T18:02:10.396+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.396+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00008-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52121, partition values: [empty row]
[2025-07-03T18:02:10.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.397+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00061-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52118, partition values: [empty row]
[2025-07-03T18:02:10.398+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.398+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00115-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-52045, partition values: [empty row]
[2025-07-03T18:02:10.399+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.399+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00041-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51912, partition values: [empty row]
[2025-07-03T18:02:10.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.400+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00089-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51902, partition values: [empty row]
[2025-07-03T18:02:10.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.401+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00026-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51833, partition values: [empty row]
[2025-07-03T18:02:10.402+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.402+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00062-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51819, partition values: [empty row]
[2025-07-03T18:02:10.403+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.403+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00031-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51818, partition values: [empty row]
[2025-07-03T18:02:10.404+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.404+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00017-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51773, partition values: [empty row]
[2025-07-03T18:02:10.405+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.405+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00175-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51738, partition values: [empty row]
[2025-07-03T18:02:10.406+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.407+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00093-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51630, partition values: [empty row]
[2025-07-03T18:02:10.407+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.407+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00099-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51626, partition values: [empty row]
[2025-07-03T18:02:10.408+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.409+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 5.0 in stage 12.0 (TID 451). 693328 bytes result sent to driver
[2025-07-03T18:02:10.411+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 6.0 in stage 12.0 (TID 452) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 10881 bytes)
[2025-07-03T18:02:10.412+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 6.0 in stage 12.0 (TID 452)
[2025-07-03T18:02:10.412+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 5.0 in stage 12.0 (TID 451) in 38 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:02:10.413+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00011-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51506, partition values: [empty row]
[2025-07-03T18:02:10.413+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.414+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00170-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51479, partition values: [empty row]
[2025-07-03T18:02:10.414+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.415+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00013-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51405, partition values: [empty row]
[2025-07-03T18:02:10.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.416+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00059-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51381, partition values: [empty row]
[2025-07-03T18:02:10.417+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.417+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00064-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51360, partition values: [empty row]
[2025-07-03T18:02:10.418+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.418+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00161-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51349, partition values: [empty row]
[2025-07-03T18:02:10.419+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.419+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00069-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-51017, partition values: [empty row]
[2025-07-03T18:02:10.420+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.420+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_event_results/part-00079-668a3f30-90ed-4d29-bcba-6739494a3bd4-c000.snappy.parquet, range: 0-50801, partition values: [empty row]
[2025-07-03T18:02:10.421+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 6.0 in stage 12.0 (TID 452). 171090 bytes result sent to driver
[2025-07-03T18:02:10.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 6.0 in stage 12.0 (TID 452) in 11 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:02:10.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-07-03T18:02:10.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.260 s
[2025-07-03T18:02:10.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:02:10.422+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
[2025-07-03T18:02:10.423+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Job 8 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.261178 s
[2025-07-03T18:02:10.434+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 39b5ac792cf9:37901 in memory (size: 6.6 KiB, free: 419.6 MiB)
[2025-07-03T18:02:10.463+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 40.0 MiB, free 298.6 MiB)
[2025-07-03T18:02:10.490+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 39b5ac792cf9:37901 in memory (size: 35.2 KiB, free: 419.6 MiB)
[2025-07-03T18:02:10.493+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 39b5ac792cf9:37901 in memory (size: 35.1 KiB, free: 419.7 MiB)
[2025-07-03T18:02:10.498+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 39b5ac792cf9:37901 in memory (size: 4.0 MiB, free: 423.7 MiB)
[2025-07-03T18:02:10.499+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_10_piece1 on 39b5ac792cf9:37901 in memory (size: 3.3 MiB, free: 427.0 MiB)
[2025-07-03T18:02:10.500+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 39b5ac792cf9:37901 in memory (size: 35.1 KiB, free: 427.0 MiB)
[2025-07-03T18:02:10.502+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 39b5ac792cf9:37901 in memory (size: 4.0 MiB, free: 431.0 MiB)
[2025-07-03T18:02:10.503+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_16_piece1 on 39b5ac792cf9:37901 in memory (size: 3.3 MiB, free: 434.3 MiB)
[2025-07-03T18:02:10.504+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 389.9 MiB)
[2025-07-03T18:02:10.504+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 39b5ac792cf9:37901 (size: 4.0 MiB, free: 430.3 MiB)
[2025-07-03T18:02:10.505+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_23_piece1 stored as bytes in memory (estimated size 3.3 MiB, free 386.6 MiB)
[2025-07-03T18:02:10.505+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Added broadcast_23_piece1 in memory on 39b5ac792cf9:37901 (size: 3.3 MiB, free: 427.0 MiB)
[2025-07-03T18:02:10.506+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Created broadcast 23 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-03T18:02:10.507+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 39b5ac792cf9:37901 in memory (size: 35.0 KiB, free: 427.0 MiB)
[2025-07-03T18:02:10.509+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 39b5ac792cf9:37901 in memory (size: 25.0 KiB, free: 427.1 MiB)
[2025-07-03T18:02:10.511+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 201.8 KiB, free 386.7 MiB)
[2025-07-03T18:02:10.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 386.6 MiB)
[2025-07-03T18:02:10.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 39b5ac792cf9:37901 (size: 35.2 KiB, free: 427.0 MiB)
[2025-07-03T18:02:10.514+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Created broadcast 24 from showString at NativeMethodAccessorImpl.java:0
[2025-07-03T18:02:10.515+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-03T18:02:10.524+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-03T18:02:10.525+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Registering RDD 47 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-07-03T18:02:10.525+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Got job 9 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-03T18:02:10.525+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Final stage: ResultStage 14 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-03T18:02:10.525+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-07-03T18:02:10.525+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
[2025-07-03T18:02:10.526+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:02:10.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 63.4 KiB, free 386.6 MiB)
[2025-07-03T18:02:10.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.9 KiB, free 386.6 MiB)
[2025-07-03T18:02:10.527+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 39b5ac792cf9:37901 (size: 25.9 KiB, free: 427.0 MiB)
[2025-07-03T18:02:10.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:10.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
[2025-07-03T18:02:10.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSchedulerImpl: Adding task set 13.0 with 7 tasks resource profile 0
[2025-07-03T18:02:10.528+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 453) (39b5ac792cf9, executor driver, partition 0, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:10.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 0.0 in stage 13.0 (TID 453)
[2025-07-03T18:02:10.532+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00068-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-168362, partition values: [empty row]
[2025-07-03T18:02:10.533+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.536+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00196-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-163710, partition values: [empty row]
[2025-07-03T18:02:10.537+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00029-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157967, partition values: [empty row]
[2025-07-03T18:02:10.540+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00198-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157920, partition values: [empty row]
[2025-07-03T18:02:10.541+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00128-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157850, partition values: [empty row]
[2025-07-03T18:02:10.543+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.544+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00120-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157700, partition values: [empty row]
[2025-07-03T18:02:10.545+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.546+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00102-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-157204, partition values: [empty row]
[2025-07-03T18:02:10.547+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.548+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00053-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156699, partition values: [empty row]
[2025-07-03T18:02:10.549+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.550+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00147-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-156146, partition values: [empty row]
[2025-07-03T18:02:10.551+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.552+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00087-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-155444, partition values: [empty row]
[2025-07-03T18:02:10.553+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00140-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-154024, partition values: [empty row]
[2025-07-03T18:02:10.555+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.556+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00095-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153497, partition values: [empty row]
[2025-07-03T18:02:10.556+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.557+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00079-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153486, partition values: [empty row]
[2025-07-03T18:02:10.558+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.559+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00130-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153363, partition values: [empty row]
[2025-07-03T18:02:10.560+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.561+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00172-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-153223, partition values: [empty row]
[2025-07-03T18:02:10.561+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.562+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00049-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152868, partition values: [empty row]
[2025-07-03T18:02:10.563+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00031-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152746, partition values: [empty row]
[2025-07-03T18:02:10.564+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.565+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00133-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152572, partition values: [empty row]
[2025-07-03T18:02:10.566+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.567+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00038-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152480, partition values: [empty row]
[2025-07-03T18:02:10.568+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.569+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00097-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152347, partition values: [empty row]
[2025-07-03T18:02:10.569+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00178-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152161, partition values: [empty row]
[2025-07-03T18:02:10.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00027-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-152149, partition values: [empty row]
[2025-07-03T18:02:10.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.573+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00045-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151971, partition values: [empty row]
[2025-07-03T18:02:10.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.575+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00135-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151699, partition values: [empty row]
[2025-07-03T18:02:10.576+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.577+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00187-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151670, partition values: [empty row]
[2025-07-03T18:02:10.577+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.578+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00083-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-151205, partition values: [empty row]
[2025-07-03T18:02:10.579+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.580+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00034-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150976, partition values: [empty row]
[2025-07-03T18:02:10.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00111-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150838, partition values: [empty row]
[2025-07-03T18:02:10.582+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.583+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00142-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150787, partition values: [empty row]
[2025-07-03T18:02:10.584+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.585+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00011-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150662, partition values: [empty row]
[2025-07-03T18:02:10.586+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00030-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150182, partition values: [empty row]
[2025-07-03T18:02:10.587+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 0.0 in stage 13.0 (TID 453). 3883 bytes result sent to driver
[2025-07-03T18:02:10.598+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 454) (39b5ac792cf9, executor driver, partition 1, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:10.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 1.0 in stage 13.0 (TID 454)
[2025-07-03T18:02:10.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 453) in 70 ms on 39b5ac792cf9 (executor driver) (1/7)
[2025-07-03T18:02:10.602+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00108-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150170, partition values: [empty row]
[2025-07-03T18:02:10.603+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.604+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00188-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150141, partition values: [empty row]
[2025-07-03T18:02:10.605+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.606+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00092-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-150033, partition values: [empty row]
[2025-07-03T18:02:10.608+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.609+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00132-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149955, partition values: [empty row]
[2025-07-03T18:02:10.610+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00162-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149789, partition values: [empty row]
[2025-07-03T18:02:10.611+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.612+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00112-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149402, partition values: [empty row]
[2025-07-03T18:02:10.613+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.614+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00146-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149158, partition values: [empty row]
[2025-07-03T18:02:10.615+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00039-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149155, partition values: [empty row]
[2025-07-03T18:02:10.616+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.617+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00164-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-149052, partition values: [empty row]
[2025-07-03T18:02:10.618+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.620+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00123-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148925, partition values: [empty row]
[2025-07-03T18:02:10.621+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.622+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00041-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148678, partition values: [empty row]
[2025-07-03T18:02:10.623+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.624+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00105-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-148248, partition values: [empty row]
[2025-07-03T18:02:10.625+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.626+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00020-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147953, partition values: [empty row]
[2025-07-03T18:02:10.627+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.628+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00072-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147680, partition values: [empty row]
[2025-07-03T18:02:10.629+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.630+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00184-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147353, partition values: [empty row]
[2025-07-03T18:02:10.631+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.632+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00119-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147307, partition values: [empty row]
[2025-07-03T18:02:10.633+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.634+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00160-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-147088, partition values: [empty row]
[2025-07-03T18:02:10.635+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.636+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00089-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146834, partition values: [empty row]
[2025-07-03T18:02:10.637+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.639+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00055-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146628, partition values: [empty row]
[2025-07-03T18:02:10.639+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.640+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00107-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146573, partition values: [empty row]
[2025-07-03T18:02:10.641+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.642+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00050-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146529, partition values: [empty row]
[2025-07-03T18:02:10.643+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.645+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00073-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146322, partition values: [empty row]
[2025-07-03T18:02:10.646+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.648+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00182-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-146085, partition values: [empty row]
[2025-07-03T18:02:10.649+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.650+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00124-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145923, partition values: [empty row]
[2025-07-03T18:02:10.652+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.653+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00037-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145736, partition values: [empty row]
[2025-07-03T18:02:10.654+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.655+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00032-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145483, partition values: [empty row]
[2025-07-03T18:02:10.656+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.657+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00044-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145472, partition values: [empty row]
[2025-07-03T18:02:10.658+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.660+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00137-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145459, partition values: [empty row]
[2025-07-03T18:02:10.661+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.662+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00009-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145443, partition values: [empty row]
[2025-07-03T18:02:10.663+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.664+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00067-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145348, partition values: [empty row]
[2025-07-03T18:02:10.665+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.666+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00139-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145180, partition values: [empty row]
[2025-07-03T18:02:10.667+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.702+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 1.0 in stage 13.0 (TID 454). 3883 bytes result sent to driver
[2025-07-03T18:02:10.707+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 455) (39b5ac792cf9, executor driver, partition 2, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:10.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 454) in 104 ms on 39b5ac792cf9 (executor driver) (2/7)
[2025-07-03T18:02:10.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 2.0 in stage 13.0 (TID 455)
[2025-07-03T18:02:10.708+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00114-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-145175, partition values: [empty row]
[2025-07-03T18:02:10.709+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.711+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00154-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144764, partition values: [empty row]
[2025-07-03T18:02:10.712+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00115-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144653, partition values: [empty row]
[2025-07-03T18:02:10.714+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.716+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00062-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144636, partition values: [empty row]
[2025-07-03T18:02:10.717+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.718+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00177-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144534, partition values: [empty row]
[2025-07-03T18:02:10.719+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.720+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00131-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144411, partition values: [empty row]
[2025-07-03T18:02:10.721+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.722+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00003-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144247, partition values: [empty row]
[2025-07-03T18:02:10.723+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.724+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00159-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144214, partition values: [empty row]
[2025-07-03T18:02:10.725+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.726+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00081-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-144124, partition values: [empty row]
[2025-07-03T18:02:10.727+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.729+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00173-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143839, partition values: [empty row]
[2025-07-03T18:02:10.730+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.734+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00145-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143692, partition values: [empty row]
[2025-07-03T18:02:10.735+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.737+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00100-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143512, partition values: [empty row]
[2025-07-03T18:02:10.738+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.741+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00110-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143491, partition values: [empty row]
[2025-07-03T18:02:10.742+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.744+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00167-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143463, partition values: [empty row]
[2025-07-03T18:02:10.745+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.746+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00082-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143421, partition values: [empty row]
[2025-07-03T18:02:10.747+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.748+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00103-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143305, partition values: [empty row]
[2025-07-03T18:02:10.749+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00094-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143260, partition values: [empty row]
[2025-07-03T18:02:10.750+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.751+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00192-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-143248, partition values: [empty row]
[2025-07-03T18:02:10.752+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00153-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142738, partition values: [empty row]
[2025-07-03T18:02:10.753+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.754+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00028-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142579, partition values: [empty row]
[2025-07-03T18:02:10.755+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.756+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00109-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142500, partition values: [empty row]
[2025-07-03T18:02:10.757+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.758+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00007-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142453, partition values: [empty row]
[2025-07-03T18:02:10.759+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00197-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142400, partition values: [empty row]
[2025-07-03T18:02:10.761+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.764+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00048-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142344, partition values: [empty row]
[2025-07-03T18:02:10.765+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.766+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00024-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142324, partition values: [empty row]
[2025-07-03T18:02:10.767+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.768+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00113-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-142107, partition values: [empty row]
[2025-07-03T18:02:10.769+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00179-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141811, partition values: [empty row]
[2025-07-03T18:02:10.770+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.771+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00194-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141737, partition values: [empty row]
[2025-07-03T18:02:10.772+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.773+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00022-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141733, partition values: [empty row]
[2025-07-03T18:02:10.774+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.775+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00006-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141716, partition values: [empty row]
[2025-07-03T18:02:10.775+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.776+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00057-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141276, partition values: [empty row]
[2025-07-03T18:02:10.777+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.799+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 2.0 in stage 13.0 (TID 455). 3969 bytes result sent to driver
[2025-07-03T18:02:10.802+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 456) (39b5ac792cf9, executor driver, partition 3, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:10.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 3.0 in stage 13.0 (TID 456)
[2025-07-03T18:02:10.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 455) in 97 ms on 39b5ac792cf9 (executor driver) (3/7)
[2025-07-03T18:02:10.803+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00180-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141220, partition values: [empty row]
[2025-07-03T18:02:10.805+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.807+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00181-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141147, partition values: [empty row]
[2025-07-03T18:02:10.808+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.810+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00134-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141133, partition values: [empty row]
[2025-07-03T18:02:10.811+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.812+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00174-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141104, partition values: [empty row]
[2025-07-03T18:02:10.813+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.818+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00054-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-141050, partition values: [empty row]
[2025-07-03T18:02:10.819+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00085-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140960, partition values: [empty row]
[2025-07-03T18:02:10.821+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00122-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140951, partition values: [empty row]
[2025-07-03T18:02:10.823+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.826+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00064-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140895, partition values: [empty row]
[2025-07-03T18:02:10.827+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.828+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00080-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140405, partition values: [empty row]
[2025-07-03T18:02:10.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.829+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00071-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140133, partition values: [empty row]
[2025-07-03T18:02:10.830+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.831+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00118-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140113, partition values: [empty row]
[2025-07-03T18:02:10.832+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.833+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00136-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140097, partition values: [empty row]
[2025-07-03T18:02:10.834+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00056-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-140011, partition values: [empty row]
[2025-07-03T18:02:10.835+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.836+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00016-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139898, partition values: [empty row]
[2025-07-03T18:02:10.837+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00121-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139858, partition values: [empty row]
[2025-07-03T18:02:10.838+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.839+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00018-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139827, partition values: [empty row]
[2025-07-03T18:02:10.840+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.841+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00002-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139804, partition values: [empty row]
[2025-07-03T18:02:10.842+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.843+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00052-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139763, partition values: [empty row]
[2025-07-03T18:02:10.843+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.845+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00152-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139683, partition values: [empty row]
[2025-07-03T18:02:10.845+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.847+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00170-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139630, partition values: [empty row]
[2025-07-03T18:02:10.847+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00183-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139299, partition values: [empty row]
[2025-07-03T18:02:10.849+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.850+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00025-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-139114, partition values: [empty row]
[2025-07-03T18:02:10.851+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.852+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00026-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138875, partition values: [empty row]
[2025-07-03T18:02:10.853+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.854+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00070-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138619, partition values: [empty row]
[2025-07-03T18:02:10.855+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.856+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00117-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138472, partition values: [empty row]
[2025-07-03T18:02:10.857+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.858+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00148-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138343, partition values: [empty row]
[2025-07-03T18:02:10.859+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00151-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-138303, partition values: [empty row]
[2025-07-03T18:02:10.861+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.862+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00190-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137980, partition values: [empty row]
[2025-07-03T18:02:10.863+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.864+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00116-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137825, partition values: [empty row]
[2025-07-03T18:02:10.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.865+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00046-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137502, partition values: [empty row]
[2025-07-03T18:02:10.866+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.867+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00063-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137399, partition values: [empty row]
[2025-07-03T18:02:10.868+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.879+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 3.0 in stage 13.0 (TID 456). 3883 bytes result sent to driver
[2025-07-03T18:02:10.879+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 457) (39b5ac792cf9, executor driver, partition 4, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:10.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 4.0 in stage 13.0 (TID 457)
[2025-07-03T18:02:10.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 456) in 80 ms on 39b5ac792cf9 (executor driver) (4/7)
[2025-07-03T18:02:10.882+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00143-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137169, partition values: [empty row]
[2025-07-03T18:02:10.883+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.884+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00047-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-137073, partition values: [empty row]
[2025-07-03T18:02:10.885+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.886+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00084-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136997, partition values: [empty row]
[2025-07-03T18:02:10.887+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00156-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136937, partition values: [empty row]
[2025-07-03T18:02:10.888+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.889+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00193-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136790, partition values: [empty row]
[2025-07-03T18:02:10.890+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.891+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00042-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136602, partition values: [empty row]
[2025-07-03T18:02:10.892+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.893+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00088-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136524, partition values: [empty row]
[2025-07-03T18:02:10.893+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.894+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00191-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136091, partition values: [empty row]
[2025-07-03T18:02:10.895+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.896+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00019-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-136064, partition values: [empty row]
[2025-07-03T18:02:10.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.897+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00127-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135998, partition values: [empty row]
[2025-07-03T18:02:10.898+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.899+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00199-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135968, partition values: [empty row]
[2025-07-03T18:02:10.900+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00013-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135936, partition values: [empty row]
[2025-07-03T18:02:10.901+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.902+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00144-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135783, partition values: [empty row]
[2025-07-03T18:02:10.903+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00101-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135779, partition values: [empty row]
[2025-07-03T18:02:10.904+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.905+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00171-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135629, partition values: [empty row]
[2025-07-03T18:02:10.906+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.907+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00166-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135568, partition values: [empty row]
[2025-07-03T18:02:10.908+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.908+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00165-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135539, partition values: [empty row]
[2025-07-03T18:02:10.909+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.910+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00060-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135477, partition values: [empty row]
[2025-07-03T18:02:10.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.911+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00004-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135462, partition values: [empty row]
[2025-07-03T18:02:10.912+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.913+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00010-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135408, partition values: [empty row]
[2025-07-03T18:02:10.914+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00040-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135398, partition values: [empty row]
[2025-07-03T18:02:10.915+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.916+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00033-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135395, partition values: [empty row]
[2025-07-03T18:02:10.917+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.917+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00021-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135250, partition values: [empty row]
[2025-07-03T18:02:10.918+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.919+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00023-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135210, partition values: [empty row]
[2025-07-03T18:02:10.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.920+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00185-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-135190, partition values: [empty row]
[2025-07-03T18:02:10.921+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.922+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00061-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134981, partition values: [empty row]
[2025-07-03T18:02:10.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.923+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00001-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134944, partition values: [empty row]
[2025-07-03T18:02:10.924+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.925+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00189-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134929, partition values: [empty row]
[2025-07-03T18:02:10.926+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00091-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134926, partition values: [empty row]
[2025-07-03T18:02:10.927+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.928+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00161-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134806, partition values: [empty row]
[2025-07-03T18:02:10.929+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00012-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134703, partition values: [empty row]
[2025-07-03T18:02:10.930+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Finished task 4.0 in stage 13.0 (TID 457). 3883 bytes result sent to driver
[2025-07-03T18:02:10.942+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 458) (39b5ac792cf9, executor driver, partition 5, PROCESS_LOCAL, 14516 bytes)
[2025-07-03T18:02:10.945+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO Executor: Running task 5.0 in stage 13.0 (TID 458)
[2025-07-03T18:02:10.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 457) in 63 ms on 39b5ac792cf9 (executor driver) (5/7)
[2025-07-03T18:02:10.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00014-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134651, partition values: [empty row]
[2025-07-03T18:02:10.946+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.948+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00075-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134649, partition values: [empty row]
[2025-07-03T18:02:10.949+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.949+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00168-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134557, partition values: [empty row]
[2025-07-03T18:02:10.950+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.951+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00176-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134495, partition values: [empty row]
[2025-07-03T18:02:10.952+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00157-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134432, partition values: [empty row]
[2025-07-03T18:02:10.953+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.954+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00069-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134344, partition values: [empty row]
[2025-07-03T18:02:10.955+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.956+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00051-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-134093, partition values: [empty row]
[2025-07-03T18:02:10.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.957+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00035-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133957, partition values: [empty row]
[2025-07-03T18:02:10.958+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.959+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00175-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133736, partition values: [empty row]
[2025-07-03T18:02:10.960+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.961+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00058-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133517, partition values: [empty row]
[2025-07-03T18:02:10.961+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.962+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00008-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133312, partition values: [empty row]
[2025-07-03T18:02:10.963+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00036-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133250, partition values: [empty row]
[2025-07-03T18:02:10.964+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.965+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00017-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133244, partition values: [empty row]
[2025-07-03T18:02:10.966+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.967+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00195-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-133115, partition values: [empty row]
[2025-07-03T18:02:10.968+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.969+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00086-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132787, partition values: [empty row]
[2025-07-03T18:02:10.970+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.971+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00106-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132496, partition values: [empty row]
[2025-07-03T18:02:10.972+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.973+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00149-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132477, partition values: [empty row]
[2025-07-03T18:02:10.974+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00126-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132427, partition values: [empty row]
[2025-07-03T18:02:10.975+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.976+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00099-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132405, partition values: [empty row]
[2025-07-03T18:02:10.977+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.978+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00186-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-132164, partition values: [empty row]
[2025-07-03T18:02:10.979+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.980+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00093-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131331, partition values: [empty row]
[2025-07-03T18:02:10.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.981+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00074-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-131260, partition values: [empty row]
[2025-07-03T18:02:10.982+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.983+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00078-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130578, partition values: [empty row]
[2025-07-03T18:02:10.984+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.985+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00141-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130266, partition values: [empty row]
[2025-07-03T18:02:10.986+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00005-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130222, partition values: [empty row]
[2025-07-03T18:02:10.988+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.989+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00065-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130083, partition values: [empty row]
[2025-07-03T18:02:10.990+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.991+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00125-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-130011, partition values: [empty row]
[2025-07-03T18:02:10.992+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.993+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00077-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129832, partition values: [empty row]
[2025-07-03T18:02:10.994+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:10.995+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00169-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129566, partition values: [empty row]
[2025-07-03T18:02:10.996+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.000+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:10 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00150-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129448, partition values: [empty row]
[2025-07-03T18:02:11.001+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00163-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129300, partition values: [empty row]
[2025-07-03T18:02:11.002+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO Executor: Finished task 5.0 in stage 13.0 (TID 458). 3926 bytes result sent to driver
[2025-07-03T18:02:11.017+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 459) (39b5ac792cf9, executor driver, partition 6, PROCESS_LOCAL, 11762 bytes)
[2025-07-03T18:02:11.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO Executor: Running task 6.0 in stage 13.0 (TID 459)
[2025-07-03T18:02:11.020+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 458) in 75 ms on 39b5ac792cf9 (executor driver) (6/7)
[2025-07-03T18:02:11.022+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00129-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-129243, partition values: [empty row]
[2025-07-03T18:02:11.023+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.024+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00155-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128963, partition values: [empty row]
[2025-07-03T18:02:11.025+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.026+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00076-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128747, partition values: [empty row]
[2025-07-03T18:02:11.027+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00098-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128595, partition values: [empty row]
[2025-07-03T18:02:11.028+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.029+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00066-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-128097, partition values: [empty row]
[2025-07-03T18:02:11.030+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00090-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-127202, partition values: [empty row]
[2025-07-03T18:02:11.032+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.033+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00138-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-126507, partition values: [empty row]
[2025-07-03T18:02:11.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.034+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00043-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125123, partition values: [empty row]
[2025-07-03T18:02:11.035+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.036+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00158-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-125003, partition values: [empty row]
[2025-07-03T18:02:11.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00059-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123983, partition values: [empty row]
[2025-07-03T18:02:11.038+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.039+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00104-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123468, partition values: [empty row]
[2025-07-03T18:02:11.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.040+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00000-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-123063, partition values: [empty row]
[2025-07-03T18:02:11.041+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.042+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00015-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-122798, partition values: [empty row]
[2025-07-03T18:02:11.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FileScanRDD: Reading File path: file:///opt/shared/silver/athlete_bio/part-00096-d8ab1cca-deb1-44f7-b811-601dfbcb4f4d-c000.snappy.parquet, range: 0-118888, partition values: [empty row]
[2025-07-03T18:02:11.044+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO FilterCompat: Filtering using predicate: noteq(athlete_id, null)
[2025-07-03T18:02:11.054+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO Executor: Finished task 6.0 in stage 13.0 (TID 459). 3926 bytes result sent to driver
[2025-07-03T18:02:11.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 459) in 38 ms on 39b5ac792cf9 (executor driver) (7/7)
[2025-07-03T18:02:11.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-07-03T18:02:11.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: ShuffleMapStage 13 (showString at NativeMethodAccessorImpl.java:0) finished in 0.529 s
[2025-07-03T18:02:11.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: looking for newly runnable stages
[2025-07-03T18:02:11.055+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: running: Set()
[2025-07-03T18:02:11.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: waiting: Set(ResultStage 14)
[2025-07-03T18:02:11.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: failed: Set()
[2025-07-03T18:02:11.056+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[50] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-03T18:02:11.057+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 60.0 KiB, free 386.5 MiB)
[2025-07-03T18:02:11.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 26.3 KiB, free 386.5 MiB)
[2025-07-03T18:02:11.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 39b5ac792cf9:37901 (size: 26.3 KiB, free: 427.0 MiB)
[2025-07-03T18:02:11.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
[2025-07-03T18:02:11.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[50] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-03T18:02:11.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-07-03T18:02:11.059+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 460) (39b5ac792cf9, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-03T18:02:11.063+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO Executor: Running task 0.0 in stage 14.0 (TID 460)
[2025-07-03T18:02:11.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO ShuffleBlockFetcherIterator: Getting 7 (11.0 KiB) non-empty blocks including 7 (11.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-03T18:02:11.064+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-03T18:02:11.069+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO CodeGenerator: Code generated in 6.645709 ms
[2025-07-03T18:02:11.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO Executor: Finished task 0.0 in stage 14.0 (TID 460). 7819 bytes result sent to driver
[2025-07-03T18:02:11.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 460) in 16 ms on 39b5ac792cf9 (executor driver) (1/1)
[2025-07-03T18:02:11.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-07-03T18:02:11.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: ResultStage 14 (showString at NativeMethodAccessorImpl.java:0) finished in 0.019 s
[2025-07-03T18:02:11.075+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-03T18:02:11.076+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-07-03T18:02:11.076+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO DAGScheduler: Job 9 finished: showString at NativeMethodAccessorImpl.java:0, took 0.551044 s
[2025-07-03T18:02:11.523+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO CodeGenerator: Code generated in 5.044041 ms
[2025-07-03T18:02:11.536+0000] {spark_submit.py:579} INFO - +------------------+------+------+-----------+------------------+-----------------+--------------------+
[2025-07-03T18:02:11.537+0000] {spark_submit.py:579} INFO - |             sport| medal|   sex|country_noc|        avg_height|       avg_weight|           timestamp|
[2025-07-03T18:02:11.537+0000] {spark_submit.py:579} INFO - +------------------+------+------+-----------+------------------+-----------------+--------------------+
[2025-07-03T18:02:11.537+0000] {spark_submit.py:579} INFO - |        Ice Hockey|Bronze|  Male|        CZE|184.44736842105263|88.86842105263158|2025-07-03 18:02:...|
[2025-07-03T18:02:11.537+0000] {spark_submit.py:579} INFO - |           Curling|Silver|  Male|        NOR|             185.8|             87.6|2025-07-03 18:02:...|
[2025-07-03T18:02:11.537+0000] {spark_submit.py:579} INFO - |              Luge|Silver|Female|        GDR|             172.4|             72.4|2025-07-03 18:02:...|
[2025-07-03T18:02:11.537+0000] {spark_submit.py:579} INFO - |          Shooting|Silver|  Male|        FRA|             179.6|             75.8|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |         Athletics|Bronze|  Male|        SUI|             200.0|            128.0|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |Equestrian Jumping|  Gold|  Male|        USA|182.11111111111111|71.66666666666667|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |            Boxing|Bronze|  Male|        VEN|             165.0|             52.5|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |           Sailing|Silver|  Male|        GDR|178.66666666666666|82.83333333333333|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |     Cycling Track|  Gold|  Male|        ESP|             180.0|69.66666666666667|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |      Canoe Sprint|Bronze|  Male|        POL| 182.3846153846154|82.38461538461539|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |              Judo|Silver|Female|        JPN|             160.6|          12569.0|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |         Badminton|Silver|  Male|        INA|174.16666666666666|70.66666666666667|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |        Basketball|  NULL|  Male|        PHI| 181.2972972972973|76.21621621621621|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |     Speed Skating|  NULL|  Male|        ITA|177.70866141732284|73.68503937007874|2025-07-03 18:02:...|
[2025-07-03T18:02:11.538+0000] {spark_submit.py:579} INFO - |           Sailing|  NULL|  Male|        ITA|179.26351351351352|78.32432432432432|2025-07-03 18:02:...|
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - |     Alpine Skiing|  NULL|  Male|        RUS|179.31034482758622| 83.1896551724138|2025-07-03 18:02:...|
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - |           Archery|  NULL|Female|        SWE|169.03225806451613|61.83870967741935|2025-07-03 18:02:...|
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - |              Judo|  NULL|  Male|        USA| 179.3684210526316|84.52631578947368|2025-07-03 18:02:...|
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - |         Athletics|  NULL|  Male|        DOM| 174.0952380952381|68.03174603174604|2025-07-03 18:02:...|
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - |          Football|  NULL|  Male|        UAE|             175.5|70.04545454545455|2025-07-03 18:02:...|
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - +------------------+------+------+-----------+------------------+-----------------+--------------------+
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - only showing top 20 rows
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - 
[2025-07-03T18:02:11.539+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-03T18:02:11.545+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO SparkUI: Stopped Spark web UI at http://39b5ac792cf9:4040
[2025-07-03T18:02:11.554+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-03T18:02:11.570+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO MemoryStore: MemoryStore cleared
[2025-07-03T18:02:11.571+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO BlockManager: BlockManager stopped
[2025-07-03T18:02:11.572+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-03T18:02:11.574+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-03T18:02:11.581+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:11 INFO SparkContext: Successfully stopped SparkContext
[2025-07-03T18:02:12.031+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:12 INFO ShutdownHookManager: Shutdown hook called
[2025-07-03T18:02:12.032+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-017264ca-313a-4b52-aa27-f0f9db6dd33c
[2025-07-03T18:02:12.037+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-09599d6c-fc09-4d64-aa6a-d6051c09be0c/pyspark-405e3d45-9461-42a7-a110-bb6311a0cc2e
[2025-07-03T18:02:12.043+0000] {spark_submit.py:579} INFO - 25/07/03 18:02:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-09599d6c-fc09-4d64-aa6a-d6051c09be0c
[2025-07-03T18:02:12.114+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-07-03T18:02:12.115+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=margosha_fp_dag, task_id=silver_to_gold, run_id=manual__2025-07-03T18:00:56.340179+00:00, execution_date=20250703T180056, start_date=20250703T180153, end_date=20250703T180212
[2025-07-03T18:02:12.172+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-07-03T18:02:12.186+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-03T18:02:12.186+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
